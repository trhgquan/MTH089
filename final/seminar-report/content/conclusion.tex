\section{Tổng kết}
Nhóm xin tổng kết lại các nội dung đã tìm hiểu trong bài báo như sau:
\begin{itemize}
\item Bài báo giới thiệu mô hình ViHealthBERT là mô hình đơn ngữ Tiếng Việt đầu tiên cho lĩnh vực y tế, sử dụng kiến trúc của BERT và bộ trọng số huấn luyện của PhoBERT. Nhóm tác giả pretrain mô hình với các task Masked Language Modeling (MLM), Next Sentence Prediction (NSP) và Capitalized Prediction (CP). Nhóm tác giả sau đó finetune mô hình với các task NER, Acronym Disambiguation và FAQ Summarization. Kết quả của ViHealthBERT tốt hơn các mô hình PhoBERT khi kiểm thử trên các tập ngữ liệu y tế Tiếng Việt.
\item Bài báo giới thiệu các bộ ngữ liệu arcDrAid và FAQ Summarization là các bộ ngữ liệu Tiếng Việt về chủ đề y tế, phục vụ cho việc huấn luyện các task Acrony Disambiguation và FAQ Summarization.
\end{itemize}

Tuy nhiên, một nhận xét của nhóm là việc pretraining task Capitalized Predicion (CP) không thể hiện được rõ tính hiệu quả như nhóm tác giả đã đề xuất. Các mô hình có sử dụng pretraining task CP không đạt được hiệu quả cao nhất, thậm chí vẫn thua nhóm mô hình train với các pretraining task cơ bản (MLM và NSP). Mô hình ViHealthBERT có thể đạt kết quả tốt do bộ ngữ liệu đầu vào đặc thù của ngành y tế so với PhoBERT dùng bộ ngữ liệu cho general domain. Mặt khác, việc sử dụng tokenize-level là syllable so với word có thể ảnh hưởng đến kết quả, xét bản chất bộ ViMQ được thu thập từ nhiều nguồn y tế và nhiều chủ đề hơn so với bộ PhoNER\_COVID-19 chỉ gồm các văn bản liên quan đến COVID-19.

Một số hướng cải tiến cho mô hình mà nhóm đề xuất, bao gồm thực hiện nhiều thử nghiệm với mô hình ViHealthBERT có pretraining task CP để chứng minh độ hiệu quả của giả thuyết nhóm tác giả bài báo đưa ra. Nhóm cũng tiến hành xây dựng một ứng dụng trích xuất triệu chứng bệnh từ miêu tả của bệnh nhân, sử dụng mô hình ViHealthBERT đã finetune. Chi tiết của ứng dụng sẽ được trình bày trong Báo cáo đồ án.