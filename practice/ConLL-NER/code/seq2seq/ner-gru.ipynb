{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362c46b9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-24T04:07:54.622625Z",
     "iopub.status.busy": "2022-10-24T04:07:54.621935Z",
     "iopub.status.idle": "2022-10-24T04:07:54.635019Z",
     "shell.execute_reply": "2022-10-24T04:07:54.633985Z"
    },
    "papermill": {
     "duration": 0.032552,
     "end_time": "2022-10-24T04:07:54.638635",
     "exception": false,
     "start_time": "2022-10-24T04:07:54.606083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0375d20",
   "metadata": {
    "papermill": {
     "duration": 0.022911,
     "end_time": "2022-10-24T04:07:54.689927",
     "exception": false,
     "start_time": "2022-10-24T04:07:54.667016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download and Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb87d3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:07:54.723315Z",
     "iopub.status.busy": "2022-10-24T04:07:54.722997Z",
     "iopub.status.idle": "2022-10-24T04:07:58.987433Z",
     "shell.execute_reply": "2022-10-24T04:07:58.986374Z"
    },
    "papermill": {
     "duration": 4.280997,
     "end_time": "2022-10-24T04:07:58.989885",
     "exception": false,
     "start_time": "2022-10-24T04:07:54.708888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 3206k  100 3206k    0     0  7726k      0 --:--:-- --:--:-- --:--:-- 7726k\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  808k  100  808k    0     0  2693k      0 --:--:-- --:--:-- --:--:-- 2693k\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  730k  100  730k    0     0  2476k      0 --:--:-- --:--:-- --:--:-- 2476k\r\n"
     ]
    }
   ],
   "source": [
    "!curl -LJ \"https://raw.githubusercontent.com/ningshixian/NER-CONLL2003/master/data/train.txt\" -o \"train.txt\"\n",
    "!curl -LJ \"https://raw.githubusercontent.com/ningshixian/NER-CONLL2003/master/data/valid.txt\" -o \"valid.txt\"\n",
    "!curl -LJ \"https://raw.githubusercontent.com/ningshixian/NER-CONLL2003/master/data/test.txt\" -o \"test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7c87daa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:07:59.020572Z",
     "iopub.status.busy": "2022-10-24T04:07:59.019714Z",
     "iopub.status.idle": "2022-10-24T04:07:59.949510Z",
     "shell.execute_reply": "2022-10-24T04:07:59.948150Z"
    },
    "papermill": {
     "duration": 0.946534,
     "end_time": "2022-10-24T04:07:59.951789",
     "exception": false,
     "start_time": "2022-10-24T04:07:59.005255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\r\n",
      "\r\n",
      "EU NNP B-NP B-ORG\r\n",
      "rejects VBZ B-VP O\r\n",
      "German JJ B-NP B-MISC\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29516b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:07:59.980422Z",
     "iopub.status.busy": "2022-10-24T04:07:59.980083Z",
     "iopub.status.idle": "2022-10-24T04:08:01.280875Z",
     "shell.execute_reply": "2022-10-24T04:08:01.279927Z"
    },
    "papermill": {
     "duration": 1.317708,
     "end_time": "2022-10-24T04:08:01.283273",
     "exception": false,
     "start_time": "2022-10-24T04:07:59.965565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus.reader import ConllCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bfef9d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:01.311822Z",
     "iopub.status.busy": "2022-10-24T04:08:01.310989Z",
     "iopub.status.idle": "2022-10-24T04:08:01.317885Z",
     "shell.execute_reply": "2022-10-24T04:08:01.317084Z"
    },
    "papermill": {
     "duration": 0.023101,
     "end_time": "2022-10-24T04:08:01.319894",
     "exception": false,
     "start_time": "2022-10-24T04:08:01.296793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sentences = ConllCorpusReader(\"./\", \"train.txt\", [\"words\", \"pos\", \"ignore\", \"chunk\"]).iob_sents()\n",
    "valid_sentences = ConllCorpusReader(\"./\", \"valid.txt\", [\"words\", \"pos\", \"ignore\", \"chunk\"]).iob_sents()\n",
    "test_sentences = ConllCorpusReader(\"./\", \"test.txt\", [\"words\", \"pos\", \"ignore\", \"chunk\"]).iob_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f2a8b2",
   "metadata": {
    "papermill": {
     "duration": 0.01333,
     "end_time": "2022-10-24T04:08:01.346430",
     "exception": false,
     "start_time": "2022-10-24T04:08:01.333100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Remove empty (len = 0) sentences due to data error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d04322d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:01.374192Z",
     "iopub.status.busy": "2022-10-24T04:08:01.373920Z",
     "iopub.status.idle": "2022-10-24T04:08:02.697404Z",
     "shell.execute_reply": "2022-10-24T04:08:02.696424Z"
    },
    "papermill": {
     "duration": 1.340021,
     "end_time": "2022-10-24T04:08:02.699995",
     "exception": false,
     "start_time": "2022-10-24T04:08:01.359974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sentences = [s for s in train_sentences if len(s) > 0]\n",
    "valid_sentences = [s for s in valid_sentences if len(s) > 0]\n",
    "test_sentences = [s for s in test_sentences if len(s) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "350dc756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:02.728328Z",
     "iopub.status.busy": "2022-10-24T04:08:02.728018Z",
     "iopub.status.idle": "2022-10-24T04:08:02.733137Z",
     "shell.execute_reply": "2022-10-24T04:08:02.732247Z"
    },
    "papermill": {
     "duration": 0.021597,
     "end_time": "2022-10-24T04:08:02.735299",
     "exception": false,
     "start_time": "2022-10-24T04:08:02.713702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set: 14041\n",
      "Length of validation set: 3250\n",
      "Length of test set: 3453\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of train set: {len(train_sentences)}\")\n",
    "print(f\"Length of validation set: {len(valid_sentences)}\")\n",
    "print(f\"Length of test set: {len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec0cde7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:02.763357Z",
     "iopub.status.busy": "2022-10-24T04:08:02.762695Z",
     "iopub.status.idle": "2022-10-24T04:08:02.771150Z",
     "shell.execute_reply": "2022-10-24T04:08:02.770132Z"
    },
    "papermill": {
     "duration": 0.025745,
     "end_time": "2022-10-24T04:08:02.774333",
     "exception": false,
     "start_time": "2022-10-24T04:08:02.748588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EU', 'NNP', 'B-ORG'),\n",
       " ('rejects', 'VBZ', 'O'),\n",
       " ('German', 'JJ', 'B-MISC'),\n",
       " ('call', 'NN', 'O'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('boycott', 'VB', 'O'),\n",
       " ('British', 'JJ', 'B-MISC'),\n",
       " ('lamb', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e06aa27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:02.802583Z",
     "iopub.status.busy": "2022-10-24T04:08:02.801817Z",
     "iopub.status.idle": "2022-10-24T04:08:02.808567Z",
     "shell.execute_reply": "2022-10-24T04:08:02.807664Z"
    },
    "papermill": {
     "duration": 0.022907,
     "end_time": "2022-10-24T04:08:02.810537",
     "exception": false,
     "start_time": "2022-10-24T04:08:02.787630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRICKET', 'NNP', 'O'),\n",
       " ('-', ':', 'O'),\n",
       " ('LEICESTERSHIRE', 'NNP', 'B-ORG'),\n",
       " ('TAKE', 'NNP', 'O'),\n",
       " ('OVER', 'IN', 'O'),\n",
       " ('AT', 'NNP', 'O'),\n",
       " ('TOP', 'NNP', 'O'),\n",
       " ('AFTER', 'NNP', 'O'),\n",
       " ('INNINGS', 'NNP', 'O'),\n",
       " ('VICTORY', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c85204",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:02.839102Z",
     "iopub.status.busy": "2022-10-24T04:08:02.838331Z",
     "iopub.status.idle": "2022-10-24T04:08:02.845141Z",
     "shell.execute_reply": "2022-10-24T04:08:02.844291Z"
    },
    "papermill": {
     "duration": 0.023167,
     "end_time": "2022-10-24T04:08:02.847115",
     "exception": false,
     "start_time": "2022-10-24T04:08:02.823948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SOCCER', 'NN', 'O'),\n",
       " ('-', ':', 'O'),\n",
       " ('JAPAN', 'NNP', 'B-LOC'),\n",
       " ('GET', 'VB', 'O'),\n",
       " ('LUCKY', 'NNP', 'O'),\n",
       " ('WIN', 'NNP', 'O'),\n",
       " (',', ',', 'O'),\n",
       " ('CHINA', 'NNP', 'B-PER'),\n",
       " ('IN', 'IN', 'O'),\n",
       " ('SURPRISE', 'DT', 'O'),\n",
       " ('DEFEAT', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff88b6",
   "metadata": {
    "papermill": {
     "duration": 0.013303,
     "end_time": "2022-10-24T04:08:02.873968",
     "exception": false,
     "start_time": "2022-10-24T04:08:02.860665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Format the data to (token, chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10c44d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:02.902568Z",
     "iopub.status.busy": "2022-10-24T04:08:02.901842Z",
     "iopub.status.idle": "2022-10-24T04:08:02.907487Z",
     "shell.execute_reply": "2022-10-24T04:08:02.906660Z"
    },
    "papermill": {
     "duration": 0.021899,
     "end_time": "2022-10-24T04:08:02.909416",
     "exception": false,
     "start_time": "2022-10-24T04:08:02.887517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_data(dataset):\n",
    "    data = []\n",
    "    label = []\n",
    "    for sentence in dataset:\n",
    "        current_data = []\n",
    "        current_label = []\n",
    "        \n",
    "        for token, _, chunk in sentence:\n",
    "            current_data.append(token.lower())\n",
    "            current_label.append(chunk)\n",
    "        \n",
    "        data.append(current_data)\n",
    "        label.append(current_label)\n",
    "\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87d37eaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:02.938214Z",
     "iopub.status.busy": "2022-10-24T04:08:02.937485Z",
     "iopub.status.idle": "2022-10-24T04:08:03.173859Z",
     "shell.execute_reply": "2022-10-24T04:08:03.172922Z"
    },
    "papermill": {
     "duration": 0.253457,
     "end_time": "2022-10-24T04:08:03.176493",
     "exception": false,
     "start_time": "2022-10-24T04:08:02.923036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = create_data(train_sentences)\n",
    "val_data, val_labels = create_data(valid_sentences)\n",
    "test_data, test_labels = create_data(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e8805a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:03.205908Z",
     "iopub.status.busy": "2022-10-24T04:08:03.205600Z",
     "iopub.status.idle": "2022-10-24T04:08:03.212247Z",
     "shell.execute_reply": "2022-10-24T04:08:03.211358Z"
    },
    "papermill": {
     "duration": 0.023504,
     "end_time": "2022-10-24T04:08:03.214306",
     "exception": false,
     "start_time": "2022-10-24T04:08:03.190802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'],\n",
       " ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0], train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a878b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:03.243264Z",
     "iopub.status.busy": "2022-10-24T04:08:03.242415Z",
     "iopub.status.idle": "2022-10-24T04:08:03.248999Z",
     "shell.execute_reply": "2022-10-24T04:08:03.248057Z"
    },
    "papermill": {
     "duration": 0.022917,
     "end_time": "2022-10-24T04:08:03.250913",
     "exception": false,
     "start_time": "2022-10-24T04:08:03.227996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cricket',\n",
       "  '-',\n",
       "  'leicestershire',\n",
       "  'take',\n",
       "  'over',\n",
       "  'at',\n",
       "  'top',\n",
       "  'after',\n",
       "  'innings',\n",
       "  'victory',\n",
       "  '.'],\n",
       " ['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[0], val_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c745f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:03.280092Z",
     "iopub.status.busy": "2022-10-24T04:08:03.279322Z",
     "iopub.status.idle": "2022-10-24T04:08:03.286167Z",
     "shell.execute_reply": "2022-10-24T04:08:03.285248Z"
    },
    "papermill": {
     "duration": 0.023579,
     "end_time": "2022-10-24T04:08:03.288165",
     "exception": false,
     "start_time": "2022-10-24T04:08:03.264586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['soccer',\n",
       "  '-',\n",
       "  'japan',\n",
       "  'get',\n",
       "  'lucky',\n",
       "  'win',\n",
       "  ',',\n",
       "  'china',\n",
       "  'in',\n",
       "  'surprise',\n",
       "  'defeat',\n",
       "  '.'],\n",
       " ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0], test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb9a21",
   "metadata": {
    "papermill": {
     "duration": 0.013565,
     "end_time": "2022-10-24T04:08:03.315512",
     "exception": false,
     "start_time": "2022-10-24T04:08:03.301947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94196468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:03.344554Z",
     "iopub.status.busy": "2022-10-24T04:08:03.343795Z",
     "iopub.status.idle": "2022-10-24T04:08:04.827826Z",
     "shell.execute_reply": "2022-10-24T04:08:04.826880Z"
    },
    "papermill": {
     "duration": 1.50095,
     "end_time": "2022-10-24T04:08:04.830219",
     "exception": false,
     "start_time": "2022-10-24T04:08:03.329269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4b32e22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:04.860840Z",
     "iopub.status.busy": "2022-10-24T04:08:04.859818Z",
     "iopub.status.idle": "2022-10-24T04:08:04.866075Z",
     "shell.execute_reply": "2022-10-24T04:08:04.865204Z"
    },
    "papermill": {
     "duration": 0.023034,
     "end_time": "2022-10-24T04:08:04.868048",
     "exception": false,
     "start_time": "2022-10-24T04:08:04.845014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConLLDataset(Dataset):\n",
    "    def __init__(self, sentences, labels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "    \n",
    "        self.length = len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10173de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:04.898881Z",
     "iopub.status.busy": "2022-10-24T04:08:04.897447Z",
     "iopub.status.idle": "2022-10-24T04:08:04.902430Z",
     "shell.execute_reply": "2022-10-24T04:08:04.901559Z"
    },
    "papermill": {
     "duration": 0.0217,
     "end_time": "2022-10-24T04:08:04.904353",
     "exception": false,
     "start_time": "2022-10-24T04:08:04.882653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ConLLDataset(train_data, train_labels)\n",
    "val_dataset = ConLLDataset(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8319d6d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:04.934389Z",
     "iopub.status.busy": "2022-10-24T04:08:04.932990Z",
     "iopub.status.idle": "2022-10-24T04:08:04.939543Z",
     "shell.execute_reply": "2022-10-24T04:08:04.938647Z"
    },
    "papermill": {
     "duration": 0.023493,
     "end_time": "2022-10-24T04:08:04.941648",
     "exception": false,
     "start_time": "2022-10-24T04:08:04.918155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'],\n",
       " ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f128b240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:04.970968Z",
     "iopub.status.busy": "2022-10-24T04:08:04.970683Z",
     "iopub.status.idle": "2022-10-24T04:08:04.976870Z",
     "shell.execute_reply": "2022-10-24T04:08:04.975745Z"
    },
    "papermill": {
     "duration": 0.023624,
     "end_time": "2022-10-24T04:08:04.979144",
     "exception": false,
     "start_time": "2022-10-24T04:08:04.955520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['cricket',\n",
       "  '-',\n",
       "  'leicestershire',\n",
       "  'take',\n",
       "  'over',\n",
       "  'at',\n",
       "  'top',\n",
       "  'after',\n",
       "  'innings',\n",
       "  'victory',\n",
       "  '.'],\n",
       " ['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658bc53",
   "metadata": {
    "papermill": {
     "duration": 0.013762,
     "end_time": "2022-10-24T04:08:05.006810",
     "exception": false,
     "start_time": "2022-10-24T04:08:04.993048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Build vocabulary from given dataset (training only!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9ddd89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.036725Z",
     "iopub.status.busy": "2022-10-24T04:08:05.035948Z",
     "iopub.status.idle": "2022-10-24T04:08:05.122406Z",
     "shell.execute_reply": "2022-10-24T04:08:05.121578Z"
    },
    "papermill": {
     "duration": 0.103344,
     "end_time": "2022-10-24T04:08:05.124489",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.021145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bc5efd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.154742Z",
     "iopub.status.busy": "2022-10-24T04:08:05.153346Z",
     "iopub.status.idle": "2022-10-24T04:08:05.158088Z",
     "shell.execute_reply": "2022-10-24T04:08:05.157261Z"
    },
    "papermill": {
     "duration": 0.021452,
     "end_time": "2022-10-24T04:08:05.160022",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.138570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for sentence, label in data_iter:\n",
    "        yield sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa29d667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.189683Z",
     "iopub.status.busy": "2022-10-24T04:08:05.188939Z",
     "iopub.status.idle": "2022-10-24T04:08:05.357059Z",
     "shell.execute_reply": "2022-10-24T04:08:05.356066Z"
    },
    "papermill": {
     "duration": 0.185584,
     "end_time": "2022-10-24T04:08:05.359522",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.173938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabulary = build_vocab_from_iterator(yield_tokens(iter(train_dataset)), specials = [\"<unk>\"])\n",
    "vocabulary.set_default_index(vocabulary[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c873ad6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.389555Z",
     "iopub.status.busy": "2022-10-24T04:08:05.389249Z",
     "iopub.status.idle": "2022-10-24T04:08:05.396086Z",
     "shell.execute_reply": "2022-10-24T04:08:05.395085Z"
    },
    "papermill": {
     "duration": 0.024182,
     "end_time": "2022-10-24T04:08:05.398279",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.374097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21010"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d17ee8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.428293Z",
     "iopub.status.busy": "2022-10-24T04:08:05.427504Z",
     "iopub.status.idle": "2022-10-24T04:08:05.433917Z",
     "shell.execute_reply": "2022-10-24T04:08:05.432963Z"
    },
    "papermill": {
     "duration": 0.023662,
     "end_time": "2022-10-24T04:08:05.435863",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.412201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1003, 18978, 204, 636, 6, 4082, 215, 6754, 2]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary(next(iter(train_dataset))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bfbb6bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.465426Z",
     "iopub.status.busy": "2022-10-24T04:08:05.464969Z",
     "iopub.status.idle": "2022-10-24T04:08:05.470817Z",
     "shell.execute_reply": "2022-10-24T04:08:05.469936Z"
    },
    "papermill": {
     "duration": 0.022713,
     "end_time": "2022-10-24T04:08:05.472811",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.450098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[292, 17, 2534, 264, 72, 18, 391, 41, 285, 311, 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary(next(iter(val_dataset))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe5a92",
   "metadata": {
    "papermill": {
     "duration": 0.014086,
     "end_time": "2022-10-24T04:08:05.501107",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.487021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Labels encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71e1b57f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.531270Z",
     "iopub.status.busy": "2022-10-24T04:08:05.530511Z",
     "iopub.status.idle": "2022-10-24T04:08:05.546325Z",
     "shell.execute_reply": "2022-10-24T04:08:05.545513Z"
    },
    "papermill": {
     "duration": 0.032784,
     "end_time": "2022-10-24T04:08:05.548278",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.515494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_labels = list({x for l in train_labels for x in l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1b841ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.578530Z",
     "iopub.status.busy": "2022-10-24T04:08:05.577757Z",
     "iopub.status.idle": "2022-10-24T04:08:05.583748Z",
     "shell.execute_reply": "2022-10-24T04:08:05.582817Z"
    },
    "papermill": {
     "duration": 0.02286,
     "end_time": "2022-10-24T04:08:05.585647",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.562787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-LOC', 'B-ORG', 'I-ORG', 'O', 'B-LOC', 'I-MISC', 'I-PER', 'B-PER', 'B-MISC']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0aee31f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.615704Z",
     "iopub.status.busy": "2022-10-24T04:08:05.614963Z",
     "iopub.status.idle": "2022-10-24T04:08:05.619865Z",
     "shell.execute_reply": "2022-10-24T04:08:05.618998Z"
    },
    "papermill": {
     "duration": 0.021921,
     "end_time": "2022-10-24T04:08:05.621835",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.599914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label2idx = {label : idx for idx, label in enumerate(unique_labels)}\n",
    "idx2label = {idx : label for idx, label in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e5e115a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.652047Z",
     "iopub.status.busy": "2022-10-24T04:08:05.651292Z",
     "iopub.status.idle": "2022-10-24T04:08:05.657303Z",
     "shell.execute_reply": "2022-10-24T04:08:05.656354Z"
    },
    "papermill": {
     "duration": 0.022971,
     "end_time": "2022-10-24T04:08:05.659178",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.636207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'B-ORG')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2idx[\"B-ORG\"], idx2label[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0675fe",
   "metadata": {
    "papermill": {
     "duration": 0.014159,
     "end_time": "2022-10-24T04:08:05.687668",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.673509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Using Seq2Seq requires similar length in both input and output. Hence we'll need a small analysis on the data length to determine the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bba9a52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.718122Z",
     "iopub.status.busy": "2022-10-24T04:08:05.717292Z",
     "iopub.status.idle": "2022-10-24T04:08:05.721771Z",
     "shell.execute_reply": "2022-10-24T04:08:05.720922Z"
    },
    "papermill": {
     "duration": 0.021586,
     "end_time": "2022-10-24T04:08:05.723644",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.702058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20fc99fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:05.753687Z",
     "iopub.status.busy": "2022-10-24T04:08:05.753166Z",
     "iopub.status.idle": "2022-10-24T04:08:05.955955Z",
     "shell.execute_reply": "2022-10-24T04:08:05.955296Z"
    },
    "papermill": {
     "duration": 0.219841,
     "end_time": "2022-10-24T04:08:05.957817",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.737976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = {\"train\" : [len(s) for s in train_data], \"val\" : [len(s) for s in val_data], \"test\" : [len(s) for s in test_data]}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.boxplot(d.values())\n",
    "ax.set_xticklabels(d.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd35685",
   "metadata": {
    "papermill": {
     "duration": 0.014428,
     "end_time": "2022-10-24T04:08:05.987153",
     "exception": false,
     "start_time": "2022-10-24T04:08:05.972725",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Except some sentences are 100-120 tokens length, we can use 64 tokens for a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b3978a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:06.018001Z",
     "iopub.status.busy": "2022-10-24T04:08:06.017158Z",
     "iopub.status.idle": "2022-10-24T04:08:06.021626Z",
     "shell.execute_reply": "2022-10-24T04:08:06.020811Z"
    },
    "papermill": {
     "duration": 0.021806,
     "end_time": "2022-10-24T04:08:06.023577",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.001771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e63d8e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:06.054400Z",
     "iopub.status.busy": "2022-10-24T04:08:06.053562Z",
     "iopub.status.idle": "2022-10-24T04:08:06.059559Z",
     "shell.execute_reply": "2022-10-24T04:08:06.058737Z"
    },
    "papermill": {
     "duration": 0.023374,
     "end_time": "2022-10-24T04:08:06.061516",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.038142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_sequence(sequence):\n",
    "    padded_sequences = np.zeros((len(sequence),), dtype = int)\n",
    "    \n",
    "    current_len = len(sequence)\n",
    "\n",
    "    if current_len <= MAX_SEQ_LENGTH:\n",
    "        zeroes = list(np.zeros(MAX_SEQ_LENGTH - current_len))\n",
    "        new = zeroes + sequence\n",
    "\n",
    "    elif current_len > MAX_SEQ_LENGTH:\n",
    "        new = sequence[0:MAX_SEQ_LENGTH]\n",
    "        \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f96cd16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:06.092189Z",
     "iopub.status.busy": "2022-10-24T04:08:06.091453Z",
     "iopub.status.idle": "2022-10-24T04:08:06.098882Z",
     "shell.execute_reply": "2022-10-24T04:08:06.097987Z"
    },
    "papermill": {
     "duration": 0.024726,
     "end_time": "2022-10-24T04:08:06.100833",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.076107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1003,\n",
       " 18978,\n",
       " 204,\n",
       " 636,\n",
       " 6,\n",
       " 4082,\n",
       " 215,\n",
       " 6754,\n",
       " 2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_sample = vocabulary(next(iter(train_dataset))[0])\n",
    "pad_sequence(vectorized_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8065558",
   "metadata": {
    "papermill": {
     "duration": 0.014504,
     "end_time": "2022-10-24T04:08:06.130093",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.115589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e73b98ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:06.161041Z",
     "iopub.status.busy": "2022-10-24T04:08:06.160448Z",
     "iopub.status.idle": "2022-10-24T04:08:06.229014Z",
     "shell.execute_reply": "2022-10-24T04:08:06.227969Z"
    },
    "papermill": {
     "duration": 0.086216,
     "end_time": "2022-10-24T04:08:06.231021",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.144805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3497aa7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:06.262393Z",
     "iopub.status.busy": "2022-10-24T04:08:06.261638Z",
     "iopub.status.idle": "2022-10-24T04:08:06.267995Z",
     "shell.execute_reply": "2022-10-24T04:08:06.267121Z"
    },
    "papermill": {
     "duration": 0.023898,
     "end_time": "2022-10-24T04:08:06.269947",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.246049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    sentences, labels = [], []\n",
    "    \n",
    "    for (sentence, label) in batch:\n",
    "        sentence_tensor = torch.tensor(vocabulary(sentence), dtype = torch.long)\n",
    "        sentences.append(sentence_tensor)\n",
    "        \n",
    "        label = torch.tensor([label2idx[l] for l in label], dtype = torch.long)\n",
    "        labels.append(label)\n",
    "    \n",
    "    \n",
    "    sentences = torch.cat(sentences)\n",
    "    labels = torch.cat(labels)\n",
    "    \n",
    "    \n",
    "    return sentences.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264cc067",
   "metadata": {
    "papermill": {
     "duration": 0.014554,
     "end_time": "2022-10-24T04:08:06.299097",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.284543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11dfbdc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:06.330251Z",
     "iopub.status.busy": "2022-10-24T04:08:06.329479Z",
     "iopub.status.idle": "2022-10-24T04:08:06.337524Z",
     "shell.execute_reply": "2022-10-24T04:08:06.336695Z"
    },
    "papermill": {
     "duration": 0.025624,
     "end_time": "2022-10-24T04:08:06.339387",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.313763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConLLPOSTagging_RNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings = self.vocab_size,\n",
    "            embedding_dim = self.embedding_dim\n",
    "        )\n",
    "        \n",
    "        self.gru = torch.nn.GRU(\n",
    "            input_size = self.embedding_dim,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers\n",
    "        )\n",
    "        \n",
    "        self.fc = torch.nn.Linear(\n",
    "            in_features = self.hidden_size,\n",
    "            out_features = self.output_dim\n",
    "        )\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embedded = self.embedding(sentence)\n",
    "        \n",
    "        rnn_output, _ = self.gru(embedded.view(len(sentence), 1, -1))\n",
    "        tag_space = self.fc(rnn_output.view(len(sentence), -1))\n",
    "        tag_scores = torch.nn.functional.log_softmax(tag_space, dim = 1)\n",
    "\n",
    "        return tag_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0190a",
   "metadata": {
    "papermill": {
     "duration": 0.014464,
     "end_time": "2022-10-24T04:08:06.368970",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.354506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68aa23ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:06.399716Z",
     "iopub.status.busy": "2022-10-24T04:08:06.399110Z",
     "iopub.status.idle": "2022-10-24T04:08:06.403730Z",
     "shell.execute_reply": "2022-10-24T04:08:06.402804Z"
    },
    "papermill": {
     "duration": 0.022004,
     "end_time": "2022-10-24T04:08:06.405660",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.383656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "learning_rate = .0001\n",
    "\n",
    "vocab_size = len(vocabulary)\n",
    "embedding_dim = 64\n",
    "hidden_size = 64\n",
    "num_layers = 4\n",
    "output_dim = len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e74f3c15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:06.437124Z",
     "iopub.status.busy": "2022-10-24T04:08:06.436240Z",
     "iopub.status.idle": "2022-10-24T04:08:10.093940Z",
     "shell.execute_reply": "2022-10-24T04:08:10.092954Z"
    },
    "papermill": {
     "duration": 3.675678,
     "end_time": "2022-10-24T04:08:10.096346",
     "exception": false,
     "start_time": "2022-10-24T04:08:06.420668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ConLLPOSTagging_RNN(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_size = hidden_size,\n",
    "    output_dim = output_dim,\n",
    "    num_layers = num_layers\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "760ddbb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:10.130110Z",
     "iopub.status.busy": "2022-10-24T04:08:10.129458Z",
     "iopub.status.idle": "2022-10-24T04:08:10.134608Z",
     "shell.execute_reply": "2022-10-24T04:08:10.133690Z"
    },
    "papermill": {
     "duration": 0.024179,
     "end_time": "2022-10-24T04:08:10.136648",
     "exception": false,
     "start_time": "2022-10-24T04:08:10.112469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2423e3f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:10.167669Z",
     "iopub.status.busy": "2022-10-24T04:08:10.166834Z",
     "iopub.status.idle": "2022-10-24T04:08:10.171981Z",
     "shell.execute_reply": "2022-10-24T04:08:10.171191Z"
    },
    "papermill": {
     "duration": 0.022672,
     "end_time": "2022-10-24T04:08:10.173874",
     "exception": false,
     "start_time": "2022-10-24T04:08:10.151202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, collate_fn = collate_batch)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = True, collate_fn = collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62afa0",
   "metadata": {
    "papermill": {
     "duration": 0.014554,
     "end_time": "2022-10-24T04:08:10.203065",
     "exception": false,
     "start_time": "2022-10-24T04:08:10.188511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3eeff701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:10.233622Z",
     "iopub.status.busy": "2022-10-24T04:08:10.233133Z",
     "iopub.status.idle": "2022-10-24T04:08:11.328270Z",
     "shell.execute_reply": "2022-10-24T04:08:11.326927Z"
    },
    "papermill": {
     "duration": 1.112683,
     "end_time": "2022-10-24T04:08:11.330366",
     "exception": false,
     "start_time": "2022-10-24T04:08:10.217683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1021, -2.2550, -2.3426,  ..., -2.1309, -2.2239, -2.1914],\n",
      "        [-2.0991, -2.2678, -2.3401,  ..., -2.1261, -2.2253, -2.1864],\n",
      "        [-2.0919, -2.2757, -2.3352,  ..., -2.1208, -2.2323, -2.1850],\n",
      "        ...,\n",
      "        [-2.0692, -2.2928, -2.3846,  ..., -2.1406, -2.2314, -2.1836],\n",
      "        [-2.0636, -2.2960, -2.3730,  ..., -2.1495, -2.2196, -2.1753],\n",
      "        [-2.0614, -2.2915, -2.3665,  ..., -2.1559, -2.2115, -2.1725]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = next(iter(train_dataloader))\n",
    "    tag_scores = model(inputs[0])\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "110de05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:11.362417Z",
     "iopub.status.busy": "2022-10-24T04:08:11.361861Z",
     "iopub.status.idle": "2022-10-24T04:08:11.367054Z",
     "shell.execute_reply": "2022-10-24T04:08:11.366218Z"
    },
    "papermill": {
     "duration": 0.023269,
     "end_time": "2022-10-24T04:08:11.369017",
     "exception": false,
     "start_time": "2022-10-24T04:08:11.345748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9ededbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:11.400366Z",
     "iopub.status.busy": "2022-10-24T04:08:11.399565Z",
     "iopub.status.idle": "2022-10-24T04:08:11.407342Z",
     "shell.execute_reply": "2022-10-24T04:08:11.406496Z"
    },
    "papermill": {
     "duration": 0.025295,
     "end_time": "2022-10-24T04:08:11.409253",
     "exception": false,
     "start_time": "2022-10-24T04:08:11.383958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    \n",
    "    total_accuracy, total_count = 0, 0\n",
    "    log_interval = 20\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for idx, (sentence, label) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tag_scores = model(sentence)\n",
    "\n",
    "        # Loss and backpropagation\n",
    "        loss = loss_fn(tag_scores, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accuracy\n",
    "        total_accuracy += (tag_scores.argmax(axis =1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        \n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "    \n",
    "            accuracy = total_accuracy / total_count\n",
    "            \n",
    "            print(f\"Epoch {epoch + 1} / {epochs} | Batch: {idx} / {len(loader)} | Training loss: {loss} | Accuracy: {accuracy}\")\n",
    "            \n",
    "            total_accuracy, total_count = 0, 0\n",
    "            \n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f00fb019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:11.440599Z",
     "iopub.status.busy": "2022-10-24T04:08:11.439827Z",
     "iopub.status.idle": "2022-10-24T04:08:11.446265Z",
     "shell.execute_reply": "2022-10-24T04:08:11.445432Z"
    },
    "papermill": {
     "duration": 0.023861,
     "end_time": "2022-10-24T04:08:11.448212",
     "exception": false,
     "start_time": "2022-10-24T04:08:11.424351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss, total_acc, total_count = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (sent, label) in enumerate(loader):\n",
    "            tag_scores = model(sent)\n",
    "            \n",
    "            loss = loss_fn(tag_scores, label)\n",
    "            \n",
    "            total_loss += loss\n",
    "            total_acc += (tag_scores.argmax(axis = 1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    \n",
    "    val_loss, val_acc = total_loss / total_count, total_acc / total_count\n",
    "    \n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59fa820f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:11.479025Z",
     "iopub.status.busy": "2022-10-24T04:08:11.478773Z",
     "iopub.status.idle": "2022-10-24T04:08:11.486380Z",
     "shell.execute_reply": "2022-10-24T04:08:11.485429Z"
    },
    "papermill": {
     "duration": 0.025508,
     "end_time": "2022-10-24T04:08:11.488380",
     "exception": false,
     "start_time": "2022-10-24T04:08:11.462872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EarlyStopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8820295e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:11.519395Z",
     "iopub.status.busy": "2022-10-24T04:08:11.518661Z",
     "iopub.status.idle": "2022-10-24T04:08:11.523018Z",
     "shell.execute_reply": "2022-10-24T04:08:11.522161Z"
    },
    "papermill": {
     "duration": 0.021964,
     "end_time": "2022-10-24T04:08:11.524983",
     "exception": false,
     "start_time": "2022-10-24T04:08:11.503019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "patience = 10\n",
    "verbose = True\n",
    "\n",
    "early_stopping = EarlyStopping(patience = patience, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ddaa9fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:08:11.557885Z",
     "iopub.status.busy": "2022-10-24T04:08:11.557032Z",
     "iopub.status.idle": "2022-10-24T04:29:47.548825Z",
     "shell.execute_reply": "2022-10-24T04:29:47.547424Z"
    },
    "papermill": {
     "duration": 1296.011375,
     "end_time": "2022-10-24T04:29:47.551019",
     "exception": false,
     "start_time": "2022-10-24T04:08:11.539644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100 | Batch: 20 / 220 | Training loss: 2.0088913440704346 | Accuracy: 0.6729775340153992\n",
      "Epoch 1 / 100 | Batch: 40 / 220 | Training loss: 1.8156338930130005 | Accuracy: 0.8338702749140894\n",
      "Epoch 1 / 100 | Batch: 60 / 220 | Training loss: 1.4519654512405396 | Accuracy: 0.8343020127004628\n",
      "Epoch 1 / 100 | Batch: 80 / 220 | Training loss: 0.9394690990447998 | Accuracy: 0.8312349316903295\n",
      "Epoch 1 / 100 | Batch: 100 / 220 | Training loss: 0.799585223197937 | Accuracy: 0.8349337481894749\n",
      "Epoch 1 / 100 | Batch: 120 / 220 | Training loss: 1.0504616498947144 | Accuracy: 0.8323936170212766\n",
      "Epoch 1 / 100 | Batch: 140 / 220 | Training loss: 0.7336740493774414 | Accuracy: 0.8266116057063178\n",
      "Epoch 1 / 100 | Batch: 160 / 220 | Training loss: 0.7137972712516785 | Accuracy: 0.8371935315597288\n",
      "Epoch 1 / 100 | Batch: 180 / 220 | Training loss: 0.8565662503242493 | Accuracy: 0.8270750449615782\n",
      "Epoch 1 / 100 | Batch: 200 / 220 | Training loss: 0.8745185136795044 | Accuracy: 0.8343299519487454\n",
      "--------------------------------------------------\n",
      "End of epoch 1 | time: 17.565647840499878 | val_loss: 0.000780 | val_acc: 0.832503\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (inf --> 0.000780).  Saving model ...\n",
      "Epoch 2 / 100 | Batch: 20 / 220 | Training loss: 0.7795458436012268 | Accuracy: 0.830794370354752\n",
      "Epoch 2 / 100 | Batch: 40 / 220 | Training loss: 0.6907321214675903 | Accuracy: 0.836134903640257\n",
      "Epoch 2 / 100 | Batch: 60 / 220 | Training loss: 0.7546195983886719 | Accuracy: 0.8335388409371147\n",
      "Epoch 2 / 100 | Batch: 80 / 220 | Training loss: 0.797819197177887 | Accuracy: 0.8359118363886828\n",
      "Epoch 2 / 100 | Batch: 100 / 220 | Training loss: 0.8327788710594177 | Accuracy: 0.8323316976346694\n",
      "Epoch 2 / 100 | Batch: 120 / 220 | Training loss: 0.7551742792129517 | Accuracy: 0.8290913213536648\n",
      "Epoch 2 / 100 | Batch: 140 / 220 | Training loss: 0.7571106553077698 | Accuracy: 0.835322942188396\n",
      "Epoch 2 / 100 | Batch: 160 / 220 | Training loss: 0.812070906162262 | Accuracy: 0.8252545374059318\n",
      "Epoch 2 / 100 | Batch: 180 / 220 | Training loss: 0.8449279069900513 | Accuracy: 0.8301979121357111\n",
      "Epoch 2 / 100 | Batch: 200 / 220 | Training loss: 0.7330679893493652 | Accuracy: 0.8377853822973594\n",
      "--------------------------------------------------\n",
      "End of epoch 2 | time: 17.277408599853516 | val_loss: 0.000769 | val_acc: 0.832503\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000780 --> 0.000769).  Saving model ...\n",
      "Epoch 3 / 100 | Batch: 20 / 220 | Training loss: 0.7177595496177673 | Accuracy: 0.8368183889423321\n",
      "Epoch 3 / 100 | Batch: 40 / 220 | Training loss: 0.7268047332763672 | Accuracy: 0.8278485110056107\n",
      "Epoch 3 / 100 | Batch: 60 / 220 | Training loss: 0.7306815385818481 | Accuracy: 0.8363626498833487\n",
      "Epoch 3 / 100 | Batch: 80 / 220 | Training loss: 0.7500883936882019 | Accuracy: 0.8313152632748279\n",
      "Epoch 3 / 100 | Batch: 100 / 220 | Training loss: 0.8835634589195251 | Accuracy: 0.8310744343644114\n",
      "Epoch 3 / 100 | Batch: 120 / 220 | Training loss: 0.8137055039405823 | Accuracy: 0.833974115990686\n",
      "Epoch 3 / 100 | Batch: 140 / 220 | Training loss: 0.880611777305603 | Accuracy: 0.8319103812061559\n",
      "Epoch 3 / 100 | Batch: 160 / 220 | Training loss: 0.8481202125549316 | Accuracy: 0.8349435958331084\n",
      "Epoch 3 / 100 | Batch: 180 / 220 | Training loss: 0.7821184396743774 | Accuracy: 0.8310864815900251\n",
      "Epoch 3 / 100 | Batch: 200 / 220 | Training loss: 0.7776975035667419 | Accuracy: 0.830613997423787\n",
      "--------------------------------------------------\n",
      "End of epoch 3 | time: 17.567548036575317 | val_loss: 0.000757 | val_acc: 0.832503\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000769 --> 0.000757).  Saving model ...\n",
      "Epoch 4 / 100 | Batch: 20 / 220 | Training loss: 0.7767046093940735 | Accuracy: 0.8286530223702998\n",
      "Epoch 4 / 100 | Batch: 40 / 220 | Training loss: 0.906276524066925 | Accuracy: 0.8323553162853298\n",
      "Epoch 4 / 100 | Batch: 60 / 220 | Training loss: 0.6703470349311829 | Accuracy: 0.8348042666089123\n",
      "Epoch 4 / 100 | Batch: 80 / 220 | Training loss: 0.6344411969184875 | Accuracy: 0.8364789766173849\n",
      "Epoch 4 / 100 | Batch: 100 / 220 | Training loss: 0.6584075689315796 | Accuracy: 0.8354229487382955\n",
      "Epoch 4 / 100 | Batch: 120 / 220 | Training loss: 0.7147331833839417 | Accuracy: 0.8298450665941832\n",
      "Epoch 4 / 100 | Batch: 140 / 220 | Training loss: 0.762267529964447 | Accuracy: 0.831625261576434\n",
      "Epoch 4 / 100 | Batch: 160 / 220 | Training loss: 0.7500965595245361 | Accuracy: 0.8322836355738951\n",
      "Epoch 4 / 100 | Batch: 180 / 220 | Training loss: 0.7987167239189148 | Accuracy: 0.8346776347417338\n",
      "Epoch 4 / 100 | Batch: 200 / 220 | Training loss: 0.7250122427940369 | Accuracy: 0.8299858864401259\n",
      "--------------------------------------------------\n",
      "End of epoch 4 | time: 16.920642614364624 | val_loss: 0.000744 | val_acc: 0.832503\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000757 --> 0.000744).  Saving model ...\n",
      "Epoch 5 / 100 | Batch: 20 / 220 | Training loss: 0.7189680933952332 | Accuracy: 0.8352431093217715\n",
      "Epoch 5 / 100 | Batch: 40 / 220 | Training loss: 0.8165906667709351 | Accuracy: 0.8293723022518071\n",
      "Epoch 5 / 100 | Batch: 60 / 220 | Training loss: 0.7991500496864319 | Accuracy: 0.8309602826249867\n",
      "Epoch 5 / 100 | Batch: 80 / 220 | Training loss: 0.7469826340675354 | Accuracy: 0.8358579052342192\n",
      "Epoch 5 / 100 | Batch: 100 / 220 | Training loss: 0.8040869832038879 | Accuracy: 0.83251953125\n",
      "Epoch 5 / 100 | Batch: 120 / 220 | Training loss: 0.710090696811676 | Accuracy: 0.8354736842105264\n",
      "Epoch 5 / 100 | Batch: 140 / 220 | Training loss: 0.8002347350120544 | Accuracy: 0.8365845858650464\n",
      "Epoch 5 / 100 | Batch: 160 / 220 | Training loss: 0.7530260682106018 | Accuracy: 0.8267095914742452\n",
      "Epoch 5 / 100 | Batch: 180 / 220 | Training loss: 0.8344916701316833 | Accuracy: 0.8308225203430833\n",
      "Epoch 5 / 100 | Batch: 200 / 220 | Training loss: 0.6826918125152588 | Accuracy: 0.8343375128914944\n",
      "--------------------------------------------------\n",
      "End of epoch 5 | time: 17.640268087387085 | val_loss: 0.000727 | val_acc: 0.832503\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000744 --> 0.000727).  Saving model ...\n",
      "Epoch 6 / 100 | Batch: 20 / 220 | Training loss: 0.6288314461708069 | Accuracy: 0.8361119531171062\n",
      "Epoch 6 / 100 | Batch: 40 / 220 | Training loss: 0.6560420989990234 | Accuracy: 0.8386787426744805\n",
      "Epoch 6 / 100 | Batch: 60 / 220 | Training loss: 0.649093508720398 | Accuracy: 0.8390860215053764\n",
      "Epoch 6 / 100 | Batch: 80 / 220 | Training loss: 0.7091434597969055 | Accuracy: 0.8215480578395237\n",
      "Epoch 6 / 100 | Batch: 100 / 220 | Training loss: 0.7030925154685974 | Accuracy: 0.8381162619573216\n",
      "Epoch 6 / 100 | Batch: 120 / 220 | Training loss: 0.7003294825553894 | Accuracy: 0.8277355302070131\n",
      "Epoch 6 / 100 | Batch: 140 / 220 | Training loss: 0.7115612030029297 | Accuracy: 0.8374429223744292\n",
      "Epoch 6 / 100 | Batch: 160 / 220 | Training loss: 0.7238113880157471 | Accuracy: 0.8348924731182795\n",
      "Epoch 6 / 100 | Batch: 180 / 220 | Training loss: 0.679915189743042 | Accuracy: 0.8261431572144127\n",
      "Epoch 6 / 100 | Batch: 200 / 220 | Training loss: 0.7500472664833069 | Accuracy: 0.8270541611624835\n",
      "--------------------------------------------------\n",
      "End of epoch 6 | time: 16.96022057533264 | val_loss: 0.000687 | val_acc: 0.832639\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000727 --> 0.000687).  Saving model ...\n",
      "Epoch 7 / 100 | Batch: 20 / 220 | Training loss: 0.5963905453681946 | Accuracy: 0.8335495925676026\n",
      "Epoch 7 / 100 | Batch: 40 / 220 | Training loss: 0.662578821182251 | Accuracy: 0.8327411432751594\n",
      "Epoch 7 / 100 | Batch: 60 / 220 | Training loss: 0.661344587802887 | Accuracy: 0.8325430230699558\n",
      "Epoch 7 / 100 | Batch: 80 / 220 | Training loss: 0.6632249355316162 | Accuracy: 0.8305592543275633\n",
      "Epoch 7 / 100 | Batch: 100 / 220 | Training loss: 0.6546266078948975 | Accuracy: 0.8253853831651325\n",
      "Epoch 7 / 100 | Batch: 120 / 220 | Training loss: 0.6827113032341003 | Accuracy: 0.8385806044013899\n",
      "Epoch 7 / 100 | Batch: 140 / 220 | Training loss: 0.6354638934135437 | Accuracy: 0.8342500528876666\n",
      "Epoch 7 / 100 | Batch: 160 / 220 | Training loss: 0.6675764322280884 | Accuracy: 0.8376793704675204\n",
      "Epoch 7 / 100 | Batch: 180 / 220 | Training loss: 0.7085743546485901 | Accuracy: 0.8451960197922898\n",
      "Epoch 7 / 100 | Batch: 200 / 220 | Training loss: 0.6231198906898499 | Accuracy: 0.8392490140532134\n",
      "--------------------------------------------------\n",
      "End of epoch 7 | time: 17.694774389266968 | val_loss: 0.000635 | val_acc: 0.834274\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000687 --> 0.000635).  Saving model ...\n",
      "Epoch 8 / 100 | Batch: 20 / 220 | Training loss: 0.6162916421890259 | Accuracy: 0.8367869148562541\n",
      "Epoch 8 / 100 | Batch: 40 / 220 | Training loss: 0.5257900953292847 | Accuracy: 0.8307598985331421\n",
      "Epoch 8 / 100 | Batch: 60 / 220 | Training loss: 0.5980082750320435 | Accuracy: 0.8428490962158841\n",
      "Epoch 8 / 100 | Batch: 80 / 220 | Training loss: 0.5943228006362915 | Accuracy: 0.8405038966584819\n",
      "Epoch 8 / 100 | Batch: 100 / 220 | Training loss: 0.6217949986457825 | Accuracy: 0.8296569322370286\n",
      "Epoch 8 / 100 | Batch: 120 / 220 | Training loss: 0.5543270111083984 | Accuracy: 0.8380379950627884\n",
      "Epoch 8 / 100 | Batch: 140 / 220 | Training loss: 0.571126401424408 | Accuracy: 0.8425906069054256\n",
      "Epoch 8 / 100 | Batch: 160 / 220 | Training loss: 0.5799230933189392 | Accuracy: 0.841669321439949\n",
      "Epoch 8 / 100 | Batch: 180 / 220 | Training loss: 0.5555984377861023 | Accuracy: 0.8410302452163179\n",
      "Epoch 8 / 100 | Batch: 200 / 220 | Training loss: 0.6616715788841248 | Accuracy: 0.8394533179647621\n",
      "--------------------------------------------------\n",
      "End of epoch 8 | time: 16.908551454544067 | val_loss: 0.000581 | val_acc: 0.842101\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000635 --> 0.000581).  Saving model ...\n",
      "Epoch 9 / 100 | Batch: 20 / 220 | Training loss: 0.636832058429718 | Accuracy: 0.8437708707937324\n",
      "Epoch 9 / 100 | Batch: 40 / 220 | Training loss: 0.5791003704071045 | Accuracy: 0.8451852238883955\n",
      "Epoch 9 / 100 | Batch: 60 / 220 | Training loss: 0.5729893445968628 | Accuracy: 0.8461156477598764\n",
      "Epoch 9 / 100 | Batch: 80 / 220 | Training loss: 0.6264245510101318 | Accuracy: 0.8450204940733356\n",
      "Epoch 9 / 100 | Batch: 100 / 220 | Training loss: 0.5860232710838318 | Accuracy: 0.8405812996983822\n",
      "Epoch 9 / 100 | Batch: 120 / 220 | Training loss: 0.5018407106399536 | Accuracy: 0.8506116123318758\n",
      "Epoch 9 / 100 | Batch: 140 / 220 | Training loss: 0.5266628265380859 | Accuracy: 0.8456197450501763\n",
      "Epoch 9 / 100 | Batch: 160 / 220 | Training loss: 0.42901647090911865 | Accuracy: 0.8516728624535316\n",
      "Epoch 9 / 100 | Batch: 180 / 220 | Training loss: 0.556979238986969 | Accuracy: 0.8491311644021003\n",
      "Epoch 9 / 100 | Batch: 200 / 220 | Training loss: 0.5593985319137573 | Accuracy: 0.8476369495166488\n",
      "--------------------------------------------------\n",
      "End of epoch 9 | time: 17.59654998779297 | val_loss: 0.000545 | val_acc: 0.847962\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000581 --> 0.000545).  Saving model ...\n",
      "Epoch 10 / 100 | Batch: 20 / 220 | Training loss: 0.454389750957489 | Accuracy: 0.851985559566787\n",
      "Epoch 10 / 100 | Batch: 40 / 220 | Training loss: 0.5810400247573853 | Accuracy: 0.8492498477550794\n",
      "Epoch 10 / 100 | Batch: 60 / 220 | Training loss: 0.5613468885421753 | Accuracy: 0.8497762625186448\n",
      "Epoch 10 / 100 | Batch: 80 / 220 | Training loss: 0.43362027406692505 | Accuracy: 0.8579045587843241\n",
      "Epoch 10 / 100 | Batch: 100 / 220 | Training loss: 0.4688888192176819 | Accuracy: 0.857999892870534\n",
      "Epoch 10 / 100 | Batch: 120 / 220 | Training loss: 0.5379626154899597 | Accuracy: 0.8531338196922094\n",
      "Epoch 10 / 100 | Batch: 140 / 220 | Training loss: 0.5450990200042725 | Accuracy: 0.8526531051555268\n",
      "Epoch 10 / 100 | Batch: 160 / 220 | Training loss: 0.524390459060669 | Accuracy: 0.8497704519055258\n",
      "Epoch 10 / 100 | Batch: 180 / 220 | Training loss: 0.5095028877258301 | Accuracy: 0.8538899430740038\n",
      "Epoch 10 / 100 | Batch: 200 / 220 | Training loss: 0.49478644132614136 | Accuracy: 0.857025382380352\n",
      "--------------------------------------------------\n",
      "End of epoch 10 | time: 17.579391479492188 | val_loss: 0.000516 | val_acc: 0.853374\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000545 --> 0.000516).  Saving model ...\n",
      "Epoch 11 / 100 | Batch: 20 / 220 | Training loss: 0.5245855450630188 | Accuracy: 0.8563076923076923\n",
      "Epoch 11 / 100 | Batch: 40 / 220 | Training loss: 0.4489506781101227 | Accuracy: 0.8576691225720027\n",
      "Epoch 11 / 100 | Batch: 60 / 220 | Training loss: 0.4741961359977722 | Accuracy: 0.8639452054794521\n",
      "Epoch 11 / 100 | Batch: 80 / 220 | Training loss: 0.5256626009941101 | Accuracy: 0.8579926867870982\n",
      "Epoch 11 / 100 | Batch: 100 / 220 | Training loss: 0.48987510800361633 | Accuracy: 0.8632850993205746\n",
      "Epoch 11 / 100 | Batch: 120 / 220 | Training loss: 0.4832431375980377 | Accuracy: 0.8650519031141869\n",
      "Epoch 11 / 100 | Batch: 140 / 220 | Training loss: 0.4320387840270996 | Accuracy: 0.8595239392123754\n",
      "Epoch 11 / 100 | Batch: 160 / 220 | Training loss: 0.3992181718349457 | Accuracy: 0.8579147274380784\n",
      "Epoch 11 / 100 | Batch: 180 / 220 | Training loss: 0.49079304933547974 | Accuracy: 0.860531106114145\n",
      "Epoch 11 / 100 | Batch: 200 / 220 | Training loss: 0.5760976076126099 | Accuracy: 0.8461580892492692\n",
      "--------------------------------------------------\n",
      "End of epoch 11 | time: 16.936886310577393 | val_loss: 0.000496 | val_acc: 0.858397\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000516 --> 0.000496).  Saving model ...\n",
      "Epoch 12 / 100 | Batch: 20 / 220 | Training loss: 0.4919505715370178 | Accuracy: 0.8650662251655629\n",
      "Epoch 12 / 100 | Batch: 40 / 220 | Training loss: 0.43371883034706116 | Accuracy: 0.8559620831165828\n",
      "Epoch 12 / 100 | Batch: 60 / 220 | Training loss: 0.47729507088661194 | Accuracy: 0.8660437800320342\n",
      "Epoch 12 / 100 | Batch: 80 / 220 | Training loss: 0.45765790343284607 | Accuracy: 0.862054306817578\n",
      "Epoch 12 / 100 | Batch: 100 / 220 | Training loss: 0.43631425499916077 | Accuracy: 0.8655703896667752\n",
      "Epoch 12 / 100 | Batch: 120 / 220 | Training loss: 0.4489595592021942 | Accuracy: 0.8630470445044187\n",
      "Epoch 12 / 100 | Batch: 140 / 220 | Training loss: 0.4710915982723236 | Accuracy: 0.8608217439585426\n",
      "Epoch 12 / 100 | Batch: 160 / 220 | Training loss: 0.39699646830558777 | Accuracy: 0.8663835347925515\n",
      "Epoch 12 / 100 | Batch: 180 / 220 | Training loss: 0.4796445071697235 | Accuracy: 0.8644213236082806\n",
      "Epoch 12 / 100 | Batch: 200 / 220 | Training loss: 0.4956839084625244 | Accuracy: 0.8631314189897297\n",
      "--------------------------------------------------\n",
      "End of epoch 12 | time: 17.610955953598022 | val_loss: 0.000478 | val_acc: 0.861766\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000496 --> 0.000478).  Saving model ...\n",
      "Epoch 13 / 100 | Batch: 20 / 220 | Training loss: 0.4404861330986023 | Accuracy: 0.8668792757574199\n",
      "Epoch 13 / 100 | Batch: 40 / 220 | Training loss: 0.5125569701194763 | Accuracy: 0.8634239592183517\n",
      "Epoch 13 / 100 | Batch: 60 / 220 | Training loss: 0.3855440318584442 | Accuracy: 0.870806487447234\n",
      "Epoch 13 / 100 | Batch: 80 / 220 | Training loss: 0.41316744685173035 | Accuracy: 0.8685970020489594\n",
      "Epoch 13 / 100 | Batch: 100 / 220 | Training loss: 0.4446302354335785 | Accuracy: 0.8719607638526558\n",
      "Epoch 13 / 100 | Batch: 120 / 220 | Training loss: 0.4709872305393219 | Accuracy: 0.8651914710779312\n",
      "Epoch 13 / 100 | Batch: 140 / 220 | Training loss: 0.4264433681964874 | Accuracy: 0.864\n",
      "Epoch 13 / 100 | Batch: 160 / 220 | Training loss: 0.48972177505493164 | Accuracy: 0.8606959805772862\n",
      "Epoch 13 / 100 | Batch: 180 / 220 | Training loss: 0.4018966257572174 | Accuracy: 0.8644344186552155\n",
      "Epoch 13 / 100 | Batch: 200 / 220 | Training loss: 0.4416170120239258 | Accuracy: 0.869721767594108\n",
      "--------------------------------------------------\n",
      "End of epoch 13 | time: 16.957111358642578 | val_loss: 0.000465 | val_acc: 0.865270\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000478 --> 0.000465).  Saving model ...\n",
      "Epoch 14 / 100 | Batch: 20 / 220 | Training loss: 0.42968252301216125 | Accuracy: 0.8724173553719008\n",
      "Epoch 14 / 100 | Batch: 40 / 220 | Training loss: 0.45502591133117676 | Accuracy: 0.8710779418720765\n",
      "Epoch 14 / 100 | Batch: 60 / 220 | Training loss: 0.41944828629493713 | Accuracy: 0.8690135521840073\n",
      "Epoch 14 / 100 | Batch: 80 / 220 | Training loss: 0.3642304241657257 | Accuracy: 0.8716658806267359\n",
      "Epoch 14 / 100 | Batch: 100 / 220 | Training loss: 0.5171579122543335 | Accuracy: 0.8702193028922556\n",
      "Epoch 14 / 100 | Batch: 120 / 220 | Training loss: 0.4049917757511139 | Accuracy: 0.8713065244599227\n",
      "Epoch 14 / 100 | Batch: 140 / 220 | Training loss: 0.47209012508392334 | Accuracy: 0.8714325297866445\n",
      "Epoch 14 / 100 | Batch: 160 / 220 | Training loss: 0.4341326951980591 | Accuracy: 0.8748386402753873\n",
      "Epoch 14 / 100 | Batch: 180 / 220 | Training loss: 0.47731661796569824 | Accuracy: 0.863936443996867\n",
      "Epoch 14 / 100 | Batch: 200 / 220 | Training loss: 0.4493395984172821 | Accuracy: 0.8701809175102304\n",
      "--------------------------------------------------\n",
      "End of epoch 14 | time: 17.580451488494873 | val_loss: 0.000454 | val_acc: 0.867022\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000465 --> 0.000454).  Saving model ...\n",
      "Epoch 15 / 100 | Batch: 20 / 220 | Training loss: 0.4318832755088806 | Accuracy: 0.8713962108731467\n",
      "Epoch 15 / 100 | Batch: 40 / 220 | Training loss: 0.40798866748809814 | Accuracy: 0.8765154424269022\n",
      "Epoch 15 / 100 | Batch: 60 / 220 | Training loss: 0.3788130581378937 | Accuracy: 0.8761576566874866\n",
      "Epoch 15 / 100 | Batch: 80 / 220 | Training loss: 0.40268659591674805 | Accuracy: 0.8702248117407794\n",
      "Epoch 15 / 100 | Batch: 100 / 220 | Training loss: 0.46468502283096313 | Accuracy: 0.874913687788814\n",
      "Epoch 15 / 100 | Batch: 120 / 220 | Training loss: 0.3740836977958679 | Accuracy: 0.8715498938428875\n",
      "Epoch 15 / 100 | Batch: 140 / 220 | Training loss: 0.36922648549079895 | Accuracy: 0.8763438013027591\n",
      "Epoch 15 / 100 | Batch: 160 / 220 | Training loss: 0.5007777214050293 | Accuracy: 0.8719488244206274\n",
      "Epoch 15 / 100 | Batch: 180 / 220 | Training loss: 0.3753979504108429 | Accuracy: 0.8720998141757367\n",
      "Epoch 15 / 100 | Batch: 200 / 220 | Training loss: 0.3023197054862976 | Accuracy: 0.8753364648757059\n",
      "--------------------------------------------------\n",
      "End of epoch 15 | time: 16.893731117248535 | val_loss: 0.000444 | val_acc: 0.869145\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000454 --> 0.000444).  Saving model ...\n",
      "Epoch 16 / 100 | Batch: 20 / 220 | Training loss: 0.34472039341926575 | Accuracy: 0.8776337520644613\n",
      "Epoch 16 / 100 | Batch: 40 / 220 | Training loss: 0.3800927698612213 | Accuracy: 0.8751418842224744\n",
      "Epoch 16 / 100 | Batch: 60 / 220 | Training loss: 0.38598620891571045 | Accuracy: 0.8834449659828069\n",
      "Epoch 16 / 100 | Batch: 80 / 220 | Training loss: 0.3199089467525482 | Accuracy: 0.8765923138941145\n",
      "Epoch 16 / 100 | Batch: 100 / 220 | Training loss: 0.40968525409698486 | Accuracy: 0.8756909131107672\n",
      "Epoch 16 / 100 | Batch: 120 / 220 | Training loss: 0.4788682460784912 | Accuracy: 0.8707086703240767\n",
      "Epoch 16 / 100 | Batch: 140 / 220 | Training loss: 0.4595494270324707 | Accuracy: 0.8747899159663866\n",
      "Epoch 16 / 100 | Batch: 160 / 220 | Training loss: 0.475616455078125 | Accuracy: 0.8799851111347442\n",
      "Epoch 16 / 100 | Batch: 180 / 220 | Training loss: 0.40438657999038696 | Accuracy: 0.8797165925193607\n",
      "Epoch 16 / 100 | Batch: 200 / 220 | Training loss: 0.3787756562232971 | Accuracy: 0.8711558854718982\n",
      "--------------------------------------------------\n",
      "End of epoch 16 | time: 17.628275156021118 | val_loss: 0.000431 | val_acc: 0.872376\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000444 --> 0.000431).  Saving model ...\n",
      "Epoch 17 / 100 | Batch: 20 / 220 | Training loss: 0.36550065875053406 | Accuracy: 0.8741655373186769\n",
      "Epoch 17 / 100 | Batch: 40 / 220 | Training loss: 0.337435245513916 | Accuracy: 0.8773530187186923\n",
      "Epoch 17 / 100 | Batch: 60 / 220 | Training loss: 0.3952653706073761 | Accuracy: 0.8794859489148403\n",
      "Epoch 17 / 100 | Batch: 80 / 220 | Training loss: 0.344422310590744 | Accuracy: 0.8827121163852607\n",
      "Epoch 17 / 100 | Batch: 100 / 220 | Training loss: 0.3392808139324188 | Accuracy: 0.8830530683555361\n",
      "Epoch 17 / 100 | Batch: 120 / 220 | Training loss: 0.4351600408554077 | Accuracy: 0.8784030991068547\n",
      "Epoch 17 / 100 | Batch: 140 / 220 | Training loss: 0.370086133480072 | Accuracy: 0.8769601930036188\n",
      "Epoch 17 / 100 | Batch: 160 / 220 | Training loss: 0.40152227878570557 | Accuracy: 0.8761696306429548\n",
      "Epoch 17 / 100 | Batch: 180 / 220 | Training loss: 0.41066083312034607 | Accuracy: 0.8794962109083146\n",
      "Epoch 17 / 100 | Batch: 200 / 220 | Training loss: 0.3594203591346741 | Accuracy: 0.8818738355070534\n",
      "--------------------------------------------------\n",
      "End of epoch 17 | time: 17.082151651382446 | val_loss: 0.000427 | val_acc: 0.874012\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000431 --> 0.000427).  Saving model ...\n",
      "Epoch 18 / 100 | Batch: 20 / 220 | Training loss: 0.3872961699962616 | Accuracy: 0.8840258064516129\n",
      "Epoch 18 / 100 | Batch: 40 / 220 | Training loss: 0.31375959515571594 | Accuracy: 0.8792125984251968\n",
      "Epoch 18 / 100 | Batch: 60 / 220 | Training loss: 0.30579686164855957 | Accuracy: 0.8816015849017257\n",
      "Epoch 18 / 100 | Batch: 80 / 220 | Training loss: 0.38849911093711853 | Accuracy: 0.8806460296096904\n",
      "Epoch 18 / 100 | Batch: 100 / 220 | Training loss: 0.41824281215667725 | Accuracy: 0.8829327721785358\n",
      "Epoch 18 / 100 | Batch: 120 / 220 | Training loss: 0.4170927107334137 | Accuracy: 0.877637821037134\n",
      "Epoch 18 / 100 | Batch: 140 / 220 | Training loss: 0.3666788637638092 | Accuracy: 0.8815768128481047\n",
      "Epoch 18 / 100 | Batch: 160 / 220 | Training loss: 0.39946529269218445 | Accuracy: 0.8819998898739057\n",
      "Epoch 18 / 100 | Batch: 180 / 220 | Training loss: 0.3965299725532532 | Accuracy: 0.8812701829924651\n",
      "Epoch 18 / 100 | Batch: 200 / 220 | Training loss: 0.35677021741867065 | Accuracy: 0.883729529846804\n",
      "--------------------------------------------------\n",
      "End of epoch 18 | time: 17.27166438102722 | val_loss: 0.000420 | val_acc: 0.875239\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000427 --> 0.000420).  Saving model ...\n",
      "Epoch 19 / 100 | Batch: 20 / 220 | Training loss: 0.36011016368865967 | Accuracy: 0.8841287800864019\n",
      "Epoch 19 / 100 | Batch: 40 / 220 | Training loss: 0.3788449466228485 | Accuracy: 0.8796045197740113\n",
      "Epoch 19 / 100 | Batch: 60 / 220 | Training loss: 0.34086504578590393 | Accuracy: 0.886420300293645\n",
      "Epoch 19 / 100 | Batch: 80 / 220 | Training loss: 0.4099730849266052 | Accuracy: 0.8814262458646221\n",
      "Epoch 19 / 100 | Batch: 100 / 220 | Training loss: 0.4059288799762726 | Accuracy: 0.8843674030229363\n",
      "Epoch 19 / 100 | Batch: 120 / 220 | Training loss: 0.37096336483955383 | Accuracy: 0.8848323576370409\n",
      "Epoch 19 / 100 | Batch: 140 / 220 | Training loss: 0.3526504337787628 | Accuracy: 0.8877782580505728\n",
      "Epoch 19 / 100 | Batch: 160 / 220 | Training loss: 0.35403984785079956 | Accuracy: 0.8842940465556198\n",
      "Epoch 19 / 100 | Batch: 180 / 220 | Training loss: 0.4036914110183716 | Accuracy: 0.8809353900203107\n",
      "Epoch 19 / 100 | Batch: 200 / 220 | Training loss: 0.33184388279914856 | Accuracy: 0.8930071789417708\n",
      "--------------------------------------------------\n",
      "End of epoch 19 | time: 17.52949619293213 | val_loss: 0.000410 | val_acc: 0.876212\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000420 --> 0.000410).  Saving model ...\n",
      "Epoch 20 / 100 | Batch: 20 / 220 | Training loss: 0.3428298830986023 | Accuracy: 0.8867210405671944\n",
      "Epoch 20 / 100 | Batch: 40 / 220 | Training loss: 0.3692031502723694 | Accuracy: 0.8864065619772273\n",
      "Epoch 20 / 100 | Batch: 60 / 220 | Training loss: 0.33581897616386414 | Accuracy: 0.8914159941305942\n",
      "Epoch 20 / 100 | Batch: 80 / 220 | Training loss: 0.36263054609298706 | Accuracy: 0.8855294983699653\n",
      "Epoch 20 / 100 | Batch: 100 / 220 | Training loss: 0.3440372347831726 | Accuracy: 0.8892025781707772\n",
      "Epoch 20 / 100 | Batch: 120 / 220 | Training loss: 0.3877755105495453 | Accuracy: 0.8813334805166133\n",
      "Epoch 20 / 100 | Batch: 140 / 220 | Training loss: 0.3633144497871399 | Accuracy: 0.8909100811502642\n",
      "Epoch 20 / 100 | Batch: 160 / 220 | Training loss: 0.3564593493938446 | Accuracy: 0.8868617137847907\n",
      "Epoch 20 / 100 | Batch: 180 / 220 | Training loss: 0.39477047324180603 | Accuracy: 0.8857948905490831\n",
      "Epoch 20 / 100 | Batch: 200 / 220 | Training loss: 0.3120599389076233 | Accuracy: 0.883900847323825\n",
      "--------------------------------------------------\n",
      "End of epoch 20 | time: 16.910481214523315 | val_loss: 0.000401 | val_acc: 0.879639\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000410 --> 0.000401).  Saving model ...\n",
      "Epoch 21 / 100 | Batch: 20 / 220 | Training loss: 0.4449828267097473 | Accuracy: 0.8897835675453892\n",
      "Epoch 21 / 100 | Batch: 40 / 220 | Training loss: 0.3409287929534912 | Accuracy: 0.8895423023578364\n",
      "Epoch 21 / 100 | Batch: 60 / 220 | Training loss: 0.330496221780777 | Accuracy: 0.8940752134938736\n",
      "Epoch 21 / 100 | Batch: 80 / 220 | Training loss: 0.3731566071510315 | Accuracy: 0.8870050491629019\n",
      "Epoch 21 / 100 | Batch: 100 / 220 | Training loss: 0.29479169845581055 | Accuracy: 0.8950784783187018\n",
      "Epoch 21 / 100 | Batch: 120 / 220 | Training loss: 0.3182365894317627 | Accuracy: 0.8889590237231076\n",
      "Epoch 21 / 100 | Batch: 140 / 220 | Training loss: 0.4049529433250427 | Accuracy: 0.887978436657682\n",
      "Epoch 21 / 100 | Batch: 160 / 220 | Training loss: 0.3364158272743225 | Accuracy: 0.8869622475856014\n",
      "Epoch 21 / 100 | Batch: 180 / 220 | Training loss: 0.3906502425670624 | Accuracy: 0.8938980217330733\n",
      "Epoch 21 / 100 | Batch: 200 / 220 | Training loss: 0.3438957631587982 | Accuracy: 0.8905326963579391\n",
      "--------------------------------------------------\n",
      "End of epoch 21 | time: 17.478116035461426 | val_loss: 0.000395 | val_acc: 0.881352\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000401 --> 0.000395).  Saving model ...\n",
      "Epoch 22 / 100 | Batch: 20 / 220 | Training loss: 0.4781186580657959 | Accuracy: 0.8888888888888888\n",
      "Epoch 22 / 100 | Batch: 40 / 220 | Training loss: 0.321964830160141 | Accuracy: 0.8921153030945316\n",
      "Epoch 22 / 100 | Batch: 60 / 220 | Training loss: 0.35058480501174927 | Accuracy: 0.8883762859263973\n",
      "Epoch 22 / 100 | Batch: 80 / 220 | Training loss: 0.3614053428173065 | Accuracy: 0.8896121362095863\n",
      "Epoch 22 / 100 | Batch: 100 / 220 | Training loss: 0.35084548592567444 | Accuracy: 0.8915486869123528\n",
      "Epoch 22 / 100 | Batch: 120 / 220 | Training loss: 0.29765409231185913 | Accuracy: 0.8922354995362034\n",
      "Epoch 22 / 100 | Batch: 140 / 220 | Training loss: 0.410359650850296 | Accuracy: 0.8921446721089906\n",
      "Epoch 22 / 100 | Batch: 160 / 220 | Training loss: 0.2940399646759033 | Accuracy: 0.8946125778063962\n",
      "Epoch 22 / 100 | Batch: 180 / 220 | Training loss: 0.24966540932655334 | Accuracy: 0.8940035367879535\n",
      "Epoch 22 / 100 | Batch: 200 / 220 | Training loss: 0.36506298184394836 | Accuracy: 0.8934993084370678\n",
      "--------------------------------------------------\n",
      "End of epoch 22 | time: 16.620091438293457 | val_loss: 0.000393 | val_acc: 0.882948\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000395 --> 0.000393).  Saving model ...\n",
      "Epoch 23 / 100 | Batch: 20 / 220 | Training loss: 0.3714938461780548 | Accuracy: 0.8911849201149136\n",
      "Epoch 23 / 100 | Batch: 40 / 220 | Training loss: 0.3425973653793335 | Accuracy: 0.8908965297337514\n",
      "Epoch 23 / 100 | Batch: 60 / 220 | Training loss: 0.37265855073928833 | Accuracy: 0.8934924196814624\n",
      "Epoch 23 / 100 | Batch: 80 / 220 | Training loss: 0.349632203578949 | Accuracy: 0.8990141075221962\n",
      "Epoch 23 / 100 | Batch: 100 / 220 | Training loss: 0.32710200548171997 | Accuracy: 0.8927819467688819\n",
      "Epoch 23 / 100 | Batch: 120 / 220 | Training loss: 0.2844248116016388 | Accuracy: 0.8982450491064241\n",
      "Epoch 23 / 100 | Batch: 140 / 220 | Training loss: 0.3325086832046509 | Accuracy: 0.8937887857652809\n",
      "Epoch 23 / 100 | Batch: 160 / 220 | Training loss: 0.3518766760826111 | Accuracy: 0.8922538675996283\n",
      "Epoch 23 / 100 | Batch: 180 / 220 | Training loss: 0.3646543025970459 | Accuracy: 0.8908274132887589\n",
      "Epoch 23 / 100 | Batch: 200 / 220 | Training loss: 0.28711172938346863 | Accuracy: 0.9034674657534246\n",
      "--------------------------------------------------\n",
      "End of epoch 23 | time: 17.303527116775513 | val_loss: 0.000384 | val_acc: 0.884603\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000393 --> 0.000384).  Saving model ...\n",
      "Epoch 24 / 100 | Batch: 20 / 220 | Training loss: 0.26160648465156555 | Accuracy: 0.8954559898315856\n",
      "Epoch 24 / 100 | Batch: 40 / 220 | Training loss: 0.3292063772678375 | Accuracy: 0.8927230565371025\n",
      "Epoch 24 / 100 | Batch: 60 / 220 | Training loss: 0.32013922929763794 | Accuracy: 0.8940529735132434\n",
      "Epoch 24 / 100 | Batch: 80 / 220 | Training loss: 0.30931371450424194 | Accuracy: 0.892891769148339\n",
      "Epoch 24 / 100 | Batch: 100 / 220 | Training loss: 0.3385533094406128 | Accuracy: 0.9015055131467345\n",
      "Epoch 24 / 100 | Batch: 120 / 220 | Training loss: 0.30224376916885376 | Accuracy: 0.8933231424359884\n",
      "Epoch 24 / 100 | Batch: 140 / 220 | Training loss: 0.3728240132331848 | Accuracy: 0.8943836465001033\n",
      "Epoch 24 / 100 | Batch: 160 / 220 | Training loss: 0.3349239230155945 | Accuracy: 0.8988196541312106\n",
      "Epoch 24 / 100 | Batch: 180 / 220 | Training loss: 0.3243197202682495 | Accuracy: 0.9020434295470309\n",
      "Epoch 24 / 100 | Batch: 200 / 220 | Training loss: 0.28506624698638916 | Accuracy: 0.8992193429469804\n",
      "--------------------------------------------------\n",
      "End of epoch 24 | time: 16.7639799118042 | val_loss: 0.000384 | val_acc: 0.886434\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 25 / 100 | Batch: 20 / 220 | Training loss: 0.2733117640018463 | Accuracy: 0.8992482720347107\n",
      "Epoch 25 / 100 | Batch: 40 / 220 | Training loss: 0.24859964847564697 | Accuracy: 0.9013657056145675\n",
      "Epoch 25 / 100 | Batch: 60 / 220 | Training loss: 0.279133141040802 | Accuracy: 0.8983951420516157\n",
      "Epoch 25 / 100 | Batch: 80 / 220 | Training loss: 0.44244447350502014 | Accuracy: 0.8952593300419387\n",
      "Epoch 25 / 100 | Batch: 100 / 220 | Training loss: 0.4081750810146332 | Accuracy: 0.8956674537367525\n",
      "Epoch 25 / 100 | Batch: 120 / 220 | Training loss: 0.3551449477672577 | Accuracy: 0.9025706803484581\n",
      "Epoch 25 / 100 | Batch: 140 / 220 | Training loss: 0.28120747208595276 | Accuracy: 0.8979944861884426\n",
      "Epoch 25 / 100 | Batch: 160 / 220 | Training loss: 0.2792053818702698 | Accuracy: 0.903593808580151\n",
      "Epoch 25 / 100 | Batch: 180 / 220 | Training loss: 0.3239898681640625 | Accuracy: 0.9001468428781204\n",
      "Epoch 25 / 100 | Batch: 200 / 220 | Training loss: 0.34096336364746094 | Accuracy: 0.9044647660032276\n",
      "--------------------------------------------------\n",
      "End of epoch 25 | time: 17.492811679840088 | val_loss: 0.000375 | val_acc: 0.887057\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000384 --> 0.000375).  Saving model ...\n",
      "Epoch 26 / 100 | Batch: 20 / 220 | Training loss: 0.2808879017829895 | Accuracy: 0.8967282656394754\n",
      "Epoch 26 / 100 | Batch: 40 / 220 | Training loss: 0.3054085969924927 | Accuracy: 0.9047872907559441\n",
      "Epoch 26 / 100 | Batch: 60 / 220 | Training loss: 0.32763704657554626 | Accuracy: 0.9032977797126687\n",
      "Epoch 26 / 100 | Batch: 80 / 220 | Training loss: 0.2725074291229248 | Accuracy: 0.9008586600384137\n",
      "Epoch 26 / 100 | Batch: 100 / 220 | Training loss: 0.3810696303844452 | Accuracy: 0.8958210396437959\n",
      "Epoch 26 / 100 | Batch: 120 / 220 | Training loss: 0.3312947750091553 | Accuracy: 0.9065868263473054\n",
      "Epoch 26 / 100 | Batch: 140 / 220 | Training loss: 0.2938505709171295 | Accuracy: 0.9022849610018675\n",
      "Epoch 26 / 100 | Batch: 160 / 220 | Training loss: 0.2615940272808075 | Accuracy: 0.9026504693539481\n",
      "Epoch 26 / 100 | Batch: 180 / 220 | Training loss: 0.3246721923351288 | Accuracy: 0.9045215220105303\n",
      "Epoch 26 / 100 | Batch: 200 / 220 | Training loss: 0.4303987920284271 | Accuracy: 0.9009762148751416\n",
      "--------------------------------------------------\n",
      "End of epoch 26 | time: 17.041027069091797 | val_loss: 0.000369 | val_acc: 0.889179\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000375 --> 0.000369).  Saving model ...\n",
      "Epoch 27 / 100 | Batch: 20 / 220 | Training loss: 0.36498892307281494 | Accuracy: 0.9001859888406696\n",
      "Epoch 27 / 100 | Batch: 40 / 220 | Training loss: 0.24797400832176208 | Accuracy: 0.905391286176993\n",
      "Epoch 27 / 100 | Batch: 60 / 220 | Training loss: 0.27664878964424133 | Accuracy: 0.9052846841028953\n",
      "Epoch 27 / 100 | Batch: 80 / 220 | Training loss: 0.3822039067745209 | Accuracy: 0.9048837589154461\n",
      "Epoch 27 / 100 | Batch: 100 / 220 | Training loss: 0.32727673649787903 | Accuracy: 0.902958267300581\n",
      "Epoch 27 / 100 | Batch: 120 / 220 | Training loss: 0.3001684546470642 | Accuracy: 0.9045237179134832\n",
      "Epoch 27 / 100 | Batch: 140 / 220 | Training loss: 0.3622628450393677 | Accuracy: 0.9002127897860903\n",
      "Epoch 27 / 100 | Batch: 160 / 220 | Training loss: 0.2665724456310272 | Accuracy: 0.9037740828714701\n",
      "Epoch 27 / 100 | Batch: 180 / 220 | Training loss: 0.30925557017326355 | Accuracy: 0.9031696640472548\n",
      "Epoch 27 / 100 | Batch: 200 / 220 | Training loss: 0.24911515414714813 | Accuracy: 0.9056675335934113\n",
      "--------------------------------------------------\n",
      "End of epoch 27 | time: 17.582212448120117 | val_loss: 0.000367 | val_acc: 0.890405\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000369 --> 0.000367).  Saving model ...\n",
      "Epoch 28 / 100 | Batch: 20 / 220 | Training loss: 0.3053124248981476 | Accuracy: 0.9046646772420293\n",
      "Epoch 28 / 100 | Batch: 40 / 220 | Training loss: 0.2973332703113556 | Accuracy: 0.9016892827471614\n",
      "Epoch 28 / 100 | Batch: 60 / 220 | Training loss: 0.31346607208251953 | Accuracy: 0.9059545800282517\n",
      "Epoch 28 / 100 | Batch: 80 / 220 | Training loss: 0.2711910009384155 | Accuracy: 0.9042135427722352\n",
      "Epoch 28 / 100 | Batch: 100 / 220 | Training loss: 0.29438281059265137 | Accuracy: 0.9054213002566296\n",
      "Epoch 28 / 100 | Batch: 120 / 220 | Training loss: 0.26636579632759094 | Accuracy: 0.9065494784772595\n",
      "Epoch 28 / 100 | Batch: 140 / 220 | Training loss: 0.30122464895248413 | Accuracy: 0.9041896361631753\n",
      "Epoch 28 / 100 | Batch: 160 / 220 | Training loss: 0.28563570976257324 | Accuracy: 0.9081611022787494\n",
      "Epoch 28 / 100 | Batch: 180 / 220 | Training loss: 0.2927769720554352 | Accuracy: 0.9109993439755084\n",
      "Epoch 28 / 100 | Batch: 200 / 220 | Training loss: 0.3358544409275055 | Accuracy: 0.9063805043082941\n",
      "--------------------------------------------------\n",
      "End of epoch 28 | time: 16.949042558670044 | val_loss: 0.000361 | val_acc: 0.891243\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000367 --> 0.000361).  Saving model ...\n",
      "Epoch 29 / 100 | Batch: 20 / 220 | Training loss: 0.28020402789115906 | Accuracy: 0.9062862567239742\n",
      "Epoch 29 / 100 | Batch: 40 / 220 | Training loss: 0.3672808110713959 | Accuracy: 0.9109739737053931\n",
      "Epoch 29 / 100 | Batch: 60 / 220 | Training loss: 0.3250267505645752 | Accuracy: 0.9076776144744522\n",
      "Epoch 29 / 100 | Batch: 80 / 220 | Training loss: 0.2341981679201126 | Accuracy: 0.9057908847184987\n",
      "Epoch 29 / 100 | Batch: 100 / 220 | Training loss: 0.27468767762184143 | Accuracy: 0.9108701695857659\n",
      "Epoch 29 / 100 | Batch: 120 / 220 | Training loss: 0.24317993223667145 | Accuracy: 0.9073554491940364\n",
      "Epoch 29 / 100 | Batch: 140 / 220 | Training loss: 0.27241700887680054 | Accuracy: 0.905939788445891\n",
      "Epoch 29 / 100 | Batch: 160 / 220 | Training loss: 0.28424811363220215 | Accuracy: 0.9081166358394082\n",
      "Epoch 29 / 100 | Batch: 180 / 220 | Training loss: 0.2963361442089081 | Accuracy: 0.9091685345287651\n",
      "Epoch 29 / 100 | Batch: 200 / 220 | Training loss: 0.2868340313434601 | Accuracy: 0.9073300616059309\n",
      "--------------------------------------------------\n",
      "End of epoch 29 | time: 17.64457607269287 | val_loss: 0.000358 | val_acc: 0.892274\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000361 --> 0.000358).  Saving model ...\n",
      "Epoch 30 / 100 | Batch: 20 / 220 | Training loss: 0.2754714787006378 | Accuracy: 0.9098923628908252\n",
      "Epoch 30 / 100 | Batch: 40 / 220 | Training loss: 0.23399309813976288 | Accuracy: 0.9087430241828328\n",
      "Epoch 30 / 100 | Batch: 60 / 220 | Training loss: 0.2525273859500885 | Accuracy: 0.9143804960244326\n",
      "Epoch 30 / 100 | Batch: 80 / 220 | Training loss: 0.2914140820503235 | Accuracy: 0.9100610565436688\n",
      "Epoch 30 / 100 | Batch: 100 / 220 | Training loss: 0.27821585536003113 | Accuracy: 0.9047514055782163\n",
      "Epoch 30 / 100 | Batch: 120 / 220 | Training loss: 0.224431574344635 | Accuracy: 0.9107877082882493\n",
      "Epoch 30 / 100 | Batch: 140 / 220 | Training loss: 0.30514615774154663 | Accuracy: 0.9116511103958803\n",
      "Epoch 30 / 100 | Batch: 160 / 220 | Training loss: 0.25600484013557434 | Accuracy: 0.9109351269255804\n",
      "Epoch 30 / 100 | Batch: 180 / 220 | Training loss: 0.24517084658145905 | Accuracy: 0.9082072844427456\n",
      "Epoch 30 / 100 | Batch: 200 / 220 | Training loss: 0.3175547420978546 | Accuracy: 0.9091682168482593\n",
      "--------------------------------------------------\n",
      "End of epoch 30 | time: 17.391479015350342 | val_loss: 0.000354 | val_acc: 0.893326\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000358 --> 0.000354).  Saving model ...\n",
      "Epoch 31 / 100 | Batch: 20 / 220 | Training loss: 0.30663561820983887 | Accuracy: 0.9080594879133235\n",
      "Epoch 31 / 100 | Batch: 40 / 220 | Training loss: 0.26557230949401855 | Accuracy: 0.9105166051660517\n",
      "Epoch 31 / 100 | Batch: 60 / 220 | Training loss: 0.3187750577926636 | Accuracy: 0.9093494864366605\n",
      "Epoch 31 / 100 | Batch: 80 / 220 | Training loss: 0.2331359088420868 | Accuracy: 0.9140779554082232\n",
      "Epoch 31 / 100 | Batch: 100 / 220 | Training loss: 0.2613855302333832 | Accuracy: 0.9148477357597433\n",
      "Epoch 31 / 100 | Batch: 120 / 220 | Training loss: 0.2620055079460144 | Accuracy: 0.9091708819001539\n",
      "Epoch 31 / 100 | Batch: 140 / 220 | Training loss: 0.22933508455753326 | Accuracy: 0.9123947972456006\n",
      "Epoch 31 / 100 | Batch: 160 / 220 | Training loss: 0.30860623717308044 | Accuracy: 0.9131871590432228\n",
      "Epoch 31 / 100 | Batch: 180 / 220 | Training loss: 0.2925998270511627 | Accuracy: 0.9151846045732202\n",
      "Epoch 31 / 100 | Batch: 200 / 220 | Training loss: 0.25625449419021606 | Accuracy: 0.9092709766162311\n",
      "--------------------------------------------------\n",
      "End of epoch 31 | time: 17.071807384490967 | val_loss: 0.000348 | val_acc: 0.895136\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000354 --> 0.000348).  Saving model ...\n",
      "Epoch 32 / 100 | Batch: 20 / 220 | Training loss: 0.277608186006546 | Accuracy: 0.9113680154142582\n",
      "Epoch 32 / 100 | Batch: 40 / 220 | Training loss: 0.2753484845161438 | Accuracy: 0.9106596767147226\n",
      "Epoch 32 / 100 | Batch: 60 / 220 | Training loss: 0.21137289702892303 | Accuracy: 0.9173549228428602\n",
      "Epoch 32 / 100 | Batch: 80 / 220 | Training loss: 0.30766794085502625 | Accuracy: 0.9175074494223431\n",
      "Epoch 32 / 100 | Batch: 100 / 220 | Training loss: 0.26416611671447754 | Accuracy: 0.9126494300806227\n",
      "Epoch 32 / 100 | Batch: 120 / 220 | Training loss: 0.36299261450767517 | Accuracy: 0.9123260227752004\n",
      "Epoch 32 / 100 | Batch: 140 / 220 | Training loss: 0.2921898066997528 | Accuracy: 0.9177811883358913\n",
      "Epoch 32 / 100 | Batch: 160 / 220 | Training loss: 0.23100686073303223 | Accuracy: 0.9139112792674233\n",
      "Epoch 32 / 100 | Batch: 180 / 220 | Training loss: 0.2126564085483551 | Accuracy: 0.9142339771729587\n",
      "Epoch 32 / 100 | Batch: 200 / 220 | Training loss: 0.2762524485588074 | Accuracy: 0.9118296954998653\n",
      "--------------------------------------------------\n",
      "End of epoch 32 | time: 17.447691440582275 | val_loss: 0.000350 | val_acc: 0.895915\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 33 / 100 | Batch: 20 / 220 | Training loss: 0.3135874569416046 | Accuracy: 0.916721410884835\n",
      "Epoch 33 / 100 | Batch: 40 / 220 | Training loss: 0.30281078815460205 | Accuracy: 0.9162964945143163\n",
      "Epoch 33 / 100 | Batch: 60 / 220 | Training loss: 0.27269867062568665 | Accuracy: 0.9136348915038325\n",
      "Epoch 33 / 100 | Batch: 80 / 220 | Training loss: 0.31062597036361694 | Accuracy: 0.9139181159025241\n",
      "Epoch 33 / 100 | Batch: 100 / 220 | Training loss: 0.2129136621952057 | Accuracy: 0.9170484557753463\n",
      "Epoch 33 / 100 | Batch: 120 / 220 | Training loss: 0.2974674105644226 | Accuracy: 0.9105302305812347\n",
      "Epoch 33 / 100 | Batch: 140 / 220 | Training loss: 0.22813229262828827 | Accuracy: 0.9162188306104901\n",
      "Epoch 33 / 100 | Batch: 160 / 220 | Training loss: 0.23762552440166473 | Accuracy: 0.9153392001782332\n",
      "Epoch 33 / 100 | Batch: 180 / 220 | Training loss: 0.2999995946884155 | Accuracy: 0.914150994526042\n",
      "Epoch 33 / 100 | Batch: 200 / 220 | Training loss: 0.22615066170692444 | Accuracy: 0.9189072454378577\n",
      "--------------------------------------------------\n",
      "End of epoch 33 | time: 17.01290011405945 | val_loss: 0.000345 | val_acc: 0.896519\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000348 --> 0.000345).  Saving model ...\n",
      "Epoch 34 / 100 | Batch: 20 / 220 | Training loss: 0.23615384101867676 | Accuracy: 0.9175003928552721\n",
      "Epoch 34 / 100 | Batch: 40 / 220 | Training loss: 0.24404621124267578 | Accuracy: 0.9146348236600944\n",
      "Epoch 34 / 100 | Batch: 60 / 220 | Training loss: 0.24228549003601074 | Accuracy: 0.9146827534202305\n",
      "Epoch 34 / 100 | Batch: 80 / 220 | Training loss: 0.24710214138031006 | Accuracy: 0.9176701501246618\n",
      "Epoch 34 / 100 | Batch: 100 / 220 | Training loss: 0.3593446910381317 | Accuracy: 0.9168164732799478\n",
      "Epoch 34 / 100 | Batch: 120 / 220 | Training loss: 0.25458067655563354 | Accuracy: 0.9216721207642774\n",
      "Epoch 34 / 100 | Batch: 140 / 220 | Training loss: 0.28082120418548584 | Accuracy: 0.9152118373429848\n",
      "Epoch 34 / 100 | Batch: 160 / 220 | Training loss: 0.2610671818256378 | Accuracy: 0.9145755190448518\n",
      "Epoch 34 / 100 | Batch: 180 / 220 | Training loss: 0.2920664846897125 | Accuracy: 0.919710003787264\n",
      "Epoch 34 / 100 | Batch: 200 / 220 | Training loss: 0.24145153164863586 | Accuracy: 0.9186674509384525\n",
      "--------------------------------------------------\n",
      "End of epoch 34 | time: 17.64609408378601 | val_loss: 0.000343 | val_acc: 0.898505\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000345 --> 0.000343).  Saving model ...\n",
      "Epoch 35 / 100 | Batch: 20 / 220 | Training loss: 0.2618294656276703 | Accuracy: 0.919204694930689\n",
      "Epoch 35 / 100 | Batch: 40 / 220 | Training loss: 0.31275829672813416 | Accuracy: 0.917949273791459\n",
      "Epoch 35 / 100 | Batch: 60 / 220 | Training loss: 0.2208380103111267 | Accuracy: 0.922086901026432\n",
      "Epoch 35 / 100 | Batch: 80 / 220 | Training loss: 0.22549425065517426 | Accuracy: 0.9188154061926853\n",
      "Epoch 35 / 100 | Batch: 100 / 220 | Training loss: 0.2472318559885025 | Accuracy: 0.920843504908326\n",
      "Epoch 35 / 100 | Batch: 120 / 220 | Training loss: 0.22469758987426758 | Accuracy: 0.9169309854533523\n",
      "Epoch 35 / 100 | Batch: 140 / 220 | Training loss: 0.32019561529159546 | Accuracy: 0.9210470312832517\n",
      "Epoch 35 / 100 | Batch: 160 / 220 | Training loss: 0.2560691833496094 | Accuracy: 0.925534795559166\n",
      "Epoch 35 / 100 | Batch: 180 / 220 | Training loss: 0.2117282748222351 | Accuracy: 0.915608581436077\n",
      "Epoch 35 / 100 | Batch: 200 / 220 | Training loss: 0.18787899613380432 | Accuracy: 0.9182280002184957\n",
      "--------------------------------------------------\n",
      "End of epoch 35 | time: 16.941503047943115 | val_loss: 0.000342 | val_acc: 0.898232\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000343 --> 0.000342).  Saving model ...\n",
      "Epoch 36 / 100 | Batch: 20 / 220 | Training loss: 0.2817051112651825 | Accuracy: 0.920809340165883\n",
      "Epoch 36 / 100 | Batch: 40 / 220 | Training loss: 0.2972073554992676 | Accuracy: 0.9240760869565218\n",
      "Epoch 36 / 100 | Batch: 60 / 220 | Training loss: 0.19659289717674255 | Accuracy: 0.9236895528603404\n",
      "Epoch 36 / 100 | Batch: 80 / 220 | Training loss: 0.2466576248407364 | Accuracy: 0.9176477121279432\n",
      "Epoch 36 / 100 | Batch: 100 / 220 | Training loss: 0.25784116983413696 | Accuracy: 0.9232141919907626\n",
      "Epoch 36 / 100 | Batch: 120 / 220 | Training loss: 0.248000830411911 | Accuracy: 0.9245925693025205\n",
      "Epoch 36 / 100 | Batch: 140 / 220 | Training loss: 0.2750776708126068 | Accuracy: 0.9213458716095015\n",
      "Epoch 36 / 100 | Batch: 160 / 220 | Training loss: 0.21140539646148682 | Accuracy: 0.9148289393688167\n",
      "Epoch 36 / 100 | Batch: 180 / 220 | Training loss: 0.2787410020828247 | Accuracy: 0.924017513882956\n",
      "Epoch 36 / 100 | Batch: 200 / 220 | Training loss: 0.2950478494167328 | Accuracy: 0.9224086764150434\n",
      "--------------------------------------------------\n",
      "End of epoch 36 | time: 17.67182469367981 | val_loss: 0.000338 | val_acc: 0.898232\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000342 --> 0.000338).  Saving model ...\n",
      "Epoch 37 / 100 | Batch: 20 / 220 | Training loss: 0.24141445755958557 | Accuracy: 0.9246515455433832\n",
      "Epoch 37 / 100 | Batch: 40 / 220 | Training loss: 0.22654031217098236 | Accuracy: 0.917907618996047\n",
      "Epoch 37 / 100 | Batch: 60 / 220 | Training loss: 0.28253355622291565 | Accuracy: 0.925794482981126\n",
      "Epoch 37 / 100 | Batch: 80 / 220 | Training loss: 0.22627389430999756 | Accuracy: 0.926790450928382\n",
      "Epoch 37 / 100 | Batch: 100 / 220 | Training loss: 0.21593396365642548 | Accuracy: 0.919639969817829\n",
      "Epoch 37 / 100 | Batch: 120 / 220 | Training loss: 0.23449821770191193 | Accuracy: 0.9241879166225796\n",
      "Epoch 37 / 100 | Batch: 140 / 220 | Training loss: 0.25716325640678406 | Accuracy: 0.9183879093198992\n",
      "Epoch 37 / 100 | Batch: 160 / 220 | Training loss: 0.30093759298324585 | Accuracy: 0.9233327968238639\n",
      "Epoch 37 / 100 | Batch: 180 / 220 | Training loss: 0.2012535035610199 | Accuracy: 0.9274642506276607\n",
      "Epoch 37 / 100 | Batch: 200 / 220 | Training loss: 0.27007758617401123 | Accuracy: 0.9182866908780175\n",
      "--------------------------------------------------\n",
      "End of epoch 37 | time: 17.004583597183228 | val_loss: 0.000335 | val_acc: 0.900413\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000338 --> 0.000335).  Saving model ...\n",
      "Epoch 38 / 100 | Batch: 20 / 220 | Training loss: 0.2279529571533203 | Accuracy: 0.9210055748395919\n",
      "Epoch 38 / 100 | Batch: 40 / 220 | Training loss: 0.21592171490192413 | Accuracy: 0.9254817987152034\n",
      "Epoch 38 / 100 | Batch: 60 / 220 | Training loss: 0.21901017427444458 | Accuracy: 0.9247831887925283\n",
      "Epoch 38 / 100 | Batch: 80 / 220 | Training loss: 0.19724898040294647 | Accuracy: 0.9267479980652442\n",
      "Epoch 38 / 100 | Batch: 100 / 220 | Training loss: 0.27632221579551697 | Accuracy: 0.926838158716934\n",
      "Epoch 38 / 100 | Batch: 120 / 220 | Training loss: 0.27934443950653076 | Accuracy: 0.9224035447962823\n",
      "Epoch 38 / 100 | Batch: 140 / 220 | Training loss: 0.2145732045173645 | Accuracy: 0.9256507592190889\n",
      "Epoch 38 / 100 | Batch: 160 / 220 | Training loss: 0.1695692092180252 | Accuracy: 0.9276643031008572\n",
      "Epoch 38 / 100 | Batch: 180 / 220 | Training loss: 0.20651811361312866 | Accuracy: 0.9227882037533512\n",
      "Epoch 38 / 100 | Batch: 200 / 220 | Training loss: 0.2004857212305069 | Accuracy: 0.9283540654529924\n",
      "--------------------------------------------------\n",
      "End of epoch 38 | time: 17.59723424911499 | val_loss: 0.000331 | val_acc: 0.901854\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000335 --> 0.000331).  Saving model ...\n",
      "Epoch 39 / 100 | Batch: 20 / 220 | Training loss: 0.2477957010269165 | Accuracy: 0.92650523888304\n",
      "Epoch 39 / 100 | Batch: 40 / 220 | Training loss: 0.29259684681892395 | Accuracy: 0.9228058399060245\n",
      "Epoch 39 / 100 | Batch: 60 / 220 | Training loss: 0.1750258505344391 | Accuracy: 0.9272352568167407\n",
      "Epoch 39 / 100 | Batch: 80 / 220 | Training loss: 0.23135027289390564 | Accuracy: 0.9240088105726872\n",
      "Epoch 39 / 100 | Batch: 100 / 220 | Training loss: 0.25691211223602295 | Accuracy: 0.9243999142734677\n",
      "Epoch 39 / 100 | Batch: 120 / 220 | Training loss: 0.22201988101005554 | Accuracy: 0.9309320460453027\n",
      "Epoch 39 / 100 | Batch: 140 / 220 | Training loss: 0.20704743266105652 | Accuracy: 0.9272351594348579\n",
      "Epoch 39 / 100 | Batch: 160 / 220 | Training loss: 0.20997653901576996 | Accuracy: 0.9302983401825266\n",
      "Epoch 39 / 100 | Batch: 180 / 220 | Training loss: 0.2496364414691925 | Accuracy: 0.9262450550046063\n",
      "Epoch 39 / 100 | Batch: 200 / 220 | Training loss: 0.23016563057899475 | Accuracy: 0.9235144041671096\n",
      "--------------------------------------------------\n",
      "End of epoch 39 | time: 17.49751114845276 | val_loss: 0.000329 | val_acc: 0.902730\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000331 --> 0.000329).  Saving model ...\n",
      "Epoch 40 / 100 | Batch: 20 / 220 | Training loss: 0.2420770227909088 | Accuracy: 0.9282898348220969\n",
      "Epoch 40 / 100 | Batch: 40 / 220 | Training loss: 0.3010379374027252 | Accuracy: 0.9269265542732543\n",
      "Epoch 40 / 100 | Batch: 60 / 220 | Training loss: 0.2623756527900696 | Accuracy: 0.9283634565730924\n",
      "Epoch 40 / 100 | Batch: 80 / 220 | Training loss: 0.22411707043647766 | Accuracy: 0.9256535509152397\n",
      "Epoch 40 / 100 | Batch: 100 / 220 | Training loss: 0.2135758101940155 | Accuracy: 0.927958555933301\n",
      "Epoch 40 / 100 | Batch: 120 / 220 | Training loss: 0.20027372241020203 | Accuracy: 0.9290596910490339\n",
      "Epoch 40 / 100 | Batch: 140 / 220 | Training loss: 0.19516319036483765 | Accuracy: 0.9304660652920962\n",
      "Epoch 40 / 100 | Batch: 160 / 220 | Training loss: 0.24977155029773712 | Accuracy: 0.9281776913099871\n",
      "Epoch 40 / 100 | Batch: 180 / 220 | Training loss: 0.16358248889446259 | Accuracy: 0.9291028682337719\n",
      "Epoch 40 / 100 | Batch: 200 / 220 | Training loss: 0.229684516787529 | Accuracy: 0.9299523676099748\n",
      "--------------------------------------------------\n",
      "End of epoch 40 | time: 17.100372314453125 | val_loss: 0.000329 | val_acc: 0.903450\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000329 --> 0.000329).  Saving model ...\n",
      "Epoch 41 / 100 | Batch: 20 / 220 | Training loss: 0.19679103791713715 | Accuracy: 0.9319277108433734\n",
      "Epoch 41 / 100 | Batch: 40 / 220 | Training loss: 0.2792389392852783 | Accuracy: 0.9287611559711008\n",
      "Epoch 41 / 100 | Batch: 60 / 220 | Training loss: 0.24543817341327667 | Accuracy: 0.9266745511235351\n",
      "Epoch 41 / 100 | Batch: 80 / 220 | Training loss: 0.21308447420597076 | Accuracy: 0.9309355692850838\n",
      "Epoch 41 / 100 | Batch: 100 / 220 | Training loss: 0.281197726726532 | Accuracy: 0.9304123711340206\n",
      "Epoch 41 / 100 | Batch: 120 / 220 | Training loss: 0.1513519585132599 | Accuracy: 0.9349904397705545\n",
      "Epoch 41 / 100 | Batch: 140 / 220 | Training loss: 0.2357933074235916 | Accuracy: 0.9271504931944674\n",
      "Epoch 41 / 100 | Batch: 160 / 220 | Training loss: 0.3365823030471802 | Accuracy: 0.9264666559709075\n",
      "Epoch 41 / 100 | Batch: 180 / 220 | Training loss: 0.20972047746181488 | Accuracy: 0.9319641916798315\n",
      "Epoch 41 / 100 | Batch: 200 / 220 | Training loss: 0.23824597895145416 | Accuracy: 0.9274104985723699\n",
      "--------------------------------------------------\n",
      "End of epoch 41 | time: 17.61469554901123 | val_loss: 0.000331 | val_acc: 0.902808\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 42 / 100 | Batch: 20 / 220 | Training loss: 0.2822737395763397 | Accuracy: 0.9304826862539349\n",
      "Epoch 42 / 100 | Batch: 40 / 220 | Training loss: 0.25648075342178345 | Accuracy: 0.935174193548387\n",
      "Epoch 42 / 100 | Batch: 60 / 220 | Training loss: 0.17451687157154083 | Accuracy: 0.9367074829931973\n",
      "Epoch 42 / 100 | Batch: 80 / 220 | Training loss: 0.22313378751277924 | Accuracy: 0.9305416380992564\n",
      "Epoch 42 / 100 | Batch: 100 / 220 | Training loss: 0.21326413750648499 | Accuracy: 0.9296866921724745\n",
      "Epoch 42 / 100 | Batch: 120 / 220 | Training loss: 0.18094947934150696 | Accuracy: 0.929721496953873\n",
      "Epoch 42 / 100 | Batch: 140 / 220 | Training loss: 0.23446610569953918 | Accuracy: 0.9351387872304487\n",
      "Epoch 42 / 100 | Batch: 160 / 220 | Training loss: 0.2514396905899048 | Accuracy: 0.929419525065963\n",
      "Epoch 42 / 100 | Batch: 180 / 220 | Training loss: 0.23552455008029938 | Accuracy: 0.9320809248554913\n",
      "Epoch 42 / 100 | Batch: 200 / 220 | Training loss: 0.1550282984972 | Accuracy: 0.9297998155482016\n",
      "--------------------------------------------------\n",
      "End of epoch 42 | time: 16.809913396835327 | val_loss: 0.000328 | val_acc: 0.903956\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000329 --> 0.000328).  Saving model ...\n",
      "Epoch 43 / 100 | Batch: 20 / 220 | Training loss: 0.26684823632240295 | Accuracy: 0.9332442571560717\n",
      "Epoch 43 / 100 | Batch: 40 / 220 | Training loss: 0.16959848999977112 | Accuracy: 0.934028725902463\n",
      "Epoch 43 / 100 | Batch: 60 / 220 | Training loss: 0.14913813769817352 | Accuracy: 0.9338931379365674\n",
      "Epoch 43 / 100 | Batch: 80 / 220 | Training loss: 0.20240193605422974 | Accuracy: 0.9317062611613183\n",
      "Epoch 43 / 100 | Batch: 100 / 220 | Training loss: 0.19807931780815125 | Accuracy: 0.933083511777302\n",
      "Epoch 43 / 100 | Batch: 120 / 220 | Training loss: 0.2544013559818268 | Accuracy: 0.9307775377969763\n",
      "Epoch 43 / 100 | Batch: 140 / 220 | Training loss: 0.2108415961265564 | Accuracy: 0.9300136712588074\n",
      "Epoch 43 / 100 | Batch: 160 / 220 | Training loss: 0.22499430179595947 | Accuracy: 0.9342655861009588\n",
      "Epoch 43 / 100 | Batch: 180 / 220 | Training loss: 0.23439964652061462 | Accuracy: 0.9311232876712329\n",
      "Epoch 43 / 100 | Batch: 200 / 220 | Training loss: 0.2095460593700409 | Accuracy: 0.928924802110818\n",
      "--------------------------------------------------\n",
      "End of epoch 43 | time: 17.535958766937256 | val_loss: 0.000325 | val_acc: 0.905124\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000328 --> 0.000325).  Saving model ...\n",
      "Epoch 44 / 100 | Batch: 20 / 220 | Training loss: 0.18484847247600555 | Accuracy: 0.9347021731200167\n",
      "Epoch 44 / 100 | Batch: 40 / 220 | Training loss: 0.15996220707893372 | Accuracy: 0.933151001946037\n",
      "Epoch 44 / 100 | Batch: 60 / 220 | Training loss: 0.2828107178211212 | Accuracy: 0.9309257973182328\n",
      "Epoch 44 / 100 | Batch: 80 / 220 | Training loss: 0.24425406754016876 | Accuracy: 0.9310025089996727\n",
      "Epoch 44 / 100 | Batch: 100 / 220 | Training loss: 0.19369979202747345 | Accuracy: 0.9344646296392691\n",
      "Epoch 44 / 100 | Batch: 120 / 220 | Training loss: 0.20452678203582764 | Accuracy: 0.9363466721957288\n",
      "Epoch 44 / 100 | Batch: 140 / 220 | Training loss: 0.20742639899253845 | Accuracy: 0.9336511497476164\n",
      "Epoch 44 / 100 | Batch: 160 / 220 | Training loss: 0.24750445783138275 | Accuracy: 0.9344855967078189\n",
      "Epoch 44 / 100 | Batch: 180 / 220 | Training loss: 0.22680452466011047 | Accuracy: 0.9344484139872253\n",
      "Epoch 44 / 100 | Batch: 200 / 220 | Training loss: 0.24031859636306763 | Accuracy: 0.9336553261504167\n",
      "--------------------------------------------------\n",
      "End of epoch 44 | time: 17.023256063461304 | val_loss: 0.000323 | val_acc: 0.907247\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000325 --> 0.000323).  Saving model ...\n",
      "Epoch 45 / 100 | Batch: 20 / 220 | Training loss: 0.1930903196334839 | Accuracy: 0.938369377601787\n",
      "Epoch 45 / 100 | Batch: 40 / 220 | Training loss: 0.22388209402561188 | Accuracy: 0.9375066425762568\n",
      "Epoch 45 / 100 | Batch: 60 / 220 | Training loss: 0.1899760216474533 | Accuracy: 0.9355084699602375\n",
      "Epoch 45 / 100 | Batch: 80 / 220 | Training loss: 0.2344670444726944 | Accuracy: 0.934354600968625\n",
      "Epoch 45 / 100 | Batch: 100 / 220 | Training loss: 0.2071731686592102 | Accuracy: 0.9381203801478353\n",
      "Epoch 45 / 100 | Batch: 120 / 220 | Training loss: 0.2178942710161209 | Accuracy: 0.9361530172413793\n",
      "Epoch 45 / 100 | Batch: 140 / 220 | Training loss: 0.1782258003950119 | Accuracy: 0.9342147694292163\n",
      "Epoch 45 / 100 | Batch: 160 / 220 | Training loss: 0.23972833156585693 | Accuracy: 0.9385868970797331\n",
      "Epoch 45 / 100 | Batch: 180 / 220 | Training loss: 0.17404574155807495 | Accuracy: 0.9308801591248135\n",
      "Epoch 45 / 100 | Batch: 200 / 220 | Training loss: 0.2699934244155884 | Accuracy: 0.9318181818181818\n",
      "--------------------------------------------------\n",
      "End of epoch 45 | time: 17.405226230621338 | val_loss: 0.000328 | val_acc: 0.902632\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 46 / 100 | Batch: 20 / 220 | Training loss: 0.24265068769454956 | Accuracy: 0.9355467747729256\n",
      "Epoch 46 / 100 | Batch: 40 / 220 | Training loss: 0.19388218224048615 | Accuracy: 0.9357739242132306\n",
      "Epoch 46 / 100 | Batch: 60 / 220 | Training loss: 0.20676289498806 | Accuracy: 0.9365165786464855\n",
      "Epoch 46 / 100 | Batch: 80 / 220 | Training loss: 0.1614311933517456 | Accuracy: 0.9384640276129868\n",
      "Epoch 46 / 100 | Batch: 100 / 220 | Training loss: 0.1958683729171753 | Accuracy: 0.9353102574926129\n",
      "Epoch 46 / 100 | Batch: 120 / 220 | Training loss: 0.24052943289279938 | Accuracy: 0.9386104904777104\n",
      "Epoch 46 / 100 | Batch: 140 / 220 | Training loss: 0.1807386577129364 | Accuracy: 0.9419695193434936\n",
      "Epoch 46 / 100 | Batch: 160 / 220 | Training loss: 0.20357699692249298 | Accuracy: 0.9325330665777481\n",
      "Epoch 46 / 100 | Batch: 180 / 220 | Training loss: 0.20087535679340363 | Accuracy: 0.9368229166666666\n",
      "Epoch 46 / 100 | Batch: 200 / 220 | Training loss: 0.18103404343128204 | Accuracy: 0.9353269581559892\n",
      "--------------------------------------------------\n",
      "End of epoch 46 | time: 16.945077180862427 | val_loss: 0.000317 | val_acc: 0.906624\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000323 --> 0.000317).  Saving model ...\n",
      "Epoch 47 / 100 | Batch: 20 / 220 | Training loss: 0.27614688873291016 | Accuracy: 0.9382640896870086\n",
      "Epoch 47 / 100 | Batch: 40 / 220 | Training loss: 0.15865330398082733 | Accuracy: 0.9414262864706856\n",
      "Epoch 47 / 100 | Batch: 60 / 220 | Training loss: 0.20034852623939514 | Accuracy: 0.933808829091695\n",
      "Epoch 47 / 100 | Batch: 80 / 220 | Training loss: 0.18876154720783234 | Accuracy: 0.9360965315729668\n",
      "Epoch 47 / 100 | Batch: 100 / 220 | Training loss: 0.22279813885688782 | Accuracy: 0.9337385037379659\n",
      "Epoch 47 / 100 | Batch: 120 / 220 | Training loss: 0.17047399282455444 | Accuracy: 0.9396470711078626\n",
      "Epoch 47 / 100 | Batch: 140 / 220 | Training loss: 0.19649279117584229 | Accuracy: 0.9401427202044946\n",
      "Epoch 47 / 100 | Batch: 160 / 220 | Training loss: 0.14989568293094635 | Accuracy: 0.9360338835794961\n",
      "Epoch 47 / 100 | Batch: 180 / 220 | Training loss: 0.21843859553337097 | Accuracy: 0.9378395027160217\n",
      "Epoch 47 / 100 | Batch: 200 / 220 | Training loss: 0.1962587535381317 | Accuracy: 0.9398352378421472\n",
      "--------------------------------------------------\n",
      "End of epoch 47 | time: 17.429952383041382 | val_loss: 0.000314 | val_acc: 0.910654\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000317 --> 0.000314).  Saving model ...\n",
      "Epoch 48 / 100 | Batch: 20 / 220 | Training loss: 0.1778089553117752 | Accuracy: 0.9386351975371986\n",
      "Epoch 48 / 100 | Batch: 40 / 220 | Training loss: 0.1971069574356079 | Accuracy: 0.9387821556496255\n",
      "Epoch 48 / 100 | Batch: 60 / 220 | Training loss: 0.21512705087661743 | Accuracy: 0.9385177621325308\n",
      "Epoch 48 / 100 | Batch: 80 / 220 | Training loss: 0.2048262059688568 | Accuracy: 0.9366542670763922\n",
      "Epoch 48 / 100 | Batch: 100 / 220 | Training loss: 0.20321983098983765 | Accuracy: 0.9400484669687071\n",
      "Epoch 48 / 100 | Batch: 120 / 220 | Training loss: 0.1797880232334137 | Accuracy: 0.9428384064702989\n",
      "Epoch 48 / 100 | Batch: 140 / 220 | Training loss: 0.16057775914669037 | Accuracy: 0.9432191459408729\n",
      "Epoch 48 / 100 | Batch: 160 / 220 | Training loss: 0.17939570546150208 | Accuracy: 0.9396835860250494\n",
      "Epoch 48 / 100 | Batch: 180 / 220 | Training loss: 0.16550838947296143 | Accuracy: 0.9363496087291965\n",
      "Epoch 48 / 100 | Batch: 200 / 220 | Training loss: 0.25872644782066345 | Accuracy: 0.9395301546529673\n",
      "--------------------------------------------------\n",
      "End of epoch 48 | time: 17.072007656097412 | val_loss: 0.000316 | val_acc: 0.907266\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 49 / 100 | Batch: 20 / 220 | Training loss: 0.1364583820104599 | Accuracy: 0.9459684555723283\n",
      "Epoch 49 / 100 | Batch: 40 / 220 | Training loss: 0.15544161200523376 | Accuracy: 0.9406142611683849\n",
      "Epoch 49 / 100 | Batch: 60 / 220 | Training loss: 0.1715460568666458 | Accuracy: 0.9460238082296026\n",
      "Epoch 49 / 100 | Batch: 80 / 220 | Training loss: 0.18129779398441315 | Accuracy: 0.9401369791394364\n",
      "Epoch 49 / 100 | Batch: 100 / 220 | Training loss: 0.23107318580150604 | Accuracy: 0.9378285591674713\n",
      "Epoch 49 / 100 | Batch: 120 / 220 | Training loss: 0.24496139585971832 | Accuracy: 0.9441885667840694\n",
      "Epoch 49 / 100 | Batch: 140 / 220 | Training loss: 0.17422069609165192 | Accuracy: 0.9401690635635086\n",
      "Epoch 49 / 100 | Batch: 160 / 220 | Training loss: 0.19532938301563263 | Accuracy: 0.9363959529669128\n",
      "Epoch 49 / 100 | Batch: 180 / 220 | Training loss: 0.19870683550834656 | Accuracy: 0.9385647638517587\n",
      "Epoch 49 / 100 | Batch: 200 / 220 | Training loss: 0.17508800327777863 | Accuracy: 0.9359810314167161\n",
      "--------------------------------------------------\n",
      "End of epoch 49 | time: 17.324671745300293 | val_loss: 0.000315 | val_acc: 0.908571\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 50 / 100 | Batch: 20 / 220 | Training loss: 0.18940314650535583 | Accuracy: 0.9455174550712663\n",
      "Epoch 50 / 100 | Batch: 40 / 220 | Training loss: 0.16055217385292053 | Accuracy: 0.941368258178603\n",
      "Epoch 50 / 100 | Batch: 60 / 220 | Training loss: 0.16337698698043823 | Accuracy: 0.9424356223175966\n",
      "Epoch 50 / 100 | Batch: 80 / 220 | Training loss: 0.1708955466747284 | Accuracy: 0.9411016480477823\n",
      "Epoch 50 / 100 | Batch: 100 / 220 | Training loss: 0.16785353422164917 | Accuracy: 0.9409729503040469\n",
      "Epoch 50 / 100 | Batch: 120 / 220 | Training loss: 0.1334707885980606 | Accuracy: 0.9449212384573601\n",
      "Epoch 50 / 100 | Batch: 140 / 220 | Training loss: 0.1509353667497635 | Accuracy: 0.9421130382447885\n",
      "Epoch 50 / 100 | Batch: 160 / 220 | Training loss: 0.17497020959854126 | Accuracy: 0.9394750937332619\n",
      "Epoch 50 / 100 | Batch: 180 / 220 | Training loss: 0.1303827166557312 | Accuracy: 0.938526734330857\n",
      "Epoch 50 / 100 | Batch: 200 / 220 | Training loss: 0.18756628036499023 | Accuracy: 0.9440785979819437\n",
      "--------------------------------------------------\n",
      "End of epoch 50 | time: 17.71493411064148 | val_loss: 0.000315 | val_acc: 0.910187\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 51 / 100 | Batch: 20 / 220 | Training loss: 0.2011348158121109 | Accuracy: 0.9461610977270347\n",
      "Epoch 51 / 100 | Batch: 40 / 220 | Training loss: 0.12557031214237213 | Accuracy: 0.9428682471822775\n",
      "Epoch 51 / 100 | Batch: 60 / 220 | Training loss: 0.17911465466022491 | Accuracy: 0.9406879554222032\n",
      "Epoch 51 / 100 | Batch: 80 / 220 | Training loss: 0.12932032346725464 | Accuracy: 0.9415165436432148\n",
      "Epoch 51 / 100 | Batch: 100 / 220 | Training loss: 0.22515642642974854 | Accuracy: 0.9425986842105263\n",
      "Epoch 51 / 100 | Batch: 120 / 220 | Training loss: 0.16238361597061157 | Accuracy: 0.9479457947945795\n",
      "Epoch 51 / 100 | Batch: 140 / 220 | Training loss: 0.26147496700286865 | Accuracy: 0.9420306042667262\n",
      "Epoch 51 / 100 | Batch: 160 / 220 | Training loss: 0.18550455570220947 | Accuracy: 0.9414060382676568\n",
      "Epoch 51 / 100 | Batch: 180 / 220 | Training loss: 0.17415650188922882 | Accuracy: 0.940597667638484\n",
      "Epoch 51 / 100 | Batch: 200 / 220 | Training loss: 0.13329683244228363 | Accuracy: 0.9404924044002095\n",
      "--------------------------------------------------\n",
      "End of epoch 51 | time: 17.011999130249023 | val_loss: 0.000310 | val_acc: 0.912698\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000314 --> 0.000310).  Saving model ...\n",
      "Epoch 52 / 100 | Batch: 20 / 220 | Training loss: 0.17548346519470215 | Accuracy: 0.9421786267423852\n",
      "Epoch 52 / 100 | Batch: 40 / 220 | Training loss: 0.1167946457862854 | Accuracy: 0.9482972637487183\n",
      "Epoch 52 / 100 | Batch: 60 / 220 | Training loss: 0.21675746142864227 | Accuracy: 0.9476816534112428\n",
      "Epoch 52 / 100 | Batch: 80 / 220 | Training loss: 0.1372481882572174 | Accuracy: 0.9467941446551073\n",
      "Epoch 52 / 100 | Batch: 100 / 220 | Training loss: 0.16445022821426392 | Accuracy: 0.946362216597555\n",
      "Epoch 52 / 100 | Batch: 120 / 220 | Training loss: 0.21047647297382355 | Accuracy: 0.9444535117784669\n",
      "Epoch 52 / 100 | Batch: 140 / 220 | Training loss: 0.16477379202842712 | Accuracy: 0.9442390959974654\n",
      "Epoch 52 / 100 | Batch: 160 / 220 | Training loss: 0.1924840360879898 | Accuracy: 0.9415485163126548\n",
      "Epoch 52 / 100 | Batch: 180 / 220 | Training loss: 0.20198242366313934 | Accuracy: 0.9402330743618202\n",
      "Epoch 52 / 100 | Batch: 200 / 220 | Training loss: 0.14323395490646362 | Accuracy: 0.9443780215210272\n",
      "--------------------------------------------------\n",
      "End of epoch 52 | time: 17.57525634765625 | val_loss: 0.000315 | val_acc: 0.910187\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 53 / 100 | Batch: 20 / 220 | Training loss: 0.166404128074646 | Accuracy: 0.9432435201311341\n",
      "Epoch 53 / 100 | Batch: 40 / 220 | Training loss: 0.14757588505744934 | Accuracy: 0.9481693868548743\n",
      "Epoch 53 / 100 | Batch: 60 / 220 | Training loss: 0.19521446526050568 | Accuracy: 0.9480904302019315\n",
      "Epoch 53 / 100 | Batch: 80 / 220 | Training loss: 0.22413775324821472 | Accuracy: 0.9460334592552617\n",
      "Epoch 53 / 100 | Batch: 100 / 220 | Training loss: 0.15505562722682953 | Accuracy: 0.9449813724960855\n",
      "Epoch 53 / 100 | Batch: 120 / 220 | Training loss: 0.14198856055736542 | Accuracy: 0.9497437506536973\n",
      "Epoch 53 / 100 | Batch: 140 / 220 | Training loss: 0.266812264919281 | Accuracy: 0.9441123091704922\n",
      "Epoch 53 / 100 | Batch: 160 / 220 | Training loss: 0.15489409863948822 | Accuracy: 0.947056017806985\n",
      "Epoch 53 / 100 | Batch: 180 / 220 | Training loss: 0.17630761861801147 | Accuracy: 0.9457860227090996\n",
      "Epoch 53 / 100 | Batch: 200 / 220 | Training loss: 0.15387623012065887 | Accuracy: 0.9435461465799856\n",
      "--------------------------------------------------\n",
      "End of epoch 53 | time: 16.90745782852173 | val_loss: 0.000310 | val_acc: 0.913185\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000310 --> 0.000310).  Saving model ...\n",
      "Epoch 54 / 100 | Batch: 20 / 220 | Training loss: 0.15869402885437012 | Accuracy: 0.9477461661589301\n",
      "Epoch 54 / 100 | Batch: 40 / 220 | Training loss: 0.10083439946174622 | Accuracy: 0.9477898609533084\n",
      "Epoch 54 / 100 | Batch: 60 / 220 | Training loss: 0.24252937734127045 | Accuracy: 0.9485321149099312\n",
      "Epoch 54 / 100 | Batch: 80 / 220 | Training loss: 0.19193135201931 | Accuracy: 0.9462977602108037\n",
      "Epoch 54 / 100 | Batch: 100 / 220 | Training loss: 0.1255924254655838 | Accuracy: 0.9470932664157257\n",
      "Epoch 54 / 100 | Batch: 120 / 220 | Training loss: 0.18476079404354095 | Accuracy: 0.9480346079897458\n",
      "Epoch 54 / 100 | Batch: 140 / 220 | Training loss: 0.13469848036766052 | Accuracy: 0.9469143265373413\n",
      "Epoch 54 / 100 | Batch: 160 / 220 | Training loss: 0.1438467800617218 | Accuracy: 0.942994079503806\n",
      "Epoch 54 / 100 | Batch: 180 / 220 | Training loss: 0.20616962015628815 | Accuracy: 0.9469562885492089\n",
      "Epoch 54 / 100 | Batch: 200 / 220 | Training loss: 0.172936350107193 | Accuracy: 0.9467797917470112\n",
      "--------------------------------------------------\n",
      "End of epoch 54 | time: 17.446487188339233 | val_loss: 0.000318 | val_acc: 0.909388\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 55 / 100 | Batch: 20 / 220 | Training loss: 0.20020976662635803 | Accuracy: 0.947185359589041\n",
      "Epoch 55 / 100 | Batch: 40 / 220 | Training loss: 0.1585863083600998 | Accuracy: 0.9461779313323256\n",
      "Epoch 55 / 100 | Batch: 60 / 220 | Training loss: 0.1825464963912964 | Accuracy: 0.9466230322180218\n",
      "Epoch 55 / 100 | Batch: 80 / 220 | Training loss: 0.17397452890872955 | Accuracy: 0.9500161411815344\n",
      "Epoch 55 / 100 | Batch: 100 / 220 | Training loss: 0.14366281032562256 | Accuracy: 0.9493213603757031\n",
      "Epoch 55 / 100 | Batch: 120 / 220 | Training loss: 0.1233067512512207 | Accuracy: 0.9505648968333952\n",
      "Epoch 55 / 100 | Batch: 140 / 220 | Training loss: 0.1813281625509262 | Accuracy: 0.9478173341809706\n",
      "Epoch 55 / 100 | Batch: 160 / 220 | Training loss: 0.15969766676425934 | Accuracy: 0.9468523975354942\n",
      "Epoch 55 / 100 | Batch: 180 / 220 | Training loss: 0.15340156853199005 | Accuracy: 0.9506582526384506\n",
      "Epoch 55 / 100 | Batch: 200 / 220 | Training loss: 0.1705806851387024 | Accuracy: 0.9480322633031992\n",
      "--------------------------------------------------\n",
      "End of epoch 55 | time: 17.105608224868774 | val_loss: 0.000318 | val_acc: 0.909525\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 56 / 100 | Batch: 20 / 220 | Training loss: 0.14318493008613586 | Accuracy: 0.9460931825256823\n",
      "Epoch 56 / 100 | Batch: 40 / 220 | Training loss: 0.14436310529708862 | Accuracy: 0.9509240565305171\n",
      "Epoch 56 / 100 | Batch: 60 / 220 | Training loss: 0.1907387673854828 | Accuracy: 0.950122917235728\n",
      "Epoch 56 / 100 | Batch: 80 / 220 | Training loss: 0.21016617119312286 | Accuracy: 0.9494028577521859\n",
      "Epoch 56 / 100 | Batch: 100 / 220 | Training loss: 0.1342361718416214 | Accuracy: 0.9505240197903921\n",
      "Epoch 56 / 100 | Batch: 120 / 220 | Training loss: 0.16028255224227905 | Accuracy: 0.9512794486884983\n",
      "Epoch 56 / 100 | Batch: 140 / 220 | Training loss: 0.1668306142091751 | Accuracy: 0.9443283089448784\n",
      "Epoch 56 / 100 | Batch: 160 / 220 | Training loss: 0.1317572444677353 | Accuracy: 0.9498779495524817\n",
      "Epoch 56 / 100 | Batch: 180 / 220 | Training loss: 0.2013024389743805 | Accuracy: 0.9494447207028013\n",
      "Epoch 56 / 100 | Batch: 200 / 220 | Training loss: 0.13041989505290985 | Accuracy: 0.9515929060428009\n",
      "--------------------------------------------------\n",
      "End of epoch 56 | time: 17.281522512435913 | val_loss: 0.000313 | val_acc: 0.910771\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 57 / 100 | Batch: 20 / 220 | Training loss: 0.14515064656734467 | Accuracy: 0.9526125142658661\n",
      "Epoch 57 / 100 | Batch: 40 / 220 | Training loss: 0.19531233608722687 | Accuracy: 0.9523088569265707\n",
      "Epoch 57 / 100 | Batch: 60 / 220 | Training loss: 0.17249801754951477 | Accuracy: 0.9503658403407229\n",
      "Epoch 57 / 100 | Batch: 80 / 220 | Training loss: 0.14711476862430573 | Accuracy: 0.947380106571936\n",
      "Epoch 57 / 100 | Batch: 100 / 220 | Training loss: 0.19518713653087616 | Accuracy: 0.952835303046731\n",
      "Epoch 57 / 100 | Batch: 120 / 220 | Training loss: 0.13615866005420685 | Accuracy: 0.9524377593360995\n",
      "Epoch 57 / 100 | Batch: 140 / 220 | Training loss: 0.16743548214435577 | Accuracy: 0.9474352603390205\n",
      "Epoch 57 / 100 | Batch: 160 / 220 | Training loss: 0.1711937040090561 | Accuracy: 0.9498501391564975\n",
      "Epoch 57 / 100 | Batch: 180 / 220 | Training loss: 0.11448448896408081 | Accuracy: 0.9494284158954818\n",
      "Epoch 57 / 100 | Batch: 200 / 220 | Training loss: 0.18724516034126282 | Accuracy: 0.9497721790404717\n",
      "--------------------------------------------------\n",
      "End of epoch 57 | time: 17.071357250213623 | val_loss: 0.000308 | val_acc: 0.912172\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000310 --> 0.000308).  Saving model ...\n",
      "Epoch 58 / 100 | Batch: 20 / 220 | Training loss: 0.195405513048172 | Accuracy: 0.9524615384615385\n",
      "Epoch 58 / 100 | Batch: 40 / 220 | Training loss: 0.1657429188489914 | Accuracy: 0.9528217062463638\n",
      "Epoch 58 / 100 | Batch: 60 / 220 | Training loss: 0.15315963327884674 | Accuracy: 0.9505915463595143\n",
      "Epoch 58 / 100 | Batch: 80 / 220 | Training loss: 0.1554638296365738 | Accuracy: 0.9553425667491706\n",
      "Epoch 58 / 100 | Batch: 100 / 220 | Training loss: 0.13242541253566742 | Accuracy: 0.9515215110178384\n",
      "Epoch 58 / 100 | Batch: 120 / 220 | Training loss: 0.16700951755046844 | Accuracy: 0.9517113581861784\n",
      "Epoch 58 / 100 | Batch: 140 / 220 | Training loss: 0.17552095651626587 | Accuracy: 0.9492822966507177\n",
      "Epoch 58 / 100 | Batch: 160 / 220 | Training loss: 0.19948622584342957 | Accuracy: 0.9508276797829036\n",
      "Epoch 58 / 100 | Batch: 180 / 220 | Training loss: 0.17778226733207703 | Accuracy: 0.9535992111318067\n",
      "Epoch 58 / 100 | Batch: 200 / 220 | Training loss: 0.16319730877876282 | Accuracy: 0.952324001087252\n",
      "--------------------------------------------------\n",
      "End of epoch 58 | time: 17.454285144805908 | val_loss: 0.000310 | val_acc: 0.911121\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 59 / 100 | Batch: 20 / 220 | Training loss: 0.11319289356470108 | Accuracy: 0.9547954190000505\n",
      "Epoch 59 / 100 | Batch: 40 / 220 | Training loss: 0.12763504683971405 | Accuracy: 0.9533673195599678\n",
      "Epoch 59 / 100 | Batch: 60 / 220 | Training loss: 0.1969641149044037 | Accuracy: 0.9519519519519519\n",
      "Epoch 59 / 100 | Batch: 80 / 220 | Training loss: 0.18303951621055603 | Accuracy: 0.9501572327044026\n",
      "Epoch 59 / 100 | Batch: 100 / 220 | Training loss: 0.10487984865903854 | Accuracy: 0.9538750335210512\n",
      "Epoch 59 / 100 | Batch: 120 / 220 | Training loss: 0.20697571337223053 | Accuracy: 0.9536809488193183\n",
      "Epoch 59 / 100 | Batch: 140 / 220 | Training loss: 0.19457079470157623 | Accuracy: 0.9500902971597439\n",
      "Epoch 59 / 100 | Batch: 160 / 220 | Training loss: 0.1552361249923706 | Accuracy: 0.9506405856783344\n",
      "Epoch 59 / 100 | Batch: 180 / 220 | Training loss: 0.11241765320301056 | Accuracy: 0.9506586050529043\n",
      "Epoch 59 / 100 | Batch: 200 / 220 | Training loss: 0.17409396171569824 | Accuracy: 0.9541336942940442\n",
      "--------------------------------------------------\n",
      "End of epoch 59 | time: 17.522021293640137 | val_loss: 0.000310 | val_acc: 0.912873\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 60 / 100 | Batch: 20 / 220 | Training loss: 0.15850460529327393 | Accuracy: 0.9553343542623788\n",
      "Epoch 60 / 100 | Batch: 40 / 220 | Training loss: 0.15968775749206543 | Accuracy: 0.9536544761291016\n",
      "Epoch 60 / 100 | Batch: 60 / 220 | Training loss: 0.15366040170192719 | Accuracy: 0.9540161403888858\n",
      "Epoch 60 / 100 | Batch: 80 / 220 | Training loss: 0.1672632098197937 | Accuracy: 0.9538535748740486\n",
      "Epoch 60 / 100 | Batch: 100 / 220 | Training loss: 0.1781335026025772 | Accuracy: 0.954858454475899\n",
      "Epoch 60 / 100 | Batch: 120 / 220 | Training loss: 0.13856396079063416 | Accuracy: 0.9534139971216886\n",
      "Epoch 60 / 100 | Batch: 140 / 220 | Training loss: 0.1609380841255188 | Accuracy: 0.9503715354992678\n",
      "Epoch 60 / 100 | Batch: 160 / 220 | Training loss: 0.18763142824172974 | Accuracy: 0.9526416361101069\n",
      "Epoch 60 / 100 | Batch: 180 / 220 | Training loss: 0.1394064724445343 | Accuracy: 0.9531001153275852\n",
      "Epoch 60 / 100 | Batch: 200 / 220 | Training loss: 0.15754620730876923 | Accuracy: 0.9556968965895384\n",
      "--------------------------------------------------\n",
      "End of epoch 60 | time: 16.948084592819214 | val_loss: 0.000314 | val_acc: 0.911919\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 61 / 100 | Batch: 20 / 220 | Training loss: 0.13597029447555542 | Accuracy: 0.9576072302391772\n",
      "Epoch 61 / 100 | Batch: 40 / 220 | Training loss: 0.13433381915092468 | Accuracy: 0.9561022672455378\n",
      "Epoch 61 / 100 | Batch: 60 / 220 | Training loss: 0.15423806011676788 | Accuracy: 0.9540833241242126\n",
      "Epoch 61 / 100 | Batch: 80 / 220 | Training loss: 0.11491796374320984 | Accuracy: 0.9557592878844411\n",
      "Epoch 61 / 100 | Batch: 100 / 220 | Training loss: 0.13848541676998138 | Accuracy: 0.9565751522273261\n",
      "Epoch 61 / 100 | Batch: 120 / 220 | Training loss: 0.18176880478858948 | Accuracy: 0.9504891304347826\n",
      "Epoch 61 / 100 | Batch: 140 / 220 | Training loss: 0.1416654735803604 | Accuracy: 0.9536761120442109\n",
      "Epoch 61 / 100 | Batch: 160 / 220 | Training loss: 0.1684466004371643 | Accuracy: 0.9533218477441585\n",
      "Epoch 61 / 100 | Batch: 180 / 220 | Training loss: 0.13368120789527893 | Accuracy: 0.9509135533133352\n",
      "Epoch 61 / 100 | Batch: 200 / 220 | Training loss: 0.23324279487133026 | Accuracy: 0.9520261082404133\n",
      "--------------------------------------------------\n",
      "End of epoch 61 | time: 17.468844413757324 | val_loss: 0.000304 | val_acc: 0.916378\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000308 --> 0.000304).  Saving model ...\n",
      "Epoch 62 / 100 | Batch: 20 / 220 | Training loss: 0.15990008413791656 | Accuracy: 0.9531282263060087\n",
      "Epoch 62 / 100 | Batch: 40 / 220 | Training loss: 0.11450643092393875 | Accuracy: 0.9528660316061891\n",
      "Epoch 62 / 100 | Batch: 60 / 220 | Training loss: 0.13521742820739746 | Accuracy: 0.9571466737910767\n",
      "Epoch 62 / 100 | Batch: 80 / 220 | Training loss: 0.20521429181098938 | Accuracy: 0.9542246101980615\n",
      "Epoch 62 / 100 | Batch: 100 / 220 | Training loss: 0.17767176032066345 | Accuracy: 0.9544115283655649\n",
      "Epoch 62 / 100 | Batch: 120 / 220 | Training loss: 0.1471346914768219 | Accuracy: 0.9574513349643655\n",
      "Epoch 62 / 100 | Batch: 140 / 220 | Training loss: 0.2025567889213562 | Accuracy: 0.9570642978003384\n",
      "Epoch 62 / 100 | Batch: 160 / 220 | Training loss: 0.12908610701560974 | Accuracy: 0.9557120751293955\n",
      "Epoch 62 / 100 | Batch: 180 / 220 | Training loss: 0.15945810079574585 | Accuracy: 0.9573088354498784\n",
      "Epoch 62 / 100 | Batch: 200 / 220 | Training loss: 0.15605072677135468 | Accuracy: 0.9538691299297527\n",
      "--------------------------------------------------\n",
      "End of epoch 62 | time: 17.15126609802246 | val_loss: 0.000310 | val_acc: 0.912328\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 63 / 100 | Batch: 20 / 220 | Training loss: 0.20243291556835175 | Accuracy: 0.9530564343300337\n",
      "Epoch 63 / 100 | Batch: 40 / 220 | Training loss: 0.14210696518421173 | Accuracy: 0.9559366900126841\n",
      "Epoch 63 / 100 | Batch: 60 / 220 | Training loss: 0.15579189360141754 | Accuracy: 0.95263242118739\n",
      "Epoch 63 / 100 | Batch: 80 / 220 | Training loss: 0.14461134374141693 | Accuracy: 0.9598524305555556\n",
      "Epoch 63 / 100 | Batch: 100 / 220 | Training loss: 0.10115029662847519 | Accuracy: 0.9569960142647367\n",
      "Epoch 63 / 100 | Batch: 120 / 220 | Training loss: 0.17083759605884552 | Accuracy: 0.9572320217096336\n",
      "Epoch 63 / 100 | Batch: 140 / 220 | Training loss: 0.21069154143333435 | Accuracy: 0.955168917115867\n",
      "Epoch 63 / 100 | Batch: 160 / 220 | Training loss: 0.12071768194437027 | Accuracy: 0.9561460710792306\n",
      "Epoch 63 / 100 | Batch: 180 / 220 | Training loss: 0.16372030973434448 | Accuracy: 0.9573242923259068\n",
      "Epoch 63 / 100 | Batch: 200 / 220 | Training loss: 0.14743074774742126 | Accuracy: 0.954158689640502\n",
      "--------------------------------------------------\n",
      "End of epoch 63 | time: 17.434693098068237 | val_loss: 0.000309 | val_acc: 0.914450\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 64 / 100 | Batch: 20 / 220 | Training loss: 0.1273808628320694 | Accuracy: 0.9558230829625752\n",
      "Epoch 64 / 100 | Batch: 40 / 220 | Training loss: 0.10020558536052704 | Accuracy: 0.9591965506362393\n",
      "Epoch 64 / 100 | Batch: 60 / 220 | Training loss: 0.12022166699171066 | Accuracy: 0.9564835647258958\n",
      "Epoch 64 / 100 | Batch: 80 / 220 | Training loss: 0.12608253955841064 | Accuracy: 0.9597811072149612\n",
      "Epoch 64 / 100 | Batch: 100 / 220 | Training loss: 0.1533108353614807 | Accuracy: 0.9568249574105622\n",
      "Epoch 64 / 100 | Batch: 120 / 220 | Training loss: 0.19423030316829681 | Accuracy: 0.9570196078431372\n",
      "Epoch 64 / 100 | Batch: 140 / 220 | Training loss: 0.11066462844610214 | Accuracy: 0.9589423184201719\n",
      "Epoch 64 / 100 | Batch: 160 / 220 | Training loss: 0.18064261972904205 | Accuracy: 0.957255107386066\n",
      "Epoch 64 / 100 | Batch: 180 / 220 | Training loss: 0.16526001691818237 | Accuracy: 0.95812422427284\n",
      "Epoch 64 / 100 | Batch: 200 / 220 | Training loss: 0.13543465733528137 | Accuracy: 0.9551100457616039\n",
      "--------------------------------------------------\n",
      "End of epoch 64 | time: 17.058812856674194 | val_loss: 0.000306 | val_acc: 0.916670\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 65 / 100 | Batch: 20 / 220 | Training loss: 0.11480055749416351 | Accuracy: 0.9565949199224727\n",
      "Epoch 65 / 100 | Batch: 40 / 220 | Training loss: 0.13629814982414246 | Accuracy: 0.9586763518966909\n",
      "Epoch 65 / 100 | Batch: 60 / 220 | Training loss: 0.14181651175022125 | Accuracy: 0.9586727489953296\n",
      "Epoch 65 / 100 | Batch: 80 / 220 | Training loss: 0.11978363990783691 | Accuracy: 0.9578419486388184\n",
      "Epoch 65 / 100 | Batch: 100 / 220 | Training loss: 0.10521389544010162 | Accuracy: 0.958555809814391\n",
      "Epoch 65 / 100 | Batch: 120 / 220 | Training loss: 0.09653662145137787 | Accuracy: 0.9589144772407828\n",
      "Epoch 65 / 100 | Batch: 140 / 220 | Training loss: 0.13277243077754974 | Accuracy: 0.9574116518309258\n",
      "Epoch 65 / 100 | Batch: 160 / 220 | Training loss: 0.19585587084293365 | Accuracy: 0.9581667853036193\n",
      "Epoch 65 / 100 | Batch: 180 / 220 | Training loss: 0.1538599282503128 | Accuracy: 0.9602544584602001\n",
      "Epoch 65 / 100 | Batch: 200 / 220 | Training loss: 0.22418330609798431 | Accuracy: 0.9576654115115654\n",
      "--------------------------------------------------\n",
      "End of epoch 65 | time: 17.426127910614014 | val_loss: 0.000303 | val_acc: 0.916534\n",
      "--------------------------------------------------\n",
      "Validation loss decreased (0.000304 --> 0.000303).  Saving model ...\n",
      "Epoch 66 / 100 | Batch: 20 / 220 | Training loss: 0.14381548762321472 | Accuracy: 0.9603492178974172\n",
      "Epoch 66 / 100 | Batch: 40 / 220 | Training loss: 0.16083486378192902 | Accuracy: 0.9566670259782257\n",
      "Epoch 66 / 100 | Batch: 60 / 220 | Training loss: 0.12690159678459167 | Accuracy: 0.9571261747205694\n",
      "Epoch 66 / 100 | Batch: 80 / 220 | Training loss: 0.13953888416290283 | Accuracy: 0.9606475173052815\n",
      "Epoch 66 / 100 | Batch: 100 / 220 | Training loss: 0.10145482420921326 | Accuracy: 0.9594761419140143\n",
      "Epoch 66 / 100 | Batch: 120 / 220 | Training loss: 0.11735646426677704 | Accuracy: 0.9591406908171862\n",
      "Epoch 66 / 100 | Batch: 140 / 220 | Training loss: 0.12742674350738525 | Accuracy: 0.9575106618227768\n",
      "Epoch 66 / 100 | Batch: 160 / 220 | Training loss: 0.13366392254829407 | Accuracy: 0.9596009428273858\n",
      "Epoch 66 / 100 | Batch: 180 / 220 | Training loss: 0.15083353221416473 | Accuracy: 0.9583289871701263\n",
      "Epoch 66 / 100 | Batch: 200 / 220 | Training loss: 0.13759545981884003 | Accuracy: 0.9607329842931938\n",
      "--------------------------------------------------\n",
      "End of epoch 66 | time: 17.11130666732788 | val_loss: 0.000308 | val_acc: 0.915755\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 67 / 100 | Batch: 20 / 220 | Training loss: 0.12069083005189896 | Accuracy: 0.9598953353796609\n",
      "Epoch 67 / 100 | Batch: 40 / 220 | Training loss: 0.09847341477870941 | Accuracy: 0.9627150066948192\n",
      "Epoch 67 / 100 | Batch: 60 / 220 | Training loss: 0.12359172850847244 | Accuracy: 0.9621077560686797\n",
      "Epoch 67 / 100 | Batch: 80 / 220 | Training loss: 0.11681973189115524 | Accuracy: 0.9584015203505253\n",
      "Epoch 67 / 100 | Batch: 100 / 220 | Training loss: 0.1877344250679016 | Accuracy: 0.960019907100199\n",
      "Epoch 67 / 100 | Batch: 120 / 220 | Training loss: 0.17643314599990845 | Accuracy: 0.9595141700404858\n",
      "Epoch 67 / 100 | Batch: 140 / 220 | Training loss: 0.14025428891181946 | Accuracy: 0.9619506966773848\n",
      "Epoch 67 / 100 | Batch: 160 / 220 | Training loss: 0.16787676513195038 | Accuracy: 0.9589663904235728\n",
      "Epoch 67 / 100 | Batch: 180 / 220 | Training loss: 0.12780970335006714 | Accuracy: 0.9611724816799737\n",
      "Epoch 67 / 100 | Batch: 200 / 220 | Training loss: 0.14884069561958313 | Accuracy: 0.9575994781474233\n",
      "--------------------------------------------------\n",
      "End of epoch 67 | time: 17.425602912902832 | val_loss: 0.000305 | val_acc: 0.916534\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 68 / 100 | Batch: 20 / 220 | Training loss: 0.10656452178955078 | Accuracy: 0.9621054764679062\n",
      "Epoch 68 / 100 | Batch: 40 / 220 | Training loss: 0.10623344779014587 | Accuracy: 0.9612724033120218\n",
      "Epoch 68 / 100 | Batch: 60 / 220 | Training loss: 0.09352637827396393 | Accuracy: 0.9613095238095238\n",
      "Epoch 68 / 100 | Batch: 80 / 220 | Training loss: 0.12075226753950119 | Accuracy: 0.9638973466724663\n",
      "Epoch 68 / 100 | Batch: 100 / 220 | Training loss: 0.13244231045246124 | Accuracy: 0.9605042471460261\n",
      "Epoch 68 / 100 | Batch: 120 / 220 | Training loss: 0.18571265041828156 | Accuracy: 0.9610761001959435\n",
      "Epoch 68 / 100 | Batch: 140 / 220 | Training loss: 0.1530812531709671 | Accuracy: 0.9579347826086957\n",
      "Epoch 68 / 100 | Batch: 160 / 220 | Training loss: 0.1438518464565277 | Accuracy: 0.9639066961159295\n",
      "Epoch 68 / 100 | Batch: 180 / 220 | Training loss: 0.11343388259410858 | Accuracy: 0.9616763310490247\n",
      "Epoch 68 / 100 | Batch: 200 / 220 | Training loss: 0.12429763376712799 | Accuracy: 0.9584416991764196\n",
      "--------------------------------------------------\n",
      "End of epoch 68 | time: 17.206085920333862 | val_loss: 0.000306 | val_acc: 0.916378\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 69 / 100 | Batch: 20 / 220 | Training loss: 0.09070421010255814 | Accuracy: 0.9653367875647668\n",
      "Epoch 69 / 100 | Batch: 40 / 220 | Training loss: 0.1150408387184143 | Accuracy: 0.9597557590896475\n",
      "Epoch 69 / 100 | Batch: 60 / 220 | Training loss: 0.12397795170545578 | Accuracy: 0.9622795115332429\n",
      "Epoch 69 / 100 | Batch: 80 / 220 | Training loss: 0.11876438558101654 | Accuracy: 0.9625396165636203\n",
      "Epoch 69 / 100 | Batch: 100 / 220 | Training loss: 0.09513088315725327 | Accuracy: 0.9625424448217318\n",
      "Epoch 69 / 100 | Batch: 120 / 220 | Training loss: 0.1603468656539917 | Accuracy: 0.957088948787062\n",
      "Epoch 69 / 100 | Batch: 140 / 220 | Training loss: 0.11101383715867996 | Accuracy: 0.9640658174097665\n",
      "Epoch 69 / 100 | Batch: 160 / 220 | Training loss: 0.12056440114974976 | Accuracy: 0.9616359828023371\n",
      "Epoch 69 / 100 | Batch: 180 / 220 | Training loss: 0.09453136473894119 | Accuracy: 0.9634995102335413\n",
      "Epoch 69 / 100 | Batch: 200 / 220 | Training loss: 0.08035431802272797 | Accuracy: 0.9613753322400045\n",
      "--------------------------------------------------\n",
      "End of epoch 69 | time: 17.45863175392151 | val_loss: 0.000308 | val_acc: 0.916650\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 70 / 100 | Batch: 20 / 220 | Training loss: 0.09919331967830658 | Accuracy: 0.9646794610044916\n",
      "Epoch 70 / 100 | Batch: 40 / 220 | Training loss: 0.12274990975856781 | Accuracy: 0.962403649520214\n",
      "Epoch 70 / 100 | Batch: 60 / 220 | Training loss: 0.11622744053602219 | Accuracy: 0.9638522703494455\n",
      "Epoch 70 / 100 | Batch: 80 / 220 | Training loss: 0.08359970897436142 | Accuracy: 0.9651630664972469\n",
      "Epoch 70 / 100 | Batch: 100 / 220 | Training loss: 0.1572628617286682 | Accuracy: 0.9646517235709979\n",
      "Epoch 70 / 100 | Batch: 120 / 220 | Training loss: 0.11437344551086426 | Accuracy: 0.963197699190456\n",
      "Epoch 70 / 100 | Batch: 140 / 220 | Training loss: 0.16253302991390228 | Accuracy: 0.9604548540393755\n",
      "Epoch 70 / 100 | Batch: 160 / 220 | Training loss: 0.1318666934967041 | Accuracy: 0.9601226993865031\n",
      "Epoch 70 / 100 | Batch: 180 / 220 | Training loss: 0.12314195930957794 | Accuracy: 0.9620395689239183\n",
      "Epoch 70 / 100 | Batch: 200 / 220 | Training loss: 0.17149627208709717 | Accuracy: 0.959745416961323\n",
      "--------------------------------------------------\n",
      "End of epoch 70 | time: 17.182936668395996 | val_loss: 0.000309 | val_acc: 0.916027\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 71 / 100 | Batch: 20 / 220 | Training loss: 0.10713633894920349 | Accuracy: 0.9649984162179284\n",
      "Epoch 71 / 100 | Batch: 40 / 220 | Training loss: 0.11608581244945526 | Accuracy: 0.9667520575570938\n",
      "Epoch 71 / 100 | Batch: 60 / 220 | Training loss: 0.16268911957740784 | Accuracy: 0.9655117355899728\n",
      "Epoch 71 / 100 | Batch: 80 / 220 | Training loss: 0.1466444581747055 | Accuracy: 0.9593394694098538\n",
      "Epoch 71 / 100 | Batch: 100 / 220 | Training loss: 0.10933005064725876 | Accuracy: 0.9634773100054674\n",
      "Epoch 71 / 100 | Batch: 120 / 220 | Training loss: 0.12995368242263794 | Accuracy: 0.9638177091622898\n",
      "Epoch 71 / 100 | Batch: 140 / 220 | Training loss: 0.11373291164636612 | Accuracy: 0.962996010917489\n",
      "Epoch 71 / 100 | Batch: 160 / 220 | Training loss: 0.09064439684152603 | Accuracy: 0.9652840158520476\n",
      "Epoch 71 / 100 | Batch: 180 / 220 | Training loss: 0.11144524812698364 | Accuracy: 0.9632666448015743\n",
      "Epoch 71 / 100 | Batch: 200 / 220 | Training loss: 0.09888938069343567 | Accuracy: 0.9619380888290713\n",
      "--------------------------------------------------\n",
      "End of epoch 71 | time: 17.077396154403687 | val_loss: 0.000308 | val_acc: 0.917663\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 72 / 100 | Batch: 20 / 220 | Training loss: 0.0992891788482666 | Accuracy: 0.9646223971822231\n",
      "Epoch 72 / 100 | Batch: 40 / 220 | Training loss: 0.12983338534832 | Accuracy: 0.966505653166304\n",
      "Epoch 72 / 100 | Batch: 60 / 220 | Training loss: 0.10832090675830841 | Accuracy: 0.9653633551397129\n",
      "Epoch 72 / 100 | Batch: 80 / 220 | Training loss: 0.12723730504512787 | Accuracy: 0.9628707392651615\n",
      "Epoch 72 / 100 | Batch: 100 / 220 | Training loss: 0.12464477866888046 | Accuracy: 0.964950953378155\n",
      "Epoch 72 / 100 | Batch: 120 / 220 | Training loss: 0.1196691244840622 | Accuracy: 0.9654392764857881\n",
      "Epoch 72 / 100 | Batch: 140 / 220 | Training loss: 0.1002686470746994 | Accuracy: 0.9663579762465337\n",
      "Epoch 72 / 100 | Batch: 160 / 220 | Training loss: 0.1605035960674286 | Accuracy: 0.9617066017375906\n",
      "Epoch 72 / 100 | Batch: 180 / 220 | Training loss: 0.13980403542518616 | Accuracy: 0.96076803895529\n",
      "Epoch 72 / 100 | Batch: 200 / 220 | Training loss: 0.1288706511259079 | Accuracy: 0.9621097137901128\n",
      "--------------------------------------------------\n",
      "End of epoch 72 | time: 17.25213623046875 | val_loss: 0.000305 | val_acc: 0.919532\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 73 / 100 | Batch: 20 / 220 | Training loss: 0.09595469385385513 | Accuracy: 0.9655349794238683\n",
      "Epoch 73 / 100 | Batch: 40 / 220 | Training loss: 0.18250280618667603 | Accuracy: 0.9663892108313139\n",
      "Epoch 73 / 100 | Batch: 60 / 220 | Training loss: 0.11313894391059875 | Accuracy: 0.962654716175843\n",
      "Epoch 73 / 100 | Batch: 80 / 220 | Training loss: 0.09985283762216568 | Accuracy: 0.964238042269188\n",
      "Epoch 73 / 100 | Batch: 100 / 220 | Training loss: 0.08992056548595428 | Accuracy: 0.9669944554869756\n",
      "Epoch 73 / 100 | Batch: 120 / 220 | Training loss: 0.10160519927740097 | Accuracy: 0.9631882371608399\n",
      "Epoch 73 / 100 | Batch: 140 / 220 | Training loss: 0.1564294844865799 | Accuracy: 0.9668860001069919\n",
      "Epoch 73 / 100 | Batch: 160 / 220 | Training loss: 0.10549585521221161 | Accuracy: 0.9674148774669269\n",
      "Epoch 73 / 100 | Batch: 180 / 220 | Training loss: 0.12860806286334991 | Accuracy: 0.9641280353200883\n",
      "Epoch 73 / 100 | Batch: 200 / 220 | Training loss: 0.09780634939670563 | Accuracy: 0.966755912539045\n",
      "--------------------------------------------------\n",
      "End of epoch 73 | time: 17.15255045890808 | val_loss: 0.000311 | val_acc: 0.917819\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch 74 / 100 | Batch: 20 / 220 | Training loss: 0.09723915904760361 | Accuracy: 0.9624200292176717\n",
      "Epoch 74 / 100 | Batch: 40 / 220 | Training loss: 0.11553361266851425 | Accuracy: 0.9684682252578155\n",
      "Epoch 74 / 100 | Batch: 60 / 220 | Training loss: 0.10590527951717377 | Accuracy: 0.966308055628444\n",
      "Epoch 74 / 100 | Batch: 80 / 220 | Training loss: 0.11889694631099701 | Accuracy: 0.9664239048945057\n",
      "Epoch 74 / 100 | Batch: 100 / 220 | Training loss: 0.1265111118555069 | Accuracy: 0.9647411852963241\n",
      "Epoch 74 / 100 | Batch: 120 / 220 | Training loss: 0.11951081454753876 | Accuracy: 0.9668884834174091\n",
      "Epoch 74 / 100 | Batch: 140 / 220 | Training loss: 0.14586888253688812 | Accuracy: 0.9644512294858514\n",
      "Epoch 74 / 100 | Batch: 160 / 220 | Training loss: 0.10379910469055176 | Accuracy: 0.9661249588228835\n",
      "Epoch 74 / 100 | Batch: 180 / 220 | Training loss: 0.19294556975364685 | Accuracy: 0.9629931086873948\n",
      "Epoch 74 / 100 | Batch: 200 / 220 | Training loss: 0.0961342379450798 | Accuracy: 0.9666253302420876\n",
      "--------------------------------------------------\n",
      "End of epoch 74 | time: 17.319937705993652 | val_loss: 0.000306 | val_acc: 0.918597\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch 75 / 100 | Batch: 20 / 220 | Training loss: 0.12988021969795227 | Accuracy: 0.9646528586620753\n",
      "Epoch 75 / 100 | Batch: 40 / 220 | Training loss: 0.1170295923948288 | Accuracy: 0.9665676478530921\n",
      "Epoch 75 / 100 | Batch: 60 / 220 | Training loss: 0.10801493376493454 | Accuracy: 0.9655063123976546\n",
      "Epoch 75 / 100 | Batch: 80 / 220 | Training loss: 0.08541157096624374 | Accuracy: 0.9689837219533656\n",
      "Epoch 75 / 100 | Batch: 100 / 220 | Training loss: 0.09841346740722656 | Accuracy: 0.967741935483871\n",
      "Epoch 75 / 100 | Batch: 120 / 220 | Training loss: 0.13143229484558105 | Accuracy: 0.9670364500792393\n",
      "Epoch 75 / 100 | Batch: 140 / 220 | Training loss: 0.12115585803985596 | Accuracy: 0.9705505077498664\n",
      "Epoch 75 / 100 | Batch: 160 / 220 | Training loss: 0.09810031950473785 | Accuracy: 0.965\n",
      "Epoch 75 / 100 | Batch: 180 / 220 | Training loss: 0.11609000712633133 | Accuracy: 0.9646503040834057\n",
      "Epoch 75 / 100 | Batch: 200 / 220 | Training loss: 0.09346162527799606 | Accuracy: 0.9657876730354229\n",
      "--------------------------------------------------\n",
      "End of epoch 75 | time: 17.00695037841797 | val_loss: 0.000306 | val_acc: 0.921245\n",
      "--------------------------------------------------\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "current_acc = 0.0\n",
    "loss, acc = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    train(train_dataloader)\n",
    "    \n",
    "    val_loss, val_acc = evaluate(val_dataloader)\n",
    "    \n",
    "    loss.append(val_loss)\n",
    "    acc.append(val_acc)\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"End of epoch {epoch + 1} | time: {time.time() - epoch_start_time} | val_loss: {val_loss:.6f} | val_acc: {val_acc:.6f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36c07b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:47.662720Z",
     "iopub.status.busy": "2022-10-24T04:29:47.661845Z",
     "iopub.status.idle": "2022-10-24T04:29:47.666704Z",
     "shell.execute_reply": "2022-10-24T04:29:47.665789Z"
    },
    "papermill": {
     "duration": 0.062176,
     "end_time": "2022-10-24T04:29:47.668766",
     "exception": false,
     "start_time": "2022-10-24T04:29:47.606590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04c0f8af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:47.779414Z",
     "iopub.status.busy": "2022-10-24T04:29:47.778745Z",
     "iopub.status.idle": "2022-10-24T04:29:47.960695Z",
     "shell.execute_reply": "2022-10-24T04:29:47.959849Z"
    },
    "papermill": {
     "duration": 0.239435,
     "end_time": "2022-10-24T04:29:47.962718",
     "exception": false,
     "start_time": "2022-10-24T04:29:47.723283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([l.cpu() for l in loss])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b38cbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:48.100159Z",
     "iopub.status.busy": "2022-10-24T04:29:48.099195Z",
     "iopub.status.idle": "2022-10-24T04:29:48.292918Z",
     "shell.execute_reply": "2022-10-24T04:29:48.292023Z"
    },
    "papermill": {
     "duration": 0.277148,
     "end_time": "2022-10-24T04:29:48.294823",
     "exception": false,
     "start_time": "2022-10-24T04:29:48.017675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b98087e",
   "metadata": {
    "papermill": {
     "duration": 0.055078,
     "end_time": "2022-10-24T04:29:48.405135",
     "exception": false,
     "start_time": "2022-10-24T04:29:48.350057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "022c438e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:48.516635Z",
     "iopub.status.busy": "2022-10-24T04:29:48.515743Z",
     "iopub.status.idle": "2022-10-24T04:29:48.532790Z",
     "shell.execute_reply": "2022-10-24T04:29:48.531980Z"
    },
    "papermill": {
     "duration": 0.074771,
     "end_time": "2022-10-24T04:29:48.534751",
     "exception": false,
     "start_time": "2022-10-24T04:29:48.459980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_checkpoint = ConLLPOSTagging_RNN(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_size = hidden_size,\n",
    "    output_dim = output_dim,\n",
    "    num_layers = num_layers\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b0c0446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:48.646737Z",
     "iopub.status.busy": "2022-10-24T04:29:48.645952Z",
     "iopub.status.idle": "2022-10-24T04:29:48.657039Z",
     "shell.execute_reply": "2022-10-24T04:29:48.656038Z"
    },
    "papermill": {
     "duration": 0.068884,
     "end_time": "2022-10-24T04:29:48.659198",
     "exception": false,
     "start_time": "2022-10-24T04:29:48.590314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint.load_state_dict(torch.load(\"checkpoint.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a7da32f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:48.770605Z",
     "iopub.status.busy": "2022-10-24T04:29:48.770321Z",
     "iopub.status.idle": "2022-10-24T04:29:48.775194Z",
     "shell.execute_reply": "2022-10-24T04:29:48.774293Z"
    },
    "papermill": {
     "duration": 0.062953,
     "end_time": "2022-10-24T04:29:48.777211",
     "exception": false,
     "start_time": "2022-10-24T04:29:48.714258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(vocabulary(text)).to(device)\n",
    "        output = best_checkpoint(text).to(device)\n",
    "    \n",
    "    \n",
    "    return [x.item() for x in output.argmax(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53dffa8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:48.888801Z",
     "iopub.status.busy": "2022-10-24T04:29:48.888536Z",
     "iopub.status.idle": "2022-10-24T04:29:52.927338Z",
     "shell.execute_reply": "2022-10-24T04:29:52.926410Z"
    },
    "papermill": {
     "duration": 4.097722,
     "end_time": "2022-10-24T04:29:52.930308",
     "exception": false,
     "start_time": "2022-10-24T04:29:48.832586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for text in test_data:\n",
    "    predicted.append(predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b113e2",
   "metadata": {
    "papermill": {
     "duration": 0.085046,
     "end_time": "2022-10-24T04:29:53.103626",
     "exception": false,
     "start_time": "2022-10-24T04:29:53.018580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A bizarre move: I'll fattern all sentences by appending all of them into 1 predicted and label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3f720b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:53.282459Z",
     "iopub.status.busy": "2022-10-24T04:29:53.282056Z",
     "iopub.status.idle": "2022-10-24T04:29:53.302920Z",
     "shell.execute_reply": "2022-10-24T04:29:53.301879Z"
    },
    "papermill": {
     "duration": 0.084661,
     "end_time": "2022-10-24T04:29:53.304752",
     "exception": false,
     "start_time": "2022-10-24T04:29:53.220091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred, y_test = [], []\n",
    "\n",
    "for s in predicted:\n",
    "    for l in s:\n",
    "        y_pred.append(l)\n",
    "\n",
    "for s in test_labels:\n",
    "    for l in s:\n",
    "        y_test.append(label2idx[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d30a0d11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:53.417499Z",
     "iopub.status.busy": "2022-10-24T04:29:53.416084Z",
     "iopub.status.idle": "2022-10-24T04:29:53.421309Z",
     "shell.execute_reply": "2022-10-24T04:29:53.420435Z"
    },
    "papermill": {
     "duration": 0.062778,
     "end_time": "2022-10-24T04:29:53.423273",
     "exception": false,
     "start_time": "2022-10-24T04:29:53.360495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87f49b27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:53.568851Z",
     "iopub.status.busy": "2022-10-24T04:29:53.568461Z",
     "iopub.status.idle": "2022-10-24T04:29:53.809573Z",
     "shell.execute_reply": "2022-10-24T04:29:53.808642Z"
    },
    "papermill": {
     "duration": 0.333668,
     "end_time": "2022-10-24T04:29:53.812005",
     "exception": false,
     "start_time": "2022-10-24T04:29:53.478337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889458 | Precision: 0.880343 | Recall: 0.889458 | F1 score: 0.881657\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.6f} | Precision: {precision_score(y_test, y_pred, average = 'weighted'):.6f} | Recall: {recall_score(y_test, y_pred, average = 'weighted'):.6f} | F1 score: {f1_score(y_test, y_pred, average = 'weighted'):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e6d480c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:53.971975Z",
     "iopub.status.busy": "2022-10-24T04:29:53.971020Z",
     "iopub.status.idle": "2022-10-24T04:29:54.040054Z",
     "shell.execute_reply": "2022-10-24T04:29:54.039003Z"
    },
    "papermill": {
     "duration": 0.14687,
     "end_time": "2022-10-24T04:29:54.043070",
     "exception": false,
     "start_time": "2022-10-24T04:29:53.896200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.52      0.55       257\n",
      "           1       0.48      0.21      0.29      1661\n",
      "           2       0.49      0.32      0.38       835\n",
      "           3       0.94      0.97      0.96     38323\n",
      "           4       0.81      0.70      0.75      1668\n",
      "           5       0.47      0.46      0.46       216\n",
      "           6       0.64      0.70      0.67      1156\n",
      "           7       0.48      0.63      0.54      1617\n",
      "           8       0.55      0.37      0.44       702\n",
      "\n",
      "    accuracy                           0.89     46435\n",
      "   macro avg       0.60      0.54      0.56     46435\n",
      "weighted avg       0.88      0.89      0.88     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aefca773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:54.155742Z",
     "iopub.status.busy": "2022-10-24T04:29:54.155412Z",
     "iopub.status.idle": "2022-10-24T04:29:54.183902Z",
     "shell.execute_reply": "2022-10-24T04:29:54.181983Z"
    },
    "papermill": {
     "duration": 0.087736,
     "end_time": "2022-10-24T04:29:54.186667",
     "exception": false,
     "start_time": "2022-10-24T04:29:54.098931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  134     0    34    38    10     5    32     2     2]\n",
      " [    2   348    37   580   140     4     8   485    57]\n",
      " [   46    25   265   325    20    14    94    37     9]\n",
      " [   36   138   155 37210    33    61   266   338    86]\n",
      " [   10    95     8   192  1160     2     6   154    41]\n",
      " [    2     1     3    91     1    99     5     3    11]\n",
      " [    1     1    30   264     1     0   809    49     1]\n",
      " [    0    46     8   482    21     2    33  1019     6]\n",
      " [    2    65     6   231    53    23    11    53   258]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb1c3a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:54.300154Z",
     "iopub.status.busy": "2022-10-24T04:29:54.299321Z",
     "iopub.status.idle": "2022-10-24T04:29:54.361480Z",
     "shell.execute_reply": "2022-10-24T04:29:54.360615Z"
    },
    "papermill": {
     "duration": 0.120091,
     "end_time": "2022-10-24T04:29:54.363387",
     "exception": false,
     "start_time": "2022-10-24T04:29:54.243296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88f86f7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T04:29:54.474653Z",
     "iopub.status.busy": "2022-10-24T04:29:54.473886Z",
     "iopub.status.idle": "2022-10-24T04:29:54.502127Z",
     "shell.execute_reply": "2022-10-24T04:29:54.497450Z"
    },
    "papermill": {
     "duration": 0.085612,
     "end_time": "2022-10-24T04:29:54.504069",
     "exception": false,
     "start_time": "2022-10-24T04:29:54.418457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soccer O O\n",
      "- O O\n",
      "japan B-LOC B-LOC\n",
      "get O O\n",
      "lucky O O\n",
      "win O O\n",
      ", O O\n",
      "china B-PER B-LOC\n",
      "in O O\n",
      "surprise O O\n",
      "defeat O O\n",
      ". O O\n",
      "--------------------------------------------------\n",
      "nadim B-PER O\n",
      "ladki I-PER O\n",
      "--------------------------------------------------\n",
      "al-ain B-LOC O\n",
      ", O O\n",
      "united B-LOC B-PER\n",
      "arab I-LOC I-PER\n",
      "emirates I-LOC I-PER\n",
      "1996-12-06 O I-PER\n",
      "--------------------------------------------------\n",
      "japan B-LOC B-LOC\n",
      "began O O\n",
      "the O O\n",
      "defence O O\n",
      "of O O\n",
      "their O O\n",
      "asian B-MISC O\n",
      "cup I-MISC O\n",
      "title O O\n",
      "with O O\n",
      "a O O\n",
      "lucky O O\n",
      "2-1 O O\n",
      "win O O\n",
      "against O O\n",
      "syria B-LOC B-LOC\n",
      "in O O\n",
      "a O O\n",
      "group O O\n",
      "c O O\n",
      "championship O O\n",
      "match O O\n",
      "on O O\n",
      "friday O O\n",
      ". O O\n",
      "--------------------------------------------------\n",
      "but O O\n",
      "china B-LOC B-LOC\n",
      "saw O O\n",
      "their O O\n",
      "luck O O\n",
      "desert O O\n",
      "them O O\n",
      "in O O\n",
      "the O O\n",
      "second O O\n",
      "match O O\n",
      "of O O\n",
      "the O O\n",
      "group O O\n",
      ", O O\n",
      "crashing O O\n",
      "to O O\n",
      "a O O\n",
      "surprise O O\n",
      "2-0 O O\n",
      "defeat O O\n",
      "to O O\n",
      "newcomers O O\n",
      "uzbekistan B-LOC B-PER\n",
      ". O O\n",
      "--------------------------------------------------\n",
      "china B-LOC B-LOC\n",
      "controlled O O\n",
      "most O O\n",
      "of O O\n",
      "the O O\n",
      "match O O\n",
      "and O O\n",
      "saw O O\n",
      "several O O\n",
      "chances O O\n",
      "missed O O\n",
      "until O O\n",
      "the O O\n",
      "78th O O\n",
      "minute O O\n",
      "when O O\n",
      "uzbek B-MISC B-PER\n",
      "striker O O\n",
      "igor B-PER B-PER\n",
      "shkvyrin I-PER I-PER\n",
      "took O O\n",
      "advantage O O\n",
      "of O O\n",
      "a O O\n",
      "misdirected O O\n",
      "defensive O O\n",
      "header O O\n",
      "to O O\n",
      "lob O O\n",
      "the O O\n",
      "ball O O\n",
      "over O O\n",
      "the O O\n",
      "advancing O O\n",
      "chinese B-MISC B-MISC\n",
      "keeper O I-MISC\n",
      "and O O\n",
      "into O O\n",
      "an O O\n",
      "empty O O\n",
      "net O O\n",
      ". O O\n",
      "--------------------------------------------------\n",
      "oleg B-PER O\n",
      "shatskiku I-PER O\n",
      "made O O\n",
      "sure O O\n",
      "of O O\n",
      "the O O\n",
      "win O O\n",
      "in O O\n",
      "injury O O\n",
      "time O O\n",
      ", O O\n",
      "hitting O O\n",
      "an O O\n",
      "unstoppable O O\n",
      "left O O\n",
      "foot O O\n",
      "shot O O\n",
      "from O O\n",
      "just O O\n",
      "outside O O\n",
      "the O O\n",
      "area O O\n",
      ". O O\n",
      "--------------------------------------------------\n",
      "the O O\n",
      "former O O\n",
      "soviet B-MISC B-LOC\n",
      "republic O O\n",
      "was O O\n",
      "playing O O\n",
      "in O O\n",
      "an O O\n",
      "asian B-MISC O\n",
      "cup I-MISC B-MISC\n",
      "finals O O\n",
      "tie O O\n",
      "for O O\n",
      "the O O\n",
      "first O O\n",
      "time O O\n",
      ". O O\n",
      "--------------------------------------------------\n",
      "despite O O\n",
      "winning O O\n",
      "the O O\n",
      "asian B-MISC O\n",
      "games I-MISC O\n",
      "title O O\n",
      "two O O\n",
      "years O O\n",
      "ago O O\n",
      ", O O\n",
      "uzbekistan B-LOC O\n",
      "are O O\n",
      "in O O\n",
      "the O O\n",
      "finals O O\n",
      "as O O\n",
      "outsiders O O\n",
      ". O O\n",
      "--------------------------------------------------\n",
      "two O O\n",
      "goals O O\n",
      "from O O\n",
      "defensive O O\n",
      "errors O O\n",
      "in O O\n",
      "the O O\n",
      "last O O\n",
      "six O O\n",
      "minutes O O\n",
      "allowed O O\n",
      "japan B-LOC B-LOC\n",
      "to O O\n",
      "come O O\n",
      "from O O\n",
      "behind O O\n",
      "and O O\n",
      "collect O O\n",
      "all O O\n",
      "three O O\n",
      "points O O\n",
      "from O O\n",
      "their O O\n",
      "opening O O\n",
      "meeting O O\n",
      "against O O\n",
      "syria B-LOC B-LOC\n",
      ". O O\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sample_predict = predict(test_data[i])\n",
    "    for text, label_true, label_pred in zip(test_data[i], test_labels[i], sample_predict):\n",
    "        print(text, label_true, idx2label[label_pred])\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1329.849454,
   "end_time": "2022-10-24T04:29:56.926701",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-24T04:07:47.077247",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
