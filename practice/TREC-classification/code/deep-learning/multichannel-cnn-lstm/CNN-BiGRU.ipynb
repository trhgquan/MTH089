{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42iJPiUeIYdu"
      },
      "source": [
        "# Using wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht1JL3zRIaW_",
        "outputId": "f6e89c56-091c-4f22-a754-b599109a8d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.9 MB 38.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 82.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 62.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 78.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 82.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 71.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 60.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 74.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 68.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 73.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 66.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 85.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 87.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 83.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 85.8 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "8TOvt0_kIb9G",
        "outputId": "ed8fa940-b21a-4201-f3ae-ea2408d6333d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1NuXBWrIcOH"
      },
      "source": [
        "# Text classification using LSTM and CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4vA1AMvZIiTo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj8GmIZOJLFE",
        "outputId": "551d01b6-72e7-4c11-aead-d6dccf627a2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN2rBsdvYvZT",
        "outputId": "86ea3435-7533-497d-b920-d688d07d86a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUIU9dVDJf1A"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BI6kcIbKkwq",
        "outputId": "fcccea9e-142c-4547-b350-d775a8509884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-14 10:44:30--  http://cogcomp.org/Data/QA/QC/TREC_10.label\n",
            "Resolving cogcomp.org (cogcomp.org)... 173.236.182.118\n",
            "Connecting to cogcomp.org (cogcomp.org)|173.236.182.118|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www.cogcomp.org/Data/QA/QC/TREC_10.label [following]\n",
            "--2022-12-14 10:44:31--  http://www.cogcomp.org/Data/QA/QC/TREC_10.label\n",
            "Resolving www.cogcomp.org (www.cogcomp.org)... 173.236.182.118\n",
            "Reusing existing connection to cogcomp.org:80.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label [following]\n",
            "--2022-12-14 10:44:32--  https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label\n",
            "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
            "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23354 (23K)\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]  22.81K   103KB/s    in 0.2s    \n",
            "\n",
            "2022-12-14 10:44:33 (103 KB/s) - ‘test.label’ saved [23354/23354]\n",
            "\n",
            "--2022-12-14 10:44:33--  http://cogcomp.org/Data/QA/QC/train_5500.label\n",
            "Resolving cogcomp.org (cogcomp.org)... 173.236.182.118\n",
            "Connecting to cogcomp.org (cogcomp.org)|173.236.182.118|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www.cogcomp.org/Data/QA/QC/train_5500.label [following]\n",
            "--2022-12-14 10:44:33--  http://www.cogcomp.org/Data/QA/QC/train_5500.label\n",
            "Resolving www.cogcomp.org (www.cogcomp.org)... 173.236.182.118\n",
            "Reusing existing connection to cogcomp.org:80.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label [following]\n",
            "--2022-12-14 10:44:34--  https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\n",
            "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
            "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335858 (328K)\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>] 327.99K   370KB/s    in 0.9s    \n",
            "\n",
            "2022-12-14 10:44:35 (370 KB/s) - ‘train.label’ saved [335858/335858]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://cogcomp.org/Data/QA/QC/TREC_10.label -O test.label\n",
        "!wget http://cogcomp.org/Data/QA/QC/train_5500.label -O train.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNgg5gyQJp6G",
        "outputId": "a7a1fdfb-aee6-4eab-db49-194446cb44dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DESC:manner How did serfdom develop in and then leave Russia ?\n",
            "ENTY:cremat What films featured the character Popeye Doyle ?\n",
            "DESC:manner How can I find a list of celebrities ' real names ?\n",
            "ENTY:animal What fowl grabs the spotlight after the Chinese Year of the Monkey ?\n",
            "ABBR:exp What is the full form of .com ?\n",
            "HUM:ind What contemptible scoundrel stole the cork from my lunch ?\n",
            "HUM:gr What team did baseball 's St. Louis Browns become ?\n",
            "HUM:title What is the oldest profession ?\n",
            "DESC:def What are liver enzymes ?\n",
            "HUM:ind Name the scar-faced bounty hunter of The Old West .\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 train.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIfUqEwWKu0o",
        "outputId": "3b8cd988-0e31-45c7-ffee-f748d0845016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NUM:dist How far is it from Denver to Aspen ?\n",
            "LOC:city What county is Modesto , California in ?\n",
            "HUM:desc Who was Galileo ?\n",
            "DESC:def What is an atom ?\n",
            "NUM:date When did Hawaii become a state ?\n",
            "NUM:dist How tall is the Sears Building ?\n",
            "HUM:gr George Bush purchased a small interest in which baseball team ?\n",
            "ENTY:plant What is Australia 's national flower ?\n",
            "DESC:reason Why does the moon turn orange ?\n",
            "DESC:def What is autism ?\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 test.label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx_86E4wKyY8"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dgc5yIOKKwt3"
      },
      "outputs": [],
      "source": [
        "import codecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gr1zazgvK1Vm"
      },
      "outputs": [],
      "source": [
        "def generate_examples(filepath):\n",
        "    examples = []\n",
        "\n",
        "    with codecs.open(filepath, \"rb+\") as f:\n",
        "        for id_, row in enumerate(f):\n",
        "            # ByteError in a sample\n",
        "            label, _, text = row.replace(b\"\\xf0\", b\" \").strip().decode().partition(\" \")\n",
        "\n",
        "            coarse_label, _, fine_label = label.partition(\":\")\n",
        "\n",
        "            examples.append((id_, {\n",
        "                \"label-coarse\" : coarse_label,\n",
        "                \"label-fine\" : fine_label,\n",
        "                \"text\" : text,\n",
        "            }))\n",
        "    \n",
        "    return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-xsWixkNK2fB"
      },
      "outputs": [],
      "source": [
        "train = generate_examples(\"train.label\")\n",
        "test = generate_examples(\"test.label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsNxhaxYK3yY",
        "outputId": "acb1050e-8de3-4521-fc2d-09198d4de68e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5452\n",
            "(0, {'label-coarse': 'DESC', 'label-fine': 'manner', 'text': 'How did serfdom develop in and then leave Russia ?'})\n"
          ]
        }
      ],
      "source": [
        "print(len(train))\n",
        "print(train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q10ZsFDJK44A",
        "outputId": "d5ed624c-2d51-4436-dd22-21df917dc5e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n",
            "(0, {'label-coarse': 'NUM', 'label-fine': 'dist', 'text': 'How far is it from Denver to Aspen ?'})\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(len(test))\n",
        "print(test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PCAybIWfVoPB"
      },
      "outputs": [],
      "source": [
        "label_list = list(set([item[1][\"label-coarse\"] for item in train]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0HwYsodWdvT",
        "outputId": "e2d0e538-329e-46f6-a904-ad5f289bc56c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ABBR', 'ENTY', 'LOC', 'NUM', 'DESC', 'HUM']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8E4-FZrKWnEz"
      },
      "outputs": [],
      "source": [
        "# Manual creating dict to match Huggingface labels.\n",
        "label2idx = {\n",
        "    \"ABBR\" : 0,\n",
        "    \"ENTY\" : 1,\n",
        "    \"DESC\" : 2,\n",
        "    \"HUM\" : 3,\n",
        "    \"LOC\" : 4,\n",
        "    \"NUM\" : 5\n",
        "}\n",
        "idx2label = {\n",
        "    0 : \"ABBR\",\n",
        "    1 : \"ENTY\",\n",
        "    2 : \"DESC\",\n",
        "    3 : \"HUM\",\n",
        "    4 : \"LOC\",\n",
        "    5 : \"NUM\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVrz08KvWxAA",
        "outputId": "4e89168b-9d4e-4343-d276-eb7301309c99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'ABBR': 0, 'ENTY': 1, 'DESC': 2, 'HUM': 3, 'LOC': 4, 'NUM': 5},\n",
              " {0: 'ABBR', 1: 'ENTY', 2: 'DESC', 3: 'HUM', 4: 'LOC', 5: 'NUM'})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label2idx, idx2label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTNc1SZuU338"
      },
      "source": [
        "Concatenate and label data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1BbxR1PJU3G6"
      },
      "outputs": [],
      "source": [
        "texts = [text[\"text\"] for id, text in train]\n",
        "labels = [label2idx[text[\"label-coarse\"]] for id, text in train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8SS93EwwNaEV"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4-0C2I5fTq43"
      },
      "outputs": [],
      "source": [
        "def tokenize(texts):\n",
        "    \"\"\"Tokenize texts, build vocabulary and find maximum sentence length.\n",
        "    \n",
        "    Args:\n",
        "        texts (List[str]): List of text data\n",
        "    \n",
        "    Returns:\n",
        "        tokenized_texts (List[List[str]]): List of list of tokens\n",
        "        word2idx (Dict): Vocabulary built from the corpus\n",
        "        max_len (int): Maximum sentence length\n",
        "    \"\"\"\n",
        "\n",
        "    max_len = 0\n",
        "    tokenized_texts = []\n",
        "    word2idx = {}\n",
        "\n",
        "    # Add <pad> and <unk> tokens to the vocabulary\n",
        "    word2idx['<pad>'] = 0\n",
        "    word2idx['<unk>'] = 1\n",
        "\n",
        "    # Building our vocab from the corpus starting from index 2\n",
        "    idx = 2\n",
        "    for sent in texts:\n",
        "        tokenized_sent = word_tokenize(sent)\n",
        "\n",
        "        # Add `tokenized_sent` to `tokenized_texts`\n",
        "        tokenized_texts.append(tokenized_sent)\n",
        "\n",
        "        # Add new token to `word2idx`\n",
        "        for token in tokenized_sent:\n",
        "            if token not in word2idx:\n",
        "                word2idx[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "        # Update `max_len`\n",
        "        max_len = max(max_len, len(tokenized_sent))\n",
        "\n",
        "    return tokenized_texts, word2idx, max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vCDRQDFOUQDJ"
      },
      "outputs": [],
      "source": [
        "def encode(tokenized_texts, word2idx, max_len):\n",
        "    \"\"\"Pad each sentence to the maximum sentence length and encode tokens to\n",
        "    their index in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        input_ids (np.array): Array of token indexes in the vocabulary with\n",
        "            shape (N, max_len). It will the input of our CNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    input_ids = []\n",
        "    for tokenized_sent in tokenized_texts:\n",
        "        # Pad sentences to max_len\n",
        "        tokenized_sent += ['<pad>'] * (max_len - len(tokenized_sent))\n",
        "\n",
        "        # Encode tokens to input_ids\n",
        "        input_id = [word2idx.get(token) for token in tokenized_sent]\n",
        "        input_ids.append(input_id)\n",
        "    \n",
        "    return np.array(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nsPisVXXuPR"
      },
      "source": [
        "Load pretrained vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ubXerikX80l",
        "outputId": "412cbc57-858f-4123-f8bc-b4596a920560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenize, build vocabulary, encode tokens\n",
        "print(\"Tokenizing...\\n\")\n",
        "tokenized_texts, word2idx, max_len = tokenize(texts)\n",
        "input_ids = encode(tokenized_texts, word2idx, max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOs1ISxGYNsB"
      },
      "source": [
        "# Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "esySp-70YCGI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zRuyQDt7YTrA"
      },
      "outputs": [],
      "source": [
        "def data_loader(train_inputs, val_inputs, train_labels, val_labels,\n",
        "                batch_size=50):\n",
        "    \"\"\"Convert train and validation sets to torch.Tensors and load them to\n",
        "    DataLoader.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data type to torch.Tensor\n",
        "    train_inputs, val_inputs, train_labels, val_labels =\\\n",
        "    tuple(torch.tensor(data) for data in\n",
        "          [train_inputs, val_inputs, train_labels, val_labels])\n",
        "\n",
        "    # Create DataLoader for training data\n",
        "    train_data = TensorDataset(train_inputs, train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Create DataLoader for validation data\n",
        "    val_data = TensorDataset(val_inputs, val_labels)\n",
        "    val_sampler = SequentialSampler(val_data)\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R-g6utXgYZ0E"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1RVUlv7mYdFl"
      },
      "outputs": [],
      "source": [
        "# Train Test Split\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
        "    input_ids, labels, test_size=0.2, random_state=42, stratify = labels)\n",
        "\n",
        "# Load data to PyTorch DataLoader\n",
        "train_dataloader, val_dataloader = data_loader(\n",
        "    train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV95XrLWYiHb"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yt80BD7BYgv7"
      },
      "outputs": [],
      "source": [
        "# Sample configuration:\n",
        "filter_sizes = [3, 5, 7]\n",
        "num_filters = [150, 150, 150]\n",
        "hidden_units = 128\n",
        "embed_dim = 200\n",
        "hidden_dim = 100\n",
        "dropout = .2\n",
        "learning_rate = 1\n",
        "epochs = 50\n",
        "save_path = \"checkpoint.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "w5D9VVrlnZEq",
        "outputId": "a73c85ab-4c73-44e6-c879-e6aef44a4cad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrhgquan\u001b[0m (\u001b[33mkhongsomeo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221214_104437-2w6dwfbl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/khongsomeo/MultiChannelTextClassification/runs/2w6dwfbl\" target=\"_blank\">glorious-dust-5</a></strong> to <a href=\"https://wandb.ai/khongsomeo/MultiChannelTextClassification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/khongsomeo/MultiChannelTextClassification/runs/2w6dwfbl?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f2767114f70>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(config = {\n",
        "    \"filter_sizes\" : filter_sizes,\n",
        "    \"num_filters\" : num_filters,\n",
        "    \"hidden_units\" : hidden_units,\n",
        "    \"embed_dim\" : embed_dim,\n",
        "    \"hidden_dim\" : hidden_dim,\n",
        "    \"dropout\" : dropout,\n",
        "    \"lr\" : learning_rate,\n",
        "    \"epochs\" : epochs\n",
        "},project=\"MultiChannelTextClassification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0v4XuWiAYj9T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_GRU(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size=None,\n",
        "                 embed_dim=200,\n",
        "                 hidden_units=128,\n",
        "                 hidden_dim=100,\n",
        "                 filter_sizes=[3, 4, 5],\n",
        "                 num_filters=[150, 150, 150],\n",
        "                 num_classes=None,\n",
        "                 dropout=0.5):\n",
        "\n",
        "        super(CNN_GRU, self).__init__()\n",
        "        # Embedding layer\n",
        "        self.embed_dim = embed_dim\n",
        "        self.embedding_cnn = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                          embedding_dim=self.embed_dim,\n",
        "                                          padding_idx=0,\n",
        "                                          max_norm=5.0)\n",
        "\n",
        "        self.embedding_gru = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                          embedding_dim=self.embed_dim,\n",
        "                                          padding_idx=0,\n",
        "                                          max_norm=5.0)\n",
        "\n",
        "        # Conv Network\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=self.embed_dim,\n",
        "                      out_channels=num_filters[i],\n",
        "                      kernel_size=filter_sizes[i])\n",
        "            for i in range(len(filter_sizes))\n",
        "        ])\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.embed_dim,\n",
        "            hidden_size = hidden_units,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        # Fully-connected layer and Dropout\n",
        "        self.fc1 = nn.Linear(np.sum(num_filters) + hidden_units, hidden_dim * 2)\n",
        "        self.sm = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(hidden_dim * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "\n",
        "        # ============ CNN ================\n",
        "        x_embed_cnn = self.embedding_cnn(input_ids).float()\n",
        "\n",
        "        x_reshaped = x_embed_cnn.permute(0, 2, 1)\n",
        "\n",
        "        # Conv then ReLU\n",
        "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
        "\n",
        "        # Max pooling\n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
        "            for x_conv in x_conv_list]\n",
        "\n",
        "        cnn_output = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
        "                         dim=1)\n",
        "\n",
        "        # ============ GRU ================\n",
        "        x_embed_gru = self.embedding_gru(input_ids).float()\n",
        "        gru_out, (h_out, _) = self.gru(x_embed_gru)\n",
        "\n",
        "        # Concatenate GRU output versus cnn output\n",
        "        x_fc = torch.cat([h_out, cnn_output], dim = 1)\n",
        "\n",
        "        first_fc = self.sm(self.fc1(x_fc))\n",
        "        \n",
        "        # Compute logits. Output shape: (b, n_classes)\n",
        "        logits = self.fc2(self.dropout(first_fc))\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kxUTRDDwYmdU"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def initilize_model(vocab_size=None,\n",
        "                    embed_dim=200,\n",
        "                    hidden_units=128,\n",
        "                    hidden_dim=100,\n",
        "                    filter_sizes=[3, 4, 5],\n",
        "                    num_filters=[150, 150, 150],\n",
        "                    num_classes=None,\n",
        "                    dropout=0.5,\n",
        "                    learning_rate=0.01):\n",
        "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
        "\n",
        "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
        "    num_filters need to be of the same length.\"\n",
        "\n",
        "    # Instantiate CNN model\n",
        "    cnn_model = CNN_GRU(vocab_size=vocab_size,\n",
        "                        embed_dim=embed_dim,\n",
        "                        hidden_units=hidden_units,\n",
        "                        hidden_dim=hidden_dim,\n",
        "                        filter_sizes=filter_sizes,\n",
        "                        num_filters=num_filters,\n",
        "                        num_classes=num_classes,\n",
        "                        dropout=dropout)\n",
        "    \n",
        "    # Send model to `device` (GPU/CPU)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    # Instantiate Adadelta optimizer\n",
        "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
        "                               lr=learning_rate,\n",
        "                               rho=0.95)\n",
        "\n",
        "    return cnn_model, optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2eBFoclrY8zn"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\"\"\"\n",
        "\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, \n",
        "          optimizer, \n",
        "          train_dataloader, \n",
        "          val_dataloader=None, \n",
        "          epochs=10,\n",
        "          save_path=\"checkpoint.pt\"\n",
        "          ):\n",
        "    \"\"\"Train the CNN model.\"\"\"\n",
        "    \n",
        "    # Tracking best validation accuracy\n",
        "    best_accuracy = 0\n",
        "\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "\n",
        "        # Tracking time and loss\n",
        "        t0_epoch = time.time()\n",
        "        total_loss = 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if val_dataloader is not None:\n",
        "            # After the completion of each training epoch, measure the model's\n",
        "            # performance on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Track the best accuracy\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "                \n",
        "                # Save best acc model.\n",
        "                torch.save(model.state_dict(), save_path)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            wandb.log({'val_accuracy': val_accuracy, 'val_loss': val_loss, 'train_loss' : avg_train_loss})\n",
        "            \n",
        "    print(\"\\n\")\n",
        "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's\n",
        "    performance on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled\n",
        "    # during the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYqfcqK9d7iR",
        "outputId": "9f0d9ab5-2544-4870-e5b7-dc09b210b046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "------------------------------------------------------------\n",
            "   1    |   1.588598   |  1.422987  |   33.94   |   7.61   \n",
            "   2    |   1.032520   |  1.053511  |   60.45   |   1.88   \n",
            "   3    |   0.575945   |  0.801731  |   67.87   |   2.06   \n",
            "   4    |   0.278209   |  0.687352  |   74.48   |   0.79   \n",
            "   5    |   0.104320   |  0.703034  |   77.22   |   0.78   \n",
            "   6    |   0.038647   |  0.667009  |   79.79   |   0.78   \n",
            "   7    |   0.017415   |  0.676802  |   80.63   |   0.78   \n",
            "   8    |   0.010607   |  0.707581  |   80.11   |   0.74   \n",
            "   9    |   0.004810   |  0.711433  |   81.33   |   0.78   \n",
            "  10    |   0.003072   |  0.739717  |   80.97   |   0.74   \n",
            "  11    |   0.002277   |  0.762284  |   80.79   |   0.74   \n",
            "  12    |   0.002023   |  0.749252  |   80.88   |   0.75   \n",
            "  13    |   0.001457   |  0.768684  |   80.77   |   0.74   \n",
            "  14    |   0.001288   |  0.777645  |   81.17   |   0.74   \n",
            "  15    |   0.001016   |  0.790042  |   80.88   |   0.74   \n",
            "  16    |   0.000889   |  0.790950  |   81.15   |   0.73   \n",
            "  17    |   0.000780   |  0.796090  |   80.97   |   0.75   \n",
            "  18    |   0.000726   |  0.803713  |   81.06   |   0.74   \n",
            "  19    |   0.000645   |  0.808029  |   81.06   |   0.74   \n",
            "  20    |   0.000604   |  0.818256  |   80.97   |   0.73   \n",
            "  21    |   0.000526   |  0.817210  |   81.06   |   0.74   \n",
            "  22    |   0.000451   |  0.819914  |   81.24   |   0.74   \n",
            "  23    |   0.000417   |  0.827242  |   80.95   |   0.73   \n",
            "  24    |   0.000416   |  0.830060  |   81.22   |   0.75   \n",
            "  25    |   0.000401   |  0.834704  |   81.04   |   0.76   \n",
            "  26    |   0.000392   |  0.837195  |   81.22   |   0.76   \n",
            "  27    |   0.000358   |  0.841841  |   80.95   |   0.75   \n",
            "  28    |   0.000318   |  0.841752  |   81.22   |   0.74   \n",
            "  29    |   0.000290   |  0.843336  |   81.13   |   0.74   \n",
            "  30    |   0.000306   |  0.846956  |   81.13   |   0.74   \n",
            "  31    |   0.000290   |  0.852230  |   80.86   |   0.75   \n",
            "  32    |   0.000257   |  0.853308  |   81.13   |   0.74   \n",
            "  33    |   0.000286   |  0.857330  |   81.15   |   0.75   \n",
            "  34    |   0.000260   |  0.860829  |   81.13   |   0.85   \n",
            "  35    |   0.000235   |  0.864331  |   81.13   |   0.87   \n",
            "  36    |   0.000237   |  0.865803  |   81.13   |   0.87   \n",
            "  37    |   0.000234   |  0.865565  |   81.24   |   0.89   \n",
            "  38    |   0.000237   |  0.870101  |   81.22   |   0.85   \n",
            "  39    |   0.000231   |  0.874686  |   81.22   |   0.76   \n",
            "  40    |   0.000229   |  0.875102  |   81.22   |   0.74   \n",
            "  41    |   0.000204   |  0.877022  |   81.31   |   0.74   \n",
            "  42    |   0.000204   |  0.875441  |   81.24   |   0.74   \n",
            "  43    |   0.000207   |  0.878589  |   81.52   |   0.78   \n",
            "  44    |   0.000179   |  0.882214  |   81.43   |   0.75   \n",
            "  45    |   0.000168   |  0.882341  |   81.41   |   0.75   \n",
            "  46    |   0.000169   |  0.881433  |   81.59   |   0.78   \n",
            "  47    |   0.000177   |  0.883465  |   81.43   |   0.74   \n",
            "  48    |   0.000154   |  0.888797  |   81.33   |   0.74   \n",
            "  49    |   0.000149   |  0.887186  |   81.61   |   0.77   \n",
            "  50    |   0.000154   |  0.890833  |   81.22   |   0.74   \n",
            "\n",
            "\n",
            "Training complete! Best accuracy: 81.61%.\n"
          ]
        }
      ],
      "source": [
        "set_seed(42)\n",
        "cnn_rand, optimizer = initilize_model(vocab_size=len(word2idx),\n",
        "                                        embed_dim=embed_dim,\n",
        "                                        hidden_units=hidden_units,\n",
        "                                        hidden_dim=hidden_dim,\n",
        "                                        learning_rate=learning_rate,\n",
        "                                        dropout=dropout,\n",
        "                                        num_classes=len(label_list))\n",
        "train(model = cnn_rand, \n",
        "      optimizer = optimizer, \n",
        "      train_dataloader = train_dataloader, \n",
        "      val_dataloader = val_dataloader, \n",
        "      epochs=epochs,\n",
        "      save_path = save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EiTKnZQd6da"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSMjyPKcjmOH"
      },
      "source": [
        "Load state dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9U_fb36hjRJI"
      },
      "outputs": [],
      "source": [
        "best_checkpoint = CNN_GRU(vocab_size=len(word2idx),\n",
        "                            embed_dim=embed_dim,\n",
        "                            hidden_units=hidden_units,\n",
        "                            hidden_dim=hidden_dim,\n",
        "                            dropout=dropout,\n",
        "                            num_classes=len(label_list)).to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXTvndBkjl5w",
        "outputId": "83acadd3-f7e1-4c57-99b9-121277b4ba0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_checkpoint.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ZqU12lDHZSyh"
      },
      "outputs": [],
      "source": [
        "def predict(text, model, max_len = 62):\n",
        "    # Tokenize, pad and encode text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    padded_tokens = tokens + ['<pad>'] * (max_len - len(tokens))\n",
        "    input_id = [word2idx.get(token, word2idx['<unk>']) for token in padded_tokens]\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    input_id = torch.tensor(input_id).unsqueeze(dim=0)\n",
        "\n",
        "    # Compute logits\n",
        "    logits = model.forward(input_id)\n",
        "\n",
        "    #  Compute probability\n",
        "    probs = torch.argmax(F.softmax(logits, dim=1).squeeze(dim=0))\n",
        "\n",
        "    return probs.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynThKVDLamZo",
        "outputId": "1e343d82-2539-4c01-a6d7-a7ce1ff74bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How far is it from Denver to Aspen ?\n",
            "Label: NUM\n",
            "Predicted: NUM\n"
          ]
        }
      ],
      "source": [
        "print(f\"Question: {test[0][1]['text']}\")\n",
        "print(f\"Label: {test[0][1]['label-coarse']}\")\n",
        "print(f\"Predicted: {idx2label[predict(model = best_checkpoint, text = test[0][1]['text'])]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "o2dirLgbaoa3"
      },
      "outputs": [],
      "source": [
        "def eval_testset(model):\n",
        "    correct_label = []\n",
        "    predicted_label = []\n",
        "    \n",
        "    for key, val in test:\n",
        "        correct_label.append(label2idx[val[\"label-coarse\"]])\n",
        "        predicted_label.append(predict(val[\"text\"], model))\n",
        "    \n",
        "    return predicted_label, correct_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh7W5ojme8nM"
      },
      "source": [
        "## Evaluate for cnn_rand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YM5dPi7De8nR"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn_rand, y_true_cnn_rand = eval_testset(best_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZEiUmah7e8nR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns4LFDXDe8nS",
        "outputId": "4e8fc3c9-9b08-4bf5-8767-bcd8303d46be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ABBR       0.64      0.78      0.70         9\n",
            "        ENTY       0.43      0.79      0.56        94\n",
            "        DESC       0.82      0.64      0.72       138\n",
            "         HUM       0.77      0.82      0.79        65\n",
            "         LOC       0.66      0.57      0.61        81\n",
            "         NUM       0.99      0.61      0.75       113\n",
            "\n",
            "    accuracy                           0.68       500\n",
            "   macro avg       0.72      0.70      0.69       500\n",
            "weighted avg       0.75      0.68      0.69       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true_cnn_rand, y_pred_cnn_rand, target_names = label2idx.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwkXwgSggK9I",
        "outputId": "0119aac5-eb5c-4a69-fab9-4f7a9416b1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.676000 \n",
            " Precision (macro): 0.716941 \n",
            " Recall (macro): 0.700641 \n",
            " F1 score (macro): 0.689064\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_true_cnn_rand, y_pred_cnn_rand):.6f} \\n \\\n",
        "Precision (macro): {precision_score(y_true_cnn_rand, y_pred_cnn_rand, average = 'macro'):.6f} \\n \\\n",
        "Recall (macro): {recall_score(y_true_cnn_rand, y_pred_cnn_rand, average = 'macro'):.6f} \\n \\\n",
        "F1 score (macro): {f1_score(y_true_cnn_rand, y_pred_cnn_rand, average = 'macro'):.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s1yXBf4e8nS",
        "outputId": "91b1b8c6-e181-462d-9fa0-6053c5b0bb5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 7  0  2  0  0  0]\n",
            " [ 0 74  0  9 11  0]\n",
            " [ 4 39 89  0  6  0]\n",
            " [ 0  9  0 53  3  0]\n",
            " [ 0 25  7  2 46  1]\n",
            " [ 0 25 10  5  4 69]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_true_cnn_rand, y_pred_cnn_rand))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "4RSCbolKe8nS",
        "outputId": "f01e5e6f-fdd6-488d-c56d-9ca32a1ce7b5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(y_true_cnn_rand, y_pred_cnn_rand), annot = True, fmt = \"g\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.xlabel(\"Ground truth\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WbtaKRLe8nS",
        "outputId": "944d8b68-4c2d-4351-9545-b62992a5cac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How far is it from Denver to Aspen ? -- NUM -- NUM\n",
            "What county is Modesto , California in ? -- LOC -- LOC\n",
            "Who was Galileo ? -- HUM -- HUM\n",
            "What is an atom ? -- ENTY -- DESC\n",
            "When did Hawaii become a state ? -- DESC -- NUM\n",
            "How tall is the Sears Building ? -- NUM -- NUM\n",
            "George Bush purchased a small interest in which baseball team ? -- HUM -- HUM\n",
            "What is Australia 's national flower ? -- ENTY -- ENTY\n",
            "Why does the moon turn orange ? -- ENTY -- DESC\n",
            "What is autism ? -- DESC -- DESC\n"
          ]
        }
      ],
      "source": [
        "for text, pred, truth in zip(test[0:10], y_pred_cnn_rand[0:10], y_true_cnn_rand[0:10]):\n",
        "    print(f\"{text[1]['text']} -- {idx2label[pred]} -- {idx2label[truth]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "Q8Nl6KU8HK-1",
        "outputId": "7aadf444-1fa2-480c-f8ba-f4c54fc99394"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇████████████████████████████████████</td></tr><tr><td>val_loss</td><td>█▅▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.00015</td></tr><tr><td>val_accuracy</td><td>81.22395</td></tr><tr><td>val_loss</td><td>0.89083</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">glorious-dust-5</strong>: <a href=\"https://wandb.ai/khongsomeo/MultiChannelTextClassification/runs/2w6dwfbl\" target=\"_blank\">https://wandb.ai/khongsomeo/MultiChannelTextClassification/runs/2w6dwfbl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221214_104437-2w6dwfbl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bea42e1b0e07028483ba0ff26b9b4dc4fa162e9d0ccb6b0507d54b9d42d30653"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
