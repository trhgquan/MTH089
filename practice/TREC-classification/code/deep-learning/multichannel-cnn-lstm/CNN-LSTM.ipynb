{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42iJPiUeIYdu"
      },
      "source": [
        "# Using wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ht1JL3zRIaW_"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TOvt0_kIb9G",
        "outputId": "04b1d483-ad10-488b-aa4b-7b7bfaa9d837"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtrhgquan\u001b[0m (\u001b[33mkhongsomeo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1NuXBWrIcOH"
      },
      "source": [
        "# Text classification using LSTM and CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4vA1AMvZIiTo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj8GmIZOJLFE",
        "outputId": "5f0c537c-b9be-496d-c973-963454b468b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN2rBsdvYvZT",
        "outputId": "8a93ca6c-8687-424a-bf8b-8267e5b7f6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUIU9dVDJf1A"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BI6kcIbKkwq",
        "outputId": "eee7a757-aa68-4ae6-818a-9344e9605376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-14 03:28:51--  http://cogcomp.org/Data/QA/QC/TREC_10.label\n",
            "Resolving cogcomp.org (cogcomp.org)... 173.236.182.118\n",
            "Connecting to cogcomp.org (cogcomp.org)|173.236.182.118|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www.cogcomp.org/Data/QA/QC/TREC_10.label [following]\n",
            "--2022-12-14 03:28:51--  http://www.cogcomp.org/Data/QA/QC/TREC_10.label\n",
            "Resolving www.cogcomp.org (www.cogcomp.org)... 173.236.182.118\n",
            "Reusing existing connection to cogcomp.org:80.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label [following]\n",
            "--2022-12-14 03:28:51--  https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label\n",
            "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
            "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23354 (23K)\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]  22.81K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-12-14 03:28:52 (328 KB/s) - ‘test.label’ saved [23354/23354]\n",
            "\n",
            "--2022-12-14 03:28:52--  http://cogcomp.org/Data/QA/QC/train_5500.label\n",
            "Resolving cogcomp.org (cogcomp.org)... 173.236.182.118\n",
            "Connecting to cogcomp.org (cogcomp.org)|173.236.182.118|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://www.cogcomp.org/Data/QA/QC/train_5500.label [following]\n",
            "--2022-12-14 03:28:52--  http://www.cogcomp.org/Data/QA/QC/train_5500.label\n",
            "Resolving www.cogcomp.org (www.cogcomp.org)... 173.236.182.118\n",
            "Reusing existing connection to cogcomp.org:80.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label [following]\n",
            "--2022-12-14 03:28:52--  https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label\n",
            "Resolving cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)... 158.130.57.77\n",
            "Connecting to cogcomp.seas.upenn.edu (cogcomp.seas.upenn.edu)|158.130.57.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335858 (328K)\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>] 327.99K  1.18MB/s    in 0.3s    \n",
            "\n",
            "2022-12-14 03:28:53 (1.18 MB/s) - ‘train.label’ saved [335858/335858]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://cogcomp.org/Data/QA/QC/TREC_10.label -O test.label\n",
        "!wget http://cogcomp.org/Data/QA/QC/train_5500.label -O train.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNgg5gyQJp6G",
        "outputId": "73fe70e2-bc61-4aa6-e37d-ca93ed358e05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DESC:manner How did serfdom develop in and then leave Russia ?\n",
            "ENTY:cremat What films featured the character Popeye Doyle ?\n",
            "DESC:manner How can I find a list of celebrities ' real names ?\n",
            "ENTY:animal What fowl grabs the spotlight after the Chinese Year of the Monkey ?\n",
            "ABBR:exp What is the full form of .com ?\n",
            "HUM:ind What contemptible scoundrel stole the cork from my lunch ?\n",
            "HUM:gr What team did baseball 's St. Louis Browns become ?\n",
            "HUM:title What is the oldest profession ?\n",
            "DESC:def What are liver enzymes ?\n",
            "HUM:ind Name the scar-faced bounty hunter of The Old West .\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 train.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIfUqEwWKu0o",
        "outputId": "008848c2-1ab4-47b2-f0d2-d28e579aff87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NUM:dist How far is it from Denver to Aspen ?\n",
            "LOC:city What county is Modesto , California in ?\n",
            "HUM:desc Who was Galileo ?\n",
            "DESC:def What is an atom ?\n",
            "NUM:date When did Hawaii become a state ?\n",
            "NUM:dist How tall is the Sears Building ?\n",
            "HUM:gr George Bush purchased a small interest in which baseball team ?\n",
            "ENTY:plant What is Australia 's national flower ?\n",
            "DESC:reason Why does the moon turn orange ?\n",
            "DESC:def What is autism ?\n"
          ]
        }
      ],
      "source": [
        "!head -n 10 test.label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx_86E4wKyY8"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dgc5yIOKKwt3"
      },
      "outputs": [],
      "source": [
        "import codecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gr1zazgvK1Vm"
      },
      "outputs": [],
      "source": [
        "def generate_examples(filepath):\n",
        "    examples = []\n",
        "\n",
        "    with codecs.open(filepath, \"rb+\") as f:\n",
        "        for id_, row in enumerate(f):\n",
        "            # ByteError in a sample\n",
        "            label, _, text = row.replace(b\"\\xf0\", b\" \").strip().decode().partition(\" \")\n",
        "\n",
        "            coarse_label, _, fine_label = label.partition(\":\")\n",
        "\n",
        "            examples.append((id_, {\n",
        "                \"label-coarse\" : coarse_label,\n",
        "                \"label-fine\" : fine_label,\n",
        "                \"text\" : text,\n",
        "            }))\n",
        "    \n",
        "    return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-xsWixkNK2fB"
      },
      "outputs": [],
      "source": [
        "train = generate_examples(\"train.label\")\n",
        "test = generate_examples(\"test.label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsNxhaxYK3yY",
        "outputId": "0f3a5109-d94f-497d-ba0d-a069b3474781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5452\n",
            "(0, {'label-coarse': 'DESC', 'label-fine': 'manner', 'text': 'How did serfdom develop in and then leave Russia ?'})\n"
          ]
        }
      ],
      "source": [
        "print(len(train))\n",
        "print(train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q10ZsFDJK44A",
        "outputId": "d891e168-814d-4169-8f15-835b1e334ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n",
            "(0, {'label-coarse': 'NUM', 'label-fine': 'dist', 'text': 'How far is it from Denver to Aspen ?'})\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(len(test))\n",
        "print(test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PCAybIWfVoPB"
      },
      "outputs": [],
      "source": [
        "label_list = list(set([item[1][\"label-coarse\"] for item in train]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0HwYsodWdvT",
        "outputId": "a40b2093-1406-497f-afe9-324129b9e374"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ENTY', 'DESC', 'HUM', 'ABBR', 'NUM', 'LOC']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8E4-FZrKWnEz"
      },
      "outputs": [],
      "source": [
        "# Manual creating dict to match Huggingface labels.\n",
        "label2idx = {\n",
        "    \"ABBR\" : 0,\n",
        "    \"ENTY\" : 1,\n",
        "    \"DESC\" : 2,\n",
        "    \"HUM\" : 3,\n",
        "    \"LOC\" : 4,\n",
        "    \"NUM\" : 5\n",
        "}\n",
        "idx2label = {\n",
        "    0 : \"ABBR\",\n",
        "    1 : \"ENTY\",\n",
        "    2 : \"DESC\",\n",
        "    3 : \"HUM\",\n",
        "    4 : \"LOC\",\n",
        "    5 : \"NUM\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVrz08KvWxAA",
        "outputId": "1148017d-afc8-4f32-918a-dcd97b3e225f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'ABBR': 0, 'ENTY': 1, 'DESC': 2, 'HUM': 3, 'LOC': 4, 'NUM': 5},\n",
              " {0: 'ABBR', 1: 'ENTY', 2: 'DESC', 3: 'HUM', 4: 'LOC', 5: 'NUM'})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label2idx, idx2label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTNc1SZuU338"
      },
      "source": [
        "Concatenate and label data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1BbxR1PJU3G6"
      },
      "outputs": [],
      "source": [
        "texts = [text[\"text\"] for id, text in train]\n",
        "labels = [label2idx[text[\"label-coarse\"]] for id, text in train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8SS93EwwNaEV"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4-0C2I5fTq43"
      },
      "outputs": [],
      "source": [
        "def tokenize(texts):\n",
        "    \"\"\"Tokenize texts, build vocabulary and find maximum sentence length.\n",
        "    \n",
        "    Args:\n",
        "        texts (List[str]): List of text data\n",
        "    \n",
        "    Returns:\n",
        "        tokenized_texts (List[List[str]]): List of list of tokens\n",
        "        word2idx (Dict): Vocabulary built from the corpus\n",
        "        max_len (int): Maximum sentence length\n",
        "    \"\"\"\n",
        "\n",
        "    max_len = 0\n",
        "    tokenized_texts = []\n",
        "    word2idx = {}\n",
        "\n",
        "    # Add <pad> and <unk> tokens to the vocabulary\n",
        "    word2idx['<pad>'] = 0\n",
        "    word2idx['<unk>'] = 1\n",
        "\n",
        "    # Building our vocab from the corpus starting from index 2\n",
        "    idx = 2\n",
        "    for sent in texts:\n",
        "        tokenized_sent = word_tokenize(sent)\n",
        "\n",
        "        # Add `tokenized_sent` to `tokenized_texts`\n",
        "        tokenized_texts.append(tokenized_sent)\n",
        "\n",
        "        # Add new token to `word2idx`\n",
        "        for token in tokenized_sent:\n",
        "            if token not in word2idx:\n",
        "                word2idx[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "        # Update `max_len`\n",
        "        max_len = max(max_len, len(tokenized_sent))\n",
        "\n",
        "    return tokenized_texts, word2idx, max_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vCDRQDFOUQDJ"
      },
      "outputs": [],
      "source": [
        "def encode(tokenized_texts, word2idx, max_len):\n",
        "    \"\"\"Pad each sentence to the maximum sentence length and encode tokens to\n",
        "    their index in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        input_ids (np.array): Array of token indexes in the vocabulary with\n",
        "            shape (N, max_len). It will the input of our CNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    input_ids = []\n",
        "    for tokenized_sent in tokenized_texts:\n",
        "        # Pad sentences to max_len\n",
        "        tokenized_sent += ['<pad>'] * (max_len - len(tokenized_sent))\n",
        "\n",
        "        # Encode tokens to input_ids\n",
        "        input_id = [word2idx.get(token) for token in tokenized_sent]\n",
        "        input_ids.append(input_id)\n",
        "    \n",
        "    return np.array(input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nsPisVXXuPR"
      },
      "source": [
        "Load pretrained vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ubXerikX80l",
        "outputId": "3b2e059d-7f75-483d-98bd-4a7343048ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenize, build vocabulary, encode tokens\n",
        "print(\"Tokenizing...\\n\")\n",
        "tokenized_texts, word2idx, max_len = tokenize(texts)\n",
        "input_ids = encode(tokenized_texts, word2idx, max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOs1ISxGYNsB"
      },
      "source": [
        "# Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "esySp-70YCGI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zRuyQDt7YTrA"
      },
      "outputs": [],
      "source": [
        "def data_loader(train_inputs, val_inputs, train_labels, val_labels,\n",
        "                batch_size=50):\n",
        "    \"\"\"Convert train and validation sets to torch.Tensors and load them to\n",
        "    DataLoader.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert data type to torch.Tensor\n",
        "    train_inputs, val_inputs, train_labels, val_labels =\\\n",
        "    tuple(torch.tensor(data) for data in\n",
        "          [train_inputs, val_inputs, train_labels, val_labels])\n",
        "\n",
        "    # Create DataLoader for training data\n",
        "    train_data = TensorDataset(train_inputs, train_labels)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    # Create DataLoader for validation data\n",
        "    val_data = TensorDataset(val_inputs, val_labels)\n",
        "    val_sampler = SequentialSampler(val_data)\n",
        "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "R-g6utXgYZ0E"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1RVUlv7mYdFl"
      },
      "outputs": [],
      "source": [
        "# Train Test Split\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
        "    input_ids, labels, test_size=0.2, random_state=42, stratify = labels)\n",
        "\n",
        "# Load data to PyTorch DataLoader\n",
        "train_dataloader, val_dataloader = data_loader(\n",
        "    train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV95XrLWYiHb"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yt80BD7BYgv7"
      },
      "outputs": [],
      "source": [
        "# Sample configuration:\n",
        "filter_sizes = [3, 4, 5]\n",
        "num_filters = [150, 150, 150]\n",
        "hidden_units = 128\n",
        "embed_dim = 200\n",
        "hidden_dim = 100\n",
        "dropout = .2\n",
        "learning_rate = .25\n",
        "epochs = 50\n",
        "save_path = \"checkpoint.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "w5D9VVrlnZEq",
        "outputId": "695be6b0-d11d-43ff-9ca7-baca353d6efd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221214_032855-1j86cp7h</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/khongsomeo/MultiChannelTextClassification/runs/1j86cp7h\" target=\"_blank\">fragrant-leaf-4</a></strong> to <a href=\"https://wandb.ai/khongsomeo/MultiChannelTextClassification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/khongsomeo/MultiChannelTextClassification/runs/1j86cp7h?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fe236234cd0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(config = {\n",
        "    \"filter_sizes\" : filter_sizes,\n",
        "    \"num_filters\" : num_filters,\n",
        "    \"hidden_units\" : hidden_units,\n",
        "    \"embed_dim\" : embed_dim,\n",
        "    \"hidden_dim\" : hidden_dim,\n",
        "    \"dropout\" : dropout,\n",
        "    \"lr\" : learning_rate,\n",
        "    \"epochs\" : epochs\n",
        "},project=\"MultiChannelTextClassification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0v4XuWiAYj9T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size=None,\n",
        "                 embed_dim=200,\n",
        "                 hidden_units=128,\n",
        "                 hidden_dim=100,\n",
        "                 filter_sizes=[3, 4, 5],\n",
        "                 num_filters=[150, 150, 150],\n",
        "                 num_classes=None,\n",
        "                 dropout=0.5):\n",
        "\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        # Embedding layer\n",
        "        self.embed_dim = embed_dim\n",
        "        self.embedding_cnn = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                          embedding_dim=self.embed_dim,\n",
        "                                          padding_idx=0,\n",
        "                                          max_norm=5.0)\n",
        "\n",
        "        self.embedding_lstm = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                          embedding_dim=self.embed_dim,\n",
        "                                          padding_idx=0,\n",
        "                                          max_norm=5.0)\n",
        "\n",
        "        # Conv Network\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=self.embed_dim,\n",
        "                      out_channels=num_filters[i],\n",
        "                      kernel_size=filter_sizes[i])\n",
        "            for i in range(len(filter_sizes))\n",
        "        ])\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.embed_dim,\n",
        "            hidden_size = hidden_units,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Fully-connected layer and Dropout\n",
        "        self.fc1 = nn.Linear(np.sum(num_filters) + hidden_units, hidden_dim * 2)\n",
        "        self.sm = nn.Sigmoid()\n",
        "        self.fc2 = nn.Linear(hidden_dim * 2, num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "\n",
        "        # ============ CNN ================\n",
        "        x_embed_cnn = self.embedding_cnn(input_ids).float()\n",
        "\n",
        "        x_reshaped = x_embed_cnn.permute(0, 2, 1)\n",
        "\n",
        "        # Conv then ReLU\n",
        "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
        "\n",
        "        # Max pooling\n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
        "            for x_conv in x_conv_list]\n",
        "\n",
        "        cnn_output = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
        "                         dim=1)\n",
        "\n",
        "        # ============ LSTM ================\n",
        "        x_embed_lstm = self.embedding_lstm(input_ids).float()\n",
        "        lstm_out, (h_out, _) = self.lstm(x_embed_lstm)\n",
        "\n",
        "        # Concatenate LSTM output versus cnn output\n",
        "        x_fc = torch.cat([h_out[-1].squeeze(dim = 1), cnn_output], dim = 1)\n",
        "\n",
        "        first_fc = self.sm(self.fc1(x_fc))\n",
        "        \n",
        "        # Compute logits. Output shape: (b, n_classes)\n",
        "        logits = self.fc2(self.dropout(first_fc))\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kxUTRDDwYmdU"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def initilize_model(vocab_size=None,\n",
        "                    embed_dim=200,\n",
        "                    hidden_units=128,\n",
        "                    hidden_dim=100,\n",
        "                    filter_sizes=[3, 4, 5],\n",
        "                    num_filters=[150, 150, 150],\n",
        "                    num_classes=None,\n",
        "                    dropout=0.5,\n",
        "                    learning_rate=0.01):\n",
        "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
        "\n",
        "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
        "    num_filters need to be of the same length.\"\n",
        "\n",
        "    # Instantiate CNN model\n",
        "    cnn_model = CNN_LSTM(vocab_size=vocab_size,\n",
        "                        embed_dim=embed_dim,\n",
        "                        hidden_units=hidden_units,\n",
        "                        hidden_dim=hidden_dim,\n",
        "                        filter_sizes=filter_sizes,\n",
        "                        num_filters=num_filters,\n",
        "                        num_classes=num_classes,\n",
        "                        dropout=dropout)\n",
        "    \n",
        "    # Send model to `device` (GPU/CPU)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    # Instantiate Adadelta optimizer\n",
        "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
        "                               lr=learning_rate,\n",
        "                               rho=0.95)\n",
        "\n",
        "    return cnn_model, optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2eBFoclrY8zn"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\"\"\"\n",
        "\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, \n",
        "          optimizer, \n",
        "          train_dataloader, \n",
        "          val_dataloader=None, \n",
        "          epochs=10,\n",
        "          save_path=\"checkpoint.pt\"\n",
        "          ):\n",
        "    \"\"\"Train the CNN model.\"\"\"\n",
        "    \n",
        "    # Tracking best validation accuracy\n",
        "    best_accuracy = 0\n",
        "\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "\n",
        "        # Tracking time and loss\n",
        "        t0_epoch = time.time()\n",
        "        total_loss = 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if val_dataloader is not None:\n",
        "            # After the completion of each training epoch, measure the model's\n",
        "            # performance on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Track the best accuracy\n",
        "            if val_accuracy > best_accuracy:\n",
        "                best_accuracy = val_accuracy\n",
        "                \n",
        "                # Save best acc model.\n",
        "                torch.save(model.state_dict(), save_path)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            wandb.log({'val_accuracy': val_accuracy, 'val_loss': val_loss, 'train_loss' : avg_train_loss})\n",
        "            \n",
        "    print(\"\\n\")\n",
        "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's\n",
        "    performance on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled\n",
        "    # during the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYqfcqK9d7iR",
        "outputId": "d40933a6-3df4-4074-c480-f9f542fe3714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "------------------------------------------------------------\n",
            "   1    |   1.666727   |  1.639337  |   26.84   |   3.20   \n",
            "   2    |   1.594973   |  1.517918  |   41.64   |   1.10   \n",
            "   3    |   1.379985   |  1.301654  |   42.40   |   1.31   \n",
            "   4    |   1.190995   |  1.139241  |   56.57   |   1.01   \n",
            "   5    |   0.994668   |  0.984729  |   64.69   |   1.03   \n",
            "   6    |   0.811920   |  0.859514  |   67.98   |   0.79   \n",
            "   7    |   0.654826   |  0.786426  |   69.82   |   0.73   \n",
            "   8    |   0.528870   |  0.743508  |   71.46   |   0.75   \n",
            "   9    |   0.418327   |  0.683281  |   74.31   |   0.73   \n",
            "  10    |   0.315734   |  0.656249  |   77.24   |   0.74   \n",
            "  11    |   0.224574   |  0.658008  |   76.68   |   0.70   \n",
            "  12    |   0.155993   |  0.629998  |   78.41   |   0.74   \n",
            "  13    |   0.111319   |  0.632861  |   79.88   |   0.73   \n",
            "  14    |   0.076517   |  0.659275  |   79.15   |   0.70   \n",
            "  15    |   0.058212   |  0.643150  |   80.06   |   0.73   \n",
            "  16    |   0.044731   |  0.660625  |   80.31   |   0.75   \n",
            "  17    |   0.034249   |  0.677155  |   79.97   |   0.70   \n",
            "  18    |   0.027051   |  0.683156  |   80.33   |   0.74   \n",
            "  19    |   0.023401   |  0.687684  |   80.24   |   0.74   \n",
            "  20    |   0.018201   |  0.698977  |   80.41   |   0.72   \n",
            "  21    |   0.016947   |  0.711685  |   80.22   |   0.70   \n",
            "  22    |   0.014175   |  0.719697  |   80.77   |   0.72   \n",
            "  23    |   0.011621   |  0.723759  |   80.59   |   0.70   \n",
            "  24    |   0.009950   |  0.725821  |   80.88   |   0.73   \n",
            "  25    |   0.009209   |  0.726157  |   80.88   |   0.70   \n",
            "  26    |   0.007461   |  0.738077  |   80.59   |   0.69   \n",
            "  27    |   0.006168   |  0.748296  |   80.50   |   0.70   \n",
            "  28    |   0.005681   |  0.760095  |   80.59   |   0.70   \n",
            "  29    |   0.004873   |  0.754419  |   81.06   |   0.73   \n",
            "  30    |   0.004946   |  0.771625  |   80.86   |   0.71   \n",
            "  31    |   0.004299   |  0.769779  |   80.70   |   0.70   \n",
            "  32    |   0.003701   |  0.774904  |   80.70   |   0.70   \n",
            "  33    |   0.003195   |  0.781351  |   80.43   |   0.70   \n",
            "  34    |   0.003133   |  0.787646  |   80.79   |   0.70   \n",
            "  35    |   0.003034   |  0.789941  |   80.61   |   0.71   \n",
            "  36    |   0.002749   |  0.793710  |   80.61   |   0.69   \n",
            "  37    |   0.002349   |  0.794732  |   80.61   |   0.70   \n",
            "  38    |   0.002379   |  0.805436  |   80.13   |   0.69   \n",
            "  39    |   0.002219   |  0.802914  |   80.43   |   0.70   \n",
            "  40    |   0.002100   |  0.806886  |   80.61   |   0.70   \n",
            "  41    |   0.002122   |  0.810105  |   80.43   |   0.70   \n",
            "  42    |   0.002069   |  0.815449  |   80.24   |   0.70   \n",
            "  43    |   0.001740   |  0.815368  |   80.52   |   0.70   \n",
            "  44    |   0.001720   |  0.812935  |   80.88   |   0.70   \n",
            "  45    |   0.001767   |  0.811808  |   80.88   |   0.71   \n",
            "  46    |   0.001651   |  0.815140  |   81.06   |   0.70   \n",
            "  47    |   0.001528   |  0.822083  |   80.88   |   0.70   \n",
            "  48    |   0.001441   |  0.826566  |   80.70   |   0.70   \n",
            "  49    |   0.001370   |  0.824797  |   80.97   |   0.69   \n",
            "  50    |   0.001467   |  0.824510  |   80.97   |   0.70   \n",
            "\n",
            "\n",
            "Training complete! Best accuracy: 81.06%.\n"
          ]
        }
      ],
      "source": [
        "set_seed(42)\n",
        "cnn_rand, optimizer = initilize_model(vocab_size=len(word2idx),\n",
        "                                        embed_dim=embed_dim,\n",
        "                                        hidden_units=hidden_units,\n",
        "                                        hidden_dim=hidden_dim,\n",
        "                                        learning_rate=learning_rate,\n",
        "                                        dropout=dropout,\n",
        "                                        num_classes=len(label_list))\n",
        "train(model = cnn_rand, \n",
        "      optimizer = optimizer, \n",
        "      train_dataloader = train_dataloader, \n",
        "      val_dataloader = val_dataloader, \n",
        "      epochs=epochs,\n",
        "      save_path = save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EiTKnZQd6da"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSMjyPKcjmOH"
      },
      "source": [
        "Load state dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "9U_fb36hjRJI"
      },
      "outputs": [],
      "source": [
        "best_checkpoint = CNN_LSTM(vocab_size=len(word2idx),\n",
        "                            embed_dim=embed_dim,\n",
        "                            hidden_units=hidden_units,\n",
        "                            hidden_dim=hidden_dim,\n",
        "                            # learning_rate=learning_rate,\n",
        "                            dropout=dropout,\n",
        "                            num_classes=len(label_list)).to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXTvndBkjl5w",
        "outputId": "0f0ef786-2917-4bf0-9814-a2e3cdd97962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_checkpoint.load_state_dict(torch.load(save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ZqU12lDHZSyh"
      },
      "outputs": [],
      "source": [
        "def predict(text, model, max_len = 62):\n",
        "    # Tokenize, pad and encode text\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    padded_tokens = tokens + ['<pad>'] * (max_len - len(tokens))\n",
        "    input_id = [word2idx.get(token, word2idx['<unk>']) for token in padded_tokens]\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    input_id = torch.tensor(input_id).unsqueeze(dim=0)\n",
        "\n",
        "    # Compute logits\n",
        "    logits = model.forward(input_id)\n",
        "\n",
        "    #  Compute probability\n",
        "    probs = torch.argmax(F.softmax(logits, dim=1).squeeze(dim=0))\n",
        "\n",
        "    return probs.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynThKVDLamZo",
        "outputId": "48c3c8ab-6bac-4a73-e6f7-9f15ec65f17d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How far is it from Denver to Aspen ?\n",
            "Label: NUM\n",
            "Predicted: NUM\n"
          ]
        }
      ],
      "source": [
        "print(f\"Question: {test[0][1]['text']}\")\n",
        "print(f\"Label: {test[0][1]['label-coarse']}\")\n",
        "print(f\"Predicted: {idx2label[predict(model = best_checkpoint, text = test[0][1]['text'])]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "o2dirLgbaoa3"
      },
      "outputs": [],
      "source": [
        "def eval_testset(model):\n",
        "    correct_label = []\n",
        "    predicted_label = []\n",
        "    \n",
        "    for key, val in test:\n",
        "        correct_label.append(label2idx[val[\"label-coarse\"]])\n",
        "        predicted_label.append(predict(val[\"text\"], model))\n",
        "    \n",
        "    return predicted_label, correct_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh7W5ojme8nM"
      },
      "source": [
        "## Evaluate for cnn_rand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YM5dPi7De8nR"
      },
      "outputs": [],
      "source": [
        "y_pred_cnn_rand, y_true_cnn_rand = eval_testset(best_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ZEiUmah7e8nR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns4LFDXDe8nS",
        "outputId": "5d2265c3-85ba-4a4b-806a-349623bb49c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ABBR       0.70      0.78      0.74         9\n",
            "        ENTY       0.43      0.78      0.56        94\n",
            "        DESC       0.75      0.84      0.79       138\n",
            "         HUM       0.83      0.23      0.36        65\n",
            "         LOC       0.61      0.63      0.62        81\n",
            "         NUM       0.97      0.57      0.72       113\n",
            "\n",
            "    accuracy                           0.65       500\n",
            "   macro avg       0.72      0.64      0.63       500\n",
            "weighted avg       0.73      0.65      0.65       500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true_cnn_rand, y_pred_cnn_rand, target_names = label2idx.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwkXwgSggK9I",
        "outputId": "e5154d91-04aa-4fcd-addd-1fa05b351314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.652000 \n",
            " Precision (macro): 0.717115 \n",
            " Recall (macro): 0.636954 \n",
            " F1 score (macro): 0.630829\n"
          ]
        }
      ],
      "source": [
        "print(f\"Accuracy: {accuracy_score(y_true_cnn_rand, y_pred_cnn_rand):.6f} \\n \\\n",
        "Precision (macro): {precision_score(y_true_cnn_rand, y_pred_cnn_rand, average = 'macro'):.6f} \\n \\\n",
        "Recall (macro): {recall_score(y_true_cnn_rand, y_pred_cnn_rand, average = 'macro'):.6f} \\n \\\n",
        "F1 score (macro): {f1_score(y_true_cnn_rand, y_pred_cnn_rand, average = 'macro'):.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s1yXBf4e8nS",
        "outputId": "f32f5b8f-ce2d-4444-ad3b-8589c7900b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  7   0   2   0   0   0]\n",
            " [  0  73   4   2  15   0]\n",
            " [  2  14 116   0   6   0]\n",
            " [  0  41   4  15   4   1]\n",
            " [  0  17  11   1  51   1]\n",
            " [  1  24  17   0   7  64]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_true_cnn_rand, y_pred_cnn_rand))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "4RSCbolKe8nS",
        "outputId": "ded935af-2c0e-40b4-c7bc-eaf6a4750545"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.heatmap(confusion_matrix(y_true_cnn_rand, y_pred_cnn_rand), annot = True, fmt = \"g\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.xlabel(\"Ground truth\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WbtaKRLe8nS",
        "outputId": "5b1f33a7-4564-4964-ce05-eea33ec095b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How far is it from Denver to Aspen ? -- NUM -- NUM\n",
            "What county is Modesto , California in ? -- LOC -- LOC\n",
            "Who was Galileo ? -- ENTY -- HUM\n",
            "What is an atom ? -- DESC -- DESC\n",
            "When did Hawaii become a state ? -- DESC -- NUM\n",
            "How tall is the Sears Building ? -- NUM -- NUM\n",
            "George Bush purchased a small interest in which baseball team ? -- HUM -- HUM\n",
            "What is Australia 's national flower ? -- ENTY -- ENTY\n",
            "Why does the moon turn orange ? -- ENTY -- DESC\n",
            "What is autism ? -- DESC -- DESC\n"
          ]
        }
      ],
      "source": [
        "for text, pred, truth in zip(test[0:10], y_pred_cnn_rand[0:10], y_true_cnn_rand[0:10]):\n",
        "    print(f\"{text[1]['text']} -- {idx2label[pred]} -- {idx2label[truth]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "b87f4983c7bb448d9d9ca1da1fa4a9b8",
            "5942c133159e4bf081dd078093d893a0",
            "ff3e3ad0531b45c286a951b29e244ee6",
            "c00a00b580e14ebbb10b37c45219e513",
            "cc73fbb47cb14cdfa99adee7ee45c202",
            "75bd223da89d4b29b66e010e29c0f74d",
            "a1ccfa39f41d49e0bec2a50091f36ab9",
            "f49495305fc74bbf8b841b523ccb98bc"
          ]
        },
        "id": "Q8Nl6KU8HK-1",
        "outputId": "d306787f-7ff9-4416-c8a7-a9eecbe5a411"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b87f4983c7bb448d9d9ca1da1fa4a9b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.006 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.449701…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>██▇▆▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▅▆▇▇▇▇███████████████████████████████</td></tr><tr><td>val_loss</td><td>█▇▆▅▃▂▂▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.00147</td></tr><tr><td>val_accuracy</td><td>80.97118</td></tr><tr><td>val_loss</td><td>0.82451</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">fragrant-leaf-4</strong>: <a href=\"https://wandb.ai/khongsomeo/MultiChannelTextClassification/runs/1j86cp7h\" target=\"_blank\">https://wandb.ai/khongsomeo/MultiChannelTextClassification/runs/1j86cp7h</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20221214_032855-1j86cp7h/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bea42e1b0e07028483ba0ff26b9b4dc4fa162e9d0ccb6b0507d54b9d42d30653"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5942c133159e4bf081dd078093d893a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc73fbb47cb14cdfa99adee7ee45c202",
            "placeholder": "​",
            "style": "IPY_MODEL_75bd223da89d4b29b66e010e29c0f74d",
            "value": "0.006 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "75bd223da89d4b29b66e010e29c0f74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1ccfa39f41d49e0bec2a50091f36ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87f4983c7bb448d9d9ca1da1fa4a9b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5942c133159e4bf081dd078093d893a0",
              "IPY_MODEL_ff3e3ad0531b45c286a951b29e244ee6"
            ],
            "layout": "IPY_MODEL_c00a00b580e14ebbb10b37c45219e513"
          }
        },
        "c00a00b580e14ebbb10b37c45219e513": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc73fbb47cb14cdfa99adee7ee45c202": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49495305fc74bbf8b841b523ccb98bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff3e3ad0531b45c286a951b29e244ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1ccfa39f41d49e0bec2a50091f36ab9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f49495305fc74bbf8b841b523ccb98bc",
            "value": 0.4497010849509189
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
